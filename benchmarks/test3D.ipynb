{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92808ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 11 07:29:50 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1D.0 Off |                    0 |\n",
      "|  0%   22C    P8              19W / 300W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d846afd-a3fd-49fa-ab4f-bb6ef3dc37f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a17adde-c69c-4aa1-827a-8f6508b2fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Requirement already satisfied: torch-geometric in /home/ubuntu/.local/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1050ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Requirement already satisfied: torch-scatter in /home/ubuntu/.local/lib/python3.10/site-packages (2.1.2+pt23cu121)\n",
      "Requirement already satisfied: torch-sparse in /home/ubuntu/.local/lib/python3.10/site-packages (0.6.18+pt23cu121)\n",
      "Requirement already satisfied: torch-cluster in /home/ubuntu/.local/lib/python3.10/site-packages (1.6.3+pt23cu121)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cee94b-989c-4354-a213-5f6d29e4f2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ase in /home/ubuntu/.local/lib/python3.10/site-packages (3.22.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (3.8.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (24.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (4.51.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (10.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c377884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pytorch-lightning\n",
    "#!pip install transformers\n",
    "#!pip install lightning-bolts\n",
    "#!pip install lightning-utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45edc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import asdict\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "# from pl_bolts.optimizers import LinearWarmupCosineAnnealingLR\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "from config import Config\n",
    "from data.ee import EE\n",
    "from data.bde import BDE\n",
    "from data.drugs import Drugs\n",
    "from data.kraken import Kraken\n",
    "from happy_config import ConfigLoader\n",
    "from loaders.samplers import EnsembleSampler, EnsembleMultiBatchSampler\n",
    "from loaders.multibatch import MultiBatchLoader\n",
    "from utils.early_stopping import EarlyStopping, generate_checkpoint_filename\n",
    "\n",
    "from models.model_3d import Model3D\n",
    "from models.models_3d.chiro import ChIRo\n",
    "from models.models_3d.painn import PaiNN\n",
    "from models.models_3d.schnet import SchNet\n",
    "from models.models_3d.gemnet import GemNetT\n",
    "from models.models_3d.dimenet import DimeNet, DimeNetPlusPlus\n",
    "from models.models_3d.clofnet import ClofNet\n",
    "from models.models_3d.leftnet import LEFTNet\n",
    "#from models.models_3d.chytorch_discrete import ChytorchDiscrete\n",
    "#from models.models_3d.chytorch_conformer import ChytorchConformer\n",
    "\n",
    "import pickle\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b09137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CyclicLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e757818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "torch.cuda.empty_cache()\n",
    "#print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If you are using a GPU, you should also set the seed for CUDA operations\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#np.random.seed(seed)\n",
    "################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee749ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_torch(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the R-squared score.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (torch.Tensor): The true target values.\n",
    "        y_pred (torch.Tensor): The predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        float: The R-squared score.\n",
    "    \"\"\"\n",
    "    # Calculate the mean of the true target values\n",
    "    y_mean = torch.mean(y_true)\n",
    "    # Calculate the total sum of squares (TSS)\n",
    "    tss = torch.sum((y_true - y_mean) ** 2)\n",
    "    # Calculate the residual sum of squares (RSS)\n",
    "    rss = torch.sum((y_true - y_pred) ** 2)\n",
    "    # Calculate R-squared score\n",
    "    r2 = 1 - rss / tss\n",
    "\n",
    "    return r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08ff1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, hparams, dataset=None):\n",
    "        super().__init__()\n",
    "        self.hparams.update(hparams.__dict__) if hasattr(hparams, \"__dict__\") else self.hparams.update(hparams)\n",
    "        self._saved_dataloaders = dict()\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.variable_name = None\n",
    "            unique_variables = 1\n",
    "\n",
    "            if self.hparams.dataset == 'Drugs':\n",
    "                dataset = Drugs('/mnt/data/MARCEL/datasets/Drugs', max_num_conformers=self.hparams.max_num_conformers).shuffle()\n",
    "            elif self.hparams.dataset == 'Kraken':\n",
    "                dataset = Kraken('/mnt/data/MARCEL/datasets/Kraken', max_num_conformers=self.hparams.max_num_conformers).shuffle()\n",
    "            elif self.hparams.dataset == 'BDE':\n",
    "                dataset = BDE('/mnt/data/MARCEL/datasets/BDE').shuffle()\n",
    "                self.variable_name = 'is_ligand'\n",
    "                unique_variables = 2\n",
    "            elif self.hparams.dataset == 'EE':\n",
    "                dataset = EE('/mnt/data/MARCEL/datasets/EE', max_num_conformers=self.hparams.max_num_conformers).shuffle()\n",
    "                self.variable_name = 'config_id'\n",
    "                unique_variables = 2\n",
    "            \n",
    "            #autoscaling\n",
    "            target_id = dataset.descriptors.index(self.hparams.target)\n",
    "            labels = dataset.y[:, target_id]\n",
    "            mean = dataset.y.mean(dim=0, keepdim=True)\n",
    "            std = dataset.y.std(dim=0, keepdim=True)\n",
    "            dataset.y = ((dataset.y - mean) / std).to('cuda')\n",
    "            mean = mean.to('cuda')\n",
    "            std = std.to('cuda')\n",
    "            #data.dataset.data.y = data.dataset.y\n",
    "            \n",
    "            self.dataset = dataset\n",
    "            self.max_atomic_num = self.dataset.data.x[:, 0].max().item() + 1\n",
    "            self.unique_variables = unique_variables\n",
    "            print('--done---')\n",
    "\n",
    "    def split_compute(self):\n",
    "\n",
    "        split = self.dataset.get_idx_split(train_ratio=self.hparams.train_ratio, \n",
    "                                      valid_ratio=self.hparams.valid_ratio, \n",
    "                                      seed=self.hparams.seed)\n",
    "        self.train_dataset = self.dataset[split['train']]\n",
    "        self.valid_dataset = self.dataset[split['valid']]\n",
    "        self.test_dataset = self.dataset[split['test']]\n",
    "\n",
    "        print(f'{len(self.train_dataset)} training data, {len(self.test_dataset)} test data and {len(self.valid_dataset)} validation data')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._get_dataloader(self.train_dataset, \"train\")\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._get_dataloader(self.valid_dataset, \"val\")\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._get_dataloader(self.test_dataset, \"test\")\n",
    "    \n",
    "    def _get_dataloader(self, dataset, stage, store_dataloader=True):\n",
    "        store_dataloader = store_dataloader\n",
    "        \n",
    "        if stage in self._saved_dataloaders and store_dataloader:\n",
    "            return self._saved_dataloaders[stage]\n",
    "\n",
    "        if self.hparams.model3d_augmentation:\n",
    "            strategy = 'random'\n",
    "        else:\n",
    "            strategy = 'first'\n",
    "            \n",
    "        if stage == \"train\":\n",
    "            shuffle=True                              \n",
    "        else:\n",
    "            shuffle=False\n",
    "            if stage == \"train\"=='test':\n",
    "                strategy = 'first'\n",
    "\n",
    "        if self.variable_name is None:\n",
    "            dl = DataLoader(dataset, batch_sampler=EnsembleSampler(dataset, \n",
    "                                                                   batch_size=self.hparams.batch_size, \n",
    "                                                                   strategy=strategy, \n",
    "                                                                   shuffle=shuffle),\n",
    "                           num_workers=20)\n",
    "        else:\n",
    "            dl = MultiBatchLoader(dataset, batch_sampler=EnsembleMultiBatchSampler(dataset, \n",
    "                                                                                   batch_size=self.hparams.batch_size, \n",
    "                                                                                   strategy=strategy, \n",
    "                                                                                   shuffle=shuffle, \n",
    "                                                                                   variable_name=self.variable_name),\n",
    "                                 )\n",
    "        if store_dataloader:\n",
    "            self._saved_dataloaders[stage] = dl\n",
    "        return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5796c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_pnorm(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Computes the norm of the parameters of a model.\n",
    "    :param model: A PyTorch model.\n",
    "    :return: The norm of the parameters of the model.\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum([p.norm().item() ** 2 for p in model.parameters() if p.requires_grad]))\n",
    "\n",
    "\n",
    "def compute_gnorm(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Computes the norm of the gradients of a model.\n",
    "    :param model: A PyTorch model.\n",
    "    :return: The norm of the gradients of the model.\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum([p.grad.norm().item() ** 2 for p in model.parameters() if p.grad is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLM(LightningModule):\n",
    "    def __init__(self, max_atomic_num=None, whole_dataset = None, unique_variables=1, **kwargs):\n",
    "        super().__init__()\n",
    "        #self.kwargs.update(kwargs.__dict__) if hasattr(kwargs, \"__dict__\") else self.kwargs.update(kwargs)\n",
    "        print(kwargs.get('model3d'))\n",
    "        if kwargs.get('model3d').model == 'SchNet':\n",
    "            model_factory = lambda: SchNet(max_atomic_num=max_atomic_num, \n",
    "                                           **asdict(kwargs.get('model3d').schnet))\n",
    "        elif kwargs.get('model3d').model == 'DimeNet':\n",
    "            model_factory = lambda: DimeNet(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').dimenet))\n",
    "        elif kwargs.get('model3d').model == 'DimeNet++':\n",
    "            model_factory = lambda: DimeNetPlusPlus(max_atomic_num=max_atomic_num, \n",
    "                                                    **asdict(kwargs.get('model3d').dimenetplusplus))\n",
    "        elif kwargs.get('model3d').model == 'GemNet':\n",
    "            model_factory = lambda: GemNetT(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').gemnet))\n",
    "        elif kwargs.get('model3d').model == 'ChIRo':\n",
    "            model_factory = lambda: ChIRo(**asdict(kwargs.get('model3d').chiro))\n",
    "            \n",
    "        elif kwargs.get('model3d').model == 'PaiNN':\n",
    "            model_factory = lambda: PaiNN(max_atomic_num=max_atomic_num, \n",
    "                                          **asdict(kwargs.get('model3d').painn))\n",
    "        elif kwargs.get('model3d').model == 'ClofNet':\n",
    "            model_factory = lambda: ClofNet(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').clofnet))\n",
    "        elif kwargs.get('model3d').model == 'LEFTNet':\n",
    "            model_factory = lambda: LEFTNet(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').leftnet))\n",
    "        elif kwargs.get('model3d').model == 'ChytorchDiscrete':\n",
    "            model_factory = lambda: ChytorchDiscrete(max_neighbors=max_atomic_num, \n",
    "                                                     **asdict(kwargs.get('model3d').chytorch_discrete))\n",
    "        elif kwargs.get('model3d').model == 'ChytorchConformer':\n",
    "            model_factory = lambda: ChytorchConformer(**asdict(kwargs.get('model3d').chytorch_conformer))\n",
    "            \n",
    "        elif kwargs.get('model3d').model == 'ChytorchRotary':\n",
    "            model_factory = lambda: ChytorchRotary(max_neighbors=max_atomic_num, \n",
    "                                                   **asdict(kwargs.get('model3d').chytorch_rotary))\n",
    "        self.device_= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.net = Model3D(model_factory, \n",
    "                           hidden_dim=kwargs.get('hidden_dim'), \n",
    "                           out_dim=1,\n",
    "                           unique_variables=unique_variables, \n",
    "                           device='cuda').to('cuda')\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss() #LOGITS #GroupedScaledMAELoss(torch.ones(4, dtype=torch.long))\n",
    "        \n",
    "        self.lr = kwargs.get('learning_rate')\n",
    "        self.wd = kwargs.get('learning_rate')\n",
    "        self.whole_dataset = whole_dataset\n",
    "\n",
    "        self._reset_losses_dict()\n",
    "        self._reset_inference_results()\n",
    "        self.save_hyperparameters(ignore=[\"cosine_annealing_lr\",\"linear_warmup_cosine_annealing_lr\",\n",
    "                                          \"model1d\",\"model2d\",\"model3d\",\"model4d\",\"modelfprf\",\"one_cycle_lr\",\n",
    "                                          \"reduce_lr_on_plateau\",\"whole_dataset\",\"device\",\"scheduler\"])\n",
    "\n",
    "    def forward(self, batch):\n",
    "        out = self.net(batch)\n",
    "        return out\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        o = AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        s = CyclicLR(o, self.lr, 2e-4, 1000, mode='triangular', cycle_momentum=False)\n",
    "        # instantiate the WeakMethod in the lr scheduler object into the custom scale function attribute\n",
    "        #s._scale_fn_custom = s._scale_fn_ref()\n",
    "        # remove the reference so there are no more WeakMethod references in the object\n",
    "        #s._scale_fn_ref = None\n",
    "        return [o], [{'scheduler': s, 'interval': 'step', 'name': 'lr_scheduler'}]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pnorm = compute_pnorm(self.net)\n",
    "        gnorm = compute_gnorm(self.net)\n",
    "        self.log(f'(training) pnorm', pnorm)\n",
    "        self.log(f'(training) gnorm', gnorm)\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "        \n",
    "    def step(self, batch, stage):\n",
    "        start = time()\n",
    "        if type(batch) is not list:\n",
    "            batch = [batch]\n",
    "        molecule_idx = batch[0].molecule_idx.to('cuda')\n",
    "        dataset = self.whole_dataset.y.to('cuda')\n",
    "        targets = dataset[molecule_idx].squeeze()\n",
    "\n",
    "        with torch.set_grad_enabled(stage == \"train\"):\n",
    "            pred = self(batch)\n",
    "            loss = self.loss_fn(pred.squeeze(), targets)\n",
    "            \n",
    "            if stage == \"test\":\n",
    "                self.inference_results['y_pred'].append(pred.squeeze())\n",
    "                self.inference_results['y_true'].append(targets.squeeze())\n",
    "                return None\n",
    "\n",
    "            r2=r2_score_torch(targets.cpu(),pred.squeeze().cpu().detach())\n",
    "\n",
    "            self.logging_info[f'{stage}_loss'].append(loss.item())\n",
    "            self.logging_info[f'{stage}_r2'].append(r2)\n",
    "            self.logging_info[f'{stage}_time'].append(time()-start)\n",
    "            \n",
    "            if stage == 'train':\n",
    "                self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], on_step=True, on_epoch=False, prog_bar=True, logger=True, sync_dist=True)\n",
    "                self.log(f'{stage}_step_loss', loss.item(), on_step=True, on_epoch=False, prog_bar=True, logger=True, sync_dist=True)\n",
    "            #model.save_checkpoint('checkpoint.pth')\n",
    "            return loss\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self.trainer.sanity_checking:                    \n",
    "            result_dict = {\n",
    "                \"epoch\": float(self.current_epoch),\n",
    "                \"train_epoch_loss\": torch.tensor(self.logging_info[\"train_loss\"]).mean().item(),\n",
    "                \"train_epoch_r2\": torch.tensor(self.logging_info[\"train_r2\"]).mean().item(),\n",
    "                \"val_epoch_loss\": torch.tensor(self.logging_info[\"val_loss\"]).mean().item(),\n",
    "                \"val_epoch_r2\": torch.tensor(self.logging_info[\"val_r2\"]).mean().item(),\n",
    "                \"train_epoch_time\": sum(self.logging_info[\"train_time\"]),\n",
    "                \"val_epoch_time\": sum(self.logging_info[\"val_time\"]),\n",
    "                }\n",
    "            self.log_dict(result_dict, logger=True, sync_dist=True)\n",
    "            \n",
    "        self._reset_losses_dict()\n",
    "    \n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        for key in self.inference_results.keys():\n",
    "            self.inference_results[key] = torch.cat(self.inference_results[key], dim=0)\n",
    "    \n",
    "    def _reset_losses_dict(self):\n",
    "        self.logging_info = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_r2\": [], \n",
    "            \"train_mse\": [], \n",
    "            \"val_loss\": [],\n",
    "            \"val_r2\": [],\n",
    "            \"train_sample_size\": [], \n",
    "            \"val_sample_size\": [],\n",
    "            \"train_time\": [],\n",
    "            \"val_time\": [],\n",
    "        }\n",
    "        \n",
    "    def _reset_inference_results(self):\n",
    "        self.inference_results = {'y_pred': [],\n",
    "                                  'y_true': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7d3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'BDE'\n",
    "target = 'BindingEnergy'\n",
    "modeltype = 'PaiNN'\n",
    "\n",
    "writer = SummaryWriter(log_dir='/mnt/code/logs/')\n",
    "#loader = ConfigLoader(model=Config, config='params/params_1d.json')\n",
    "#config = loader()\n",
    "\n",
    "config = Config\n",
    "config.dataset = dataname\n",
    "config.target = target\n",
    "config.device = 'cuda:0'\n",
    "\n",
    "\n",
    "#config.hidden_dim =128\n",
    "#config.dropout = 0.5\n",
    "\n",
    "#config.train_ratio = 0.7\n",
    "#config.valid_ratio = 0.1\n",
    "#config.batch_size = 256\n",
    "#config.patience = 200\n",
    "\n",
    "#config.learning_rate = 0.00001\n",
    "#config.weight_decay = 1e-4\n",
    "#config.scheduler = None\n",
    "#config.reduce_lr_on_plateau = ReduceLROnPlateau()\n",
    "\n",
    "#config.num_epochs = 2000\n",
    "#config.cosine_annealing_lr = CosineAnnealingLR()\n",
    "#config.linear_warmup_cosine_annealing_lr = LinearWarmupCosineAnnealingLR()\n",
    "\n",
    "\n",
    "#not used in 1d\n",
    "\n",
    "#config.one_cycle_lr = OneCycleLR()\n",
    "#config.seed = 123\n",
    "#activation = 'relu'\n",
    "\n",
    "######3DMODEL\n",
    "config.model3d.model=modeltype\n",
    "config.model3d.augmentation = True\n",
    "\n",
    "#config.model3d.schnet = SchNet()\n",
    "#config.model3d.dimenet = DimeNet()\n",
    "#config.model3d.dimenetplusplus = DimeNetPlusPlus()\n",
    "#config.model3d.gemnet = GemNet()\n",
    "#config.model3d.painn = PaiNN()\n",
    "#config.model3d.clofnet = ClofNet()\n",
    "#config.model3d.leftnet= LEFTNet()\n",
    "#config.model3d.chytorch_discrete = ChytorchDiscrete()\n",
    "#config.model3d.chytorch_conformer = ChytorchConformer()\n",
    "#config.model3d.chytorch_rotary = ChytorchRotary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce3a7da-8b67-4b4c-98dc-c92f28bcc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_to_dict(config_class):\n",
    "    config_dict = {}\n",
    "    for attr_name in dir(config_class):\n",
    "        if not attr_name.startswith(\"__\") and not callable(getattr(config_class, attr_name)):\n",
    "            #if attr_name=='model1d':\n",
    "             #   attr_val = getattr(config_class, attr_name)\n",
    "             #   for subattr, subvalue in zip(['model', 'input_type', 'embedding_dim', 'num_layers', 'num_heads'],\n",
    "             #                                [attr_val.model, attr_val.input_type, attr_val.embedding_dim, \n",
    "             #                                 attr_val.num_layers, attr_val.num_heads]):\n",
    "             #       config_dict[f'{attr_name}_{subattr}'] = subvalue\n",
    "            #elif attr_name in ['model2d','model3d','model4d','modelfprf',\n",
    "            #                   'linear_warmup_cosine_annealing_lr','cosine_annealing_lr',\n",
    "            #                   'reduce_lr_on_plateau','one_cycle_lr']:\n",
    "            #    pass\n",
    "            #else:\n",
    "            config_dict[attr_name] = getattr(config_class, attr_name)\n",
    "    return config_dict\n",
    "config_dict = config_to_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61b8117-6368-49f0-bab2-1b12bea10ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subkeys = [\"dataset\",\n",
    "           \"max_num_conformers\",\n",
    "           \"target\",\n",
    "           \"train_ratio\",\n",
    "           \"valid_ratio\",\n",
    "           \"seed\",\n",
    "           \"model3d\", #.augmentation\"\n",
    "           \"batch_size\"]\n",
    "config_dict_datamodule = {}\n",
    "for k,v in config_dict.items():\n",
    "    if k in subkeys:\n",
    "        if k==\"model3d\":\n",
    "            config_dict_datamodule[f'{k}_augmentation']=config_dict[k].augmentation\n",
    "        else:\n",
    "            config_dict_datamodule[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24cfce3-1969-43a4-809d-36d81a4c8508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256,\n",
       " 'dataset': 'BDE',\n",
       " 'max_num_conformers': 20,\n",
       " 'model3d_augmentation': True,\n",
       " 'seed': 123,\n",
       " 'target': 'BindingEnergy',\n",
       " 'train_ratio': 0.7,\n",
       " 'valid_ratio': 0.1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict_datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cb75383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--done---\n",
      "79637 training data, 22623 test data and 11838 validation data\n"
     ]
    }
   ],
   "source": [
    "data = DataModule(config_dict_datamodule)\n",
    "data.prepare_data()\n",
    "data.split_compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3edb7560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32))\n"
     ]
    }
   ],
   "source": [
    "model = ModelLM(max_atomic_num=data.max_atomic_num, \n",
    "                whole_dataset = data.dataset, \n",
    "                unique_variables=data.unique_variables, **config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e82ee2b-5cfe-4480-95d4-d6e3a5cd3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model._log_hyperparams = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69530b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PARAMS = 2494977\n"
     ]
    }
   ],
   "source": [
    "print(f'#PARAMS = {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffad2ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLM(\n",
       "  (net): Model3D(\n",
       "    (models): ModuleList(\n",
       "      (0-1): 2 x PaiNN(\n",
       "        (cutoff_fn): CosineCutoff()\n",
       "        (radial_basis): GaussianRBF()\n",
       "        (embedding): Embedding(79, 128, padding_idx=0)\n",
       "        (filter_net): Dense(\n",
       "          in_features=64, out_features=2304, bias=True\n",
       "          (activation): Identity()\n",
       "        )\n",
       "        (interactions): ModuleList(\n",
       "          (0-5): 6 x PaiNNInteraction(\n",
       "            (interatomic_context_net): Sequential(\n",
       "              (0): Dense(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dense(\n",
       "                in_features=128, out_features=384, bias=True\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mixing): ModuleList(\n",
       "          (0-5): 6 x PaiNNMixing(\n",
       "            (intraatomic_context_net): Sequential(\n",
       "              (0): Dense(in_features=256, out_features=128, bias=True)\n",
       "              (1): Dense(\n",
       "                in_features=128, out_features=384, bias=True\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (mu_channel_mix): Dense(\n",
       "              in_features=128, out_features=256, bias=False\n",
       "              (activation): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a20c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = f\"tmp_3d_v4\"\n",
    "\n",
    "dir_load_model = None\n",
    "log_dir_folder = '/mnt/code/logs/'\n",
    "log_dir_folder = os.path.join(log_dir_folder, dir_name)\n",
    "if os.path.exists(log_dir_folder):\n",
    "    if os.path.exists(os.path.join(log_dir_folder, \"last.ckpt\")):\n",
    "        dir_load_model = os.path.join(log_dir_folder, \"last.ckpt\")\n",
    "    csv_path = os.path.join(log_dir_folder, \"metrics.csv\")\n",
    "    while os.path.exists(csv_path):\n",
    "        csv_path = csv_path + '.bak'\n",
    "    if os.path.exists(os.path.join(log_dir_folder, \"metrics.csv\")):\n",
    "        os.rename(os.path.join(log_dir_folder, \"metrics.csv\"), csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50c750fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_monitor = \"val_epoch_loss\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=log_dir_folder,\n",
    "    monitor=metric_to_monitor,\n",
    "    mode = 'min',\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    every_n_epochs=5,\n",
    "    save_weights_only=True,\n",
    "    verbose=True,\n",
    "    filename=\"best-model-{epoch}-{val_epoch_loss:.4f}\",\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = early_stop_callback = EarlyStopping(\n",
    "        monitor=metric_to_monitor,  # The metric you want to monitor\n",
    "        patience=config.patience,  # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=True,\n",
    "        mode='min'  # Minimizing the validation loss\n",
    "    )\n",
    "\n",
    "tb_logger = TensorBoardLogger(log_dir_folder, name=\"tensorbord\")#, version=\"\", default_hp_metric=False)\n",
    "csv_logger = CSVLogger(log_dir_folder, name=\"\", version=\"\")\n",
    "\n",
    "model_params = dict(\n",
    "    devices=1, #args['ngpus'],\n",
    "    accelerator='gpu', #args['accelerator'],\n",
    "    default_root_dir=log_dir_folder, #args['log_dir'],\n",
    "    logger=[tb_logger, csv_logger],\n",
    "    enable_progress_bar=True)\n",
    "\n",
    "\n",
    "model_params.update(dict(\n",
    "    max_epochs=config.num_epochs,#1000,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    #enable_checkpointing=False,\n",
    "    gradient_clip_val=10,#args['clip_norm'],\n",
    "    #precision=\"16-mixed\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843bb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f4d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /mnt/code/logs/tmp_3d_v4/tensorbord\n",
      "/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory /mnt/code/logs/tmp_3d_v4/ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/code/logs/tmp_3d_v4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | net     | Model3D | 2.5 M \n",
      "1 | loss_fn | MSELoss | 0     \n",
      "------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.980     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d876e780df46c2a19caa417190f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved. New best score: 37.467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 21.977 >= min_delta = 0.0. New best score: 15.490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 13.343 >= min_delta = 0.0. New best score: 2.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.839 >= min_delta = 0.0. New best score: 1.308\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**model_params)\n",
    "trainer.fit(model, datamodule=data, ckpt_path=dir_load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d985fe7-6a31-48dc-97a3-6aea72870763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHECKPOINT_EQUALS_CHAR',\n",
       " 'CHECKPOINT_JOIN_CHAR',\n",
       " 'CHECKPOINT_NAME_LAST',\n",
       " 'FILE_EXTENSION',\n",
       " 'STARTING_VERSION',\n",
       " '_ModelCheckpoint__init_ckpt_dir',\n",
       " '_ModelCheckpoint__init_monitor_mode',\n",
       " '_ModelCheckpoint__init_triggers',\n",
       " '_ModelCheckpoint__resolve_ckpt_dir',\n",
       " '_ModelCheckpoint__validate_init_configuration',\n",
       " '_ModelCheckpoint__warn_if_dir_not_empty',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_enable_version_counter',\n",
       " '_every_n_epochs',\n",
       " '_every_n_train_steps',\n",
       " '_find_last_checkpoints',\n",
       " '_format_checkpoint_name',\n",
       " '_fs',\n",
       " '_generate_state_key',\n",
       " '_get_metric_interpolated_filepath_name',\n",
       " '_last_checkpoint_saved',\n",
       " '_last_global_step_saved',\n",
       " '_last_time_checked',\n",
       " '_legacy_state_key',\n",
       " '_link_checkpoint',\n",
       " '_monitor_candidates',\n",
       " '_remove_checkpoint',\n",
       " '_save_checkpoint',\n",
       " '_save_last_checkpoint',\n",
       " '_save_model',\n",
       " '_save_monitor_checkpoint',\n",
       " '_save_none_monitor_checkpoint',\n",
       " '_save_on_train_epoch_end',\n",
       " '_save_topk_checkpoint',\n",
       " '_should_remove_checkpoint',\n",
       " '_should_save_on_train_epoch_end',\n",
       " '_should_skip_saving_checkpoint',\n",
       " '_train_time_interval',\n",
       " '_update_best_and_save',\n",
       " 'auto_insert_metric_name',\n",
       " 'best_k_models',\n",
       " 'best_model_path',\n",
       " 'best_model_score',\n",
       " 'check_monitor_top_k',\n",
       " 'current_score',\n",
       " 'dirpath',\n",
       " 'every_n_epochs',\n",
       " 'file_exists',\n",
       " 'filename',\n",
       " 'format_checkpoint_name',\n",
       " 'kth_best_model_path',\n",
       " 'kth_value',\n",
       " 'last_model_path',\n",
       " 'load_state_dict',\n",
       " 'log',\n",
       " 'log_dict',\n",
       " 'mode',\n",
       " 'monitor',\n",
       " 'on_after_backward',\n",
       " 'on_before_backward',\n",
       " 'on_before_optimizer_step',\n",
       " 'on_before_zero_grad',\n",
       " 'on_exception',\n",
       " 'on_fit_end',\n",
       " 'on_fit_start',\n",
       " 'on_load_checkpoint',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_batch_start',\n",
       " 'on_predict_end',\n",
       " 'on_predict_epoch_end',\n",
       " 'on_predict_epoch_start',\n",
       " 'on_predict_start',\n",
       " 'on_sanity_check_end',\n",
       " 'on_sanity_check_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_batch_start',\n",
       " 'on_test_end',\n",
       " 'on_test_epoch_end',\n",
       " 'on_test_epoch_start',\n",
       " 'on_test_start',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_batch_start',\n",
       " 'on_train_end',\n",
       " 'on_train_epoch_end',\n",
       " 'on_train_epoch_start',\n",
       " 'on_train_start',\n",
       " 'on_validation_batch_end',\n",
       " 'on_validation_batch_start',\n",
       " 'on_validation_end',\n",
       " 'on_validation_epoch_end',\n",
       " 'on_validation_epoch_start',\n",
       " 'on_validation_start',\n",
       " 'save_last',\n",
       " 'save_top_k',\n",
       " 'save_weights_only',\n",
       " 'setup',\n",
       " 'state_dict',\n",
       " 'state_key',\n",
       " 'teardown',\n",
       " 'to_yaml',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98760096-e74b-4ba8-b072-9d43d749c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_candidates = checkpoint_callback._monitor_candidates(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9907a93e-cca3-4531-b03f-835078dd6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_callback.on_train_epoch_end(trainer, trainer.lightning_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "879d4a72-08fa-4ad2-bd7c-4feba112afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_callback._save_last_checkpoint(trainer, monitor_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba5b9cc4-d3a3-4299-b96c-289dfc605f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = checkpoint_callback.format_checkpoint_name(monitor_candidates, checkpoint_callback.CHECKPOINT_NAME_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af8bbdd9-87cc-40b3-a4bd-c51c6c1fa067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/code/logs/tmp_3d_v3/last.ckpt'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2585f9ce-b987-459b-9517-80b74b313596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback.save_weights_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79f187f7-bd3a-4203-a69d-32be51cac6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_callback._save_checkpoint(trainer, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0435485-b25d-4ed8-a4f2-8ad2786ba436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_checkpoint(filepath, checkpoint_callback.save_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "370d4ca6-b286-4f08-b8d6-4aa4f2389ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = trainer._checkpoint_connector.dump_checkpoint(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4737b286-2388-4700-b7c7-f4857c071507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 0,\n",
       " 'global_step': 17,\n",
       " 'pytorch-lightning_version': '2.2.4',\n",
       " 'state_dict': OrderedDict([('net.models.0.cutoff_fn.cutoff', tensor([12.])),\n",
       "              ('net.models.0.radial_basis.widths',\n",
       "               tensor([0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905])),\n",
       "              ('net.models.0.radial_basis.offsets',\n",
       "               tensor([ 0.0000,  0.1905,  0.3810,  0.5714,  0.7619,  0.9524,  1.1429,  1.3333,\n",
       "                        1.5238,  1.7143,  1.9048,  2.0952,  2.2857,  2.4762,  2.6667,  2.8571,\n",
       "                        3.0476,  3.2381,  3.4286,  3.6190,  3.8095,  4.0000,  4.1905,  4.3810,\n",
       "                        4.5714,  4.7619,  4.9524,  5.1429,  5.3333,  5.5238,  5.7143,  5.9048,\n",
       "                        6.0952,  6.2857,  6.4762,  6.6667,  6.8571,  7.0476,  7.2381,  7.4286,\n",
       "                        7.6190,  7.8095,  8.0000,  8.1905,  8.3810,  8.5714,  8.7619,  8.9524,\n",
       "                        9.1429,  9.3333,  9.5238,  9.7143,  9.9048, 10.0952, 10.2857, 10.4762,\n",
       "                       10.6667, 10.8571, 11.0476, 11.2381, 11.4286, 11.6190, 11.8095, 12.0000])),\n",
       "              ('net.models.0.embedding.weight',\n",
       "               tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                       [-0.2889, -0.5668,  0.2041,  ...,  0.4086,  0.0659, -0.7352],\n",
       "                       [ 0.1309, -0.0077, -0.1093,  ..., -0.2402, -0.8083, -0.4777],\n",
       "                       ...,\n",
       "                       [-0.5771,  1.1482, -0.4036,  ...,  0.4707, -1.8326, -0.0154],\n",
       "                       [-1.2592,  0.1146, -1.6867,  ...,  0.4969, -0.5850, -0.9559],\n",
       "                       [-0.7042,  0.9125,  0.2693,  ..., -1.3160, -0.0431,  0.7255]])),\n",
       "              ('net.models.0.filter_net.weight',\n",
       "               tensor([[ 0.0138,  0.0166, -0.0148,  ..., -0.0297, -0.0025,  0.0017],\n",
       "                       [ 0.0295, -0.0219, -0.0418,  ..., -0.0494, -0.0579,  0.0380],\n",
       "                       [ 0.0312, -0.0084,  0.0148,  ..., -0.0035, -0.0551, -0.0117],\n",
       "                       ...,\n",
       "                       [ 0.0207,  0.0458, -0.0460,  ..., -0.0354,  0.0101, -0.0485],\n",
       "                       [ 0.0187,  0.0356, -0.0091,  ..., -0.0143, -0.0061,  0.0129],\n",
       "                       [-0.0051, -0.0151, -0.0435,  ..., -0.0169, -0.0354, -0.0430]])),\n",
       "              ('net.models.0.filter_net.bias',\n",
       "               tensor([ 0.0047, -0.0075, -0.0128,  ...,  0.0093,  0.0067, -0.0116])),\n",
       "              ('net.models.0.interactions.0.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.1469,  0.0840, -0.0850,  ..., -0.0469,  0.0712,  0.0771],\n",
       "                       [-0.0687, -0.1520,  0.0254,  ..., -0.0181, -0.1202,  0.0885],\n",
       "                       [ 0.0099,  0.0806,  0.0808,  ..., -0.1540, -0.1489,  0.0185],\n",
       "                       ...,\n",
       "                       [ 0.1509, -0.1333,  0.1274,  ...,  0.0213, -0.1324,  0.1462],\n",
       "                       [-0.1014, -0.0646, -0.0397,  ...,  0.0456,  0.0100,  0.1391],\n",
       "                       [ 0.1355,  0.1081,  0.0586,  ..., -0.0172,  0.0174, -0.1527]])),\n",
       "              ('net.models.0.interactions.0.interatomic_context_net.0.bias',\n",
       "               tensor([-9.4401e-03, -2.1139e-05, -2.9731e-03, -1.2373e-03,  9.1660e-04,\n",
       "                       -1.0597e-02, -1.1698e-02, -8.4611e-03,  2.5262e-03,  1.7867e-03,\n",
       "                       -1.0849e-02,  3.0380e-03,  5.1440e-03, -1.4851e-03,  7.0580e-04,\n",
       "                       -2.4025e-03,  3.0678e-03, -9.3439e-03, -1.1805e-02, -7.4336e-03,\n",
       "                       -2.4789e-03,  3.0491e-03, -3.7755e-03, -6.3354e-03, -4.9268e-03,\n",
       "                        3.6976e-03,  6.4163e-04, -1.4642e-04, -6.2415e-03, -6.6437e-03,\n",
       "                       -1.0033e-02, -2.6950e-03, -7.4214e-05,  3.4996e-03, -6.2236e-03,\n",
       "                       -9.6297e-03, -5.4924e-03, -3.5810e-04, -5.0294e-03, -9.7253e-03,\n",
       "                       -1.6324e-02, -1.7380e-03, -9.2261e-03,  2.9801e-03, -3.3332e-03,\n",
       "                       -5.6943e-03, -2.0220e-03, -3.4836e-03, -5.8257e-03, -1.1449e-02,\n",
       "                       -7.0183e-04, -8.0407e-03, -1.8834e-03, -5.9116e-03,  1.4513e-03,\n",
       "                       -1.0543e-02,  3.5709e-04, -6.3603e-03,  1.5113e-02,  4.8681e-03,\n",
       "                       -1.4905e-03,  3.9714e-03, -3.4214e-03, -1.4248e-03, -1.0556e-02,\n",
       "                       -9.4102e-03,  1.9582e-03, -4.0821e-03, -1.2872e-02, -6.2993e-03,\n",
       "                       -5.0087e-03, -1.7246e-02, -3.9781e-03, -6.1558e-03, -5.1161e-03,\n",
       "                       -4.2974e-03, -6.3038e-03, -1.1112e-02, -3.1006e-03,  9.6674e-04,\n",
       "                       -3.8865e-03, -3.4406e-03, -2.4453e-03, -6.4022e-03, -4.0440e-03,\n",
       "                        5.4521e-03,  1.1622e-02, -4.4730e-03, -4.0255e-03, -1.7247e-03,\n",
       "                       -2.3259e-03,  1.0895e-03,  2.5601e-03,  3.7743e-04,  1.0873e-02,\n",
       "                       -7.9867e-03,  7.8038e-04, -3.0800e-03, -6.4166e-03,  1.8101e-03,\n",
       "                        8.9563e-04, -7.6557e-03, -2.6474e-03, -3.9687e-03, -6.0760e-03,\n",
       "                       -1.3874e-02, -1.3251e-02, -1.7780e-02, -4.8600e-03,  1.1578e-02,\n",
       "                        5.0345e-04,  1.8684e-03, -3.8574e-03, -3.3469e-03, -7.2357e-04,\n",
       "                       -3.8283e-03, -1.0710e-04, -2.3070e-03, -6.9610e-03, -8.7807e-03,\n",
       "                       -4.1221e-03,  7.5003e-03, -6.5523e-03, -4.5711e-03,  9.0354e-05,\n",
       "                        5.1620e-04, -8.9660e-03, -1.0537e-02])),\n",
       "              ('net.models.0.interactions.0.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0333, -0.0452,  0.0113,  ..., -0.0758,  0.0214, -0.1071],\n",
       "                       [ 0.0668, -0.0038, -0.0090,  ..., -0.0270,  0.0539, -0.1022],\n",
       "                       [-0.0302,  0.0813, -0.1055,  ..., -0.0335,  0.0218, -0.0242],\n",
       "                       ...,\n",
       "                       [-0.0174,  0.0563,  0.1032,  ..., -0.0861,  0.0553, -0.0293],\n",
       "                       [ 0.0167, -0.0666, -0.0325,  ...,  0.0120,  0.0735, -0.0230],\n",
       "                       [-0.0544, -0.0388, -0.1076,  ..., -0.1061, -0.0149,  0.0698]])),\n",
       "              ('net.models.0.interactions.0.interatomic_context_net.1.bias',\n",
       "               tensor([-4.1185e-03,  3.4807e-03,  5.0015e-03, -7.8935e-04,  1.3109e-02,\n",
       "                        5.7324e-03, -2.8094e-03, -6.2321e-03,  7.2435e-04, -4.9896e-03,\n",
       "                        2.7082e-03,  5.8076e-04,  2.2775e-03, -1.0446e-02, -3.0943e-03,\n",
       "                       -7.2850e-03, -4.3086e-04,  8.5424e-03, -1.7739e-04, -2.4227e-03,\n",
       "                       -4.9183e-03, -6.6611e-03, -2.6404e-03, -1.6658e-04, -2.2447e-03,\n",
       "                       -8.9027e-03,  5.1315e-03,  4.4705e-03,  1.0287e-02,  2.0978e-03,\n",
       "                       -3.2935e-04,  1.2115e-03, -1.0113e-02, -5.7016e-03, -2.0117e-03,\n",
       "                        6.9212e-03,  5.0661e-03, -8.0462e-04, -1.2931e-03, -2.8142e-03,\n",
       "                       -8.0192e-03,  2.4114e-03, -5.2193e-04,  1.1284e-02, -1.0531e-02,\n",
       "                        4.8231e-03, -1.9934e-03,  9.1970e-06, -5.4403e-03,  9.9221e-03,\n",
       "                        2.4496e-04, -3.2518e-04,  7.5876e-03,  1.2844e-02,  4.1358e-03,\n",
       "                        1.1237e-03,  1.0358e-02, -1.0344e-02,  5.8258e-03, -8.0241e-04,\n",
       "                       -4.4389e-03,  9.7125e-04, -4.7124e-04, -1.4398e-02,  1.1063e-02,\n",
       "                       -6.4085e-03,  1.7952e-03,  5.7534e-04, -1.9575e-03,  6.3254e-03,\n",
       "                        2.5900e-03, -8.9456e-03, -3.2739e-03,  9.3670e-03,  8.2083e-03,\n",
       "                        3.3269e-04,  8.5348e-03,  5.5366e-03, -1.6621e-03, -6.4086e-03,\n",
       "                       -5.2128e-03,  5.0263e-03,  4.1860e-03,  2.3910e-03,  8.0044e-03,\n",
       "                        1.4019e-02, -2.2020e-03, -4.4268e-03,  4.9381e-03,  9.3683e-03,\n",
       "                       -5.6178e-03,  9.7682e-03, -7.8459e-05, -3.2836e-03, -1.0189e-03,\n",
       "                        8.0456e-03, -6.7282e-03, -4.1254e-03,  4.9988e-03,  8.4907e-03,\n",
       "                       -5.8090e-03, -4.5343e-03, -4.3788e-03, -3.9976e-03,  4.5335e-03,\n",
       "                        6.2735e-03, -6.9419e-04, -7.1064e-04, -2.8025e-03,  7.4040e-03,\n",
       "                        1.2840e-03, -5.1171e-03,  1.5340e-04,  6.4399e-03, -5.1419e-04,\n",
       "                       -2.2231e-03,  9.8215e-03,  8.1375e-04, -7.6384e-03,  2.9878e-03,\n",
       "                        3.0730e-04,  5.8554e-03,  9.2524e-03,  6.0167e-03, -6.9167e-03,\n",
       "                       -9.2981e-03,  4.9037e-03,  2.1800e-03, -1.5967e-02,  8.7098e-03,\n",
       "                       -2.1407e-02,  1.3393e-02,  6.2795e-03,  2.9634e-03, -7.0967e-03,\n",
       "                       -1.5372e-03,  2.6616e-04, -9.5714e-03,  7.1746e-03,  3.6374e-03,\n",
       "                        7.2212e-03,  5.2083e-03,  1.2383e-02,  5.4451e-03, -2.2856e-03,\n",
       "                       -1.8555e-02, -1.6226e-03, -9.5594e-04, -1.7475e-03, -3.0355e-03,\n",
       "                       -1.1214e-02, -4.2792e-03, -7.9321e-03, -7.6011e-03, -8.0194e-03,\n",
       "                       -6.1183e-04,  8.9267e-03,  4.5543e-04, -7.1109e-03, -1.2896e-02,\n",
       "                       -1.6668e-03, -8.8818e-03, -9.0546e-03,  8.4176e-03,  3.3354e-03,\n",
       "                        5.0945e-03,  1.2745e-02, -9.4244e-03,  6.6921e-03,  2.6327e-03,\n",
       "                       -9.7219e-04,  4.0776e-03, -1.9625e-03, -8.5674e-03,  2.2440e-03,\n",
       "                        3.6244e-03,  9.7563e-03,  9.8163e-03,  1.1330e-02,  8.8934e-03,\n",
       "                        1.2876e-02,  2.8625e-03, -8.4940e-03,  1.4933e-02,  3.0506e-03,\n",
       "                       -9.9983e-03,  7.7095e-03, -6.3551e-03,  1.0647e-03, -1.6260e-03,\n",
       "                        8.4900e-03, -1.3800e-03, -2.6046e-03,  9.1888e-03,  1.9380e-03,\n",
       "                        4.0410e-03,  2.2169e-03,  1.0209e-02,  2.8011e-03, -2.0665e-03,\n",
       "                       -6.7702e-04, -1.0759e-03,  1.0177e-02,  4.3065e-03,  4.8574e-03,\n",
       "                       -2.1235e-03,  2.0383e-03, -1.0657e-02,  3.8127e-03, -1.6542e-03,\n",
       "                        2.9892e-03, -3.1886e-03, -3.2888e-03, -2.5991e-03, -1.0746e-02,\n",
       "                        6.6888e-03, -8.6816e-03,  5.7350e-05,  1.5916e-02, -5.6242e-03,\n",
       "                       -1.4384e-03, -3.4616e-05,  2.8776e-03,  2.0867e-03, -1.1004e-03,\n",
       "                        1.6845e-02, -1.7813e-03,  9.2415e-03, -1.9089e-03,  1.3683e-02,\n",
       "                       -3.9907e-03,  6.4502e-03,  1.3916e-02, -1.8047e-02, -2.4488e-04,\n",
       "                       -4.3700e-03, -1.5037e-02, -1.3932e-02,  5.2236e-03, -9.0137e-03,\n",
       "                        4.4243e-03,  1.5211e-02,  1.1191e-02, -3.2623e-03,  1.1480e-03,\n",
       "                       -8.1752e-03,  3.7816e-03,  1.8239e-03, -9.1132e-03, -8.3233e-03,\n",
       "                        1.0179e-02,  1.2400e-03, -5.1327e-03, -3.1005e-03,  7.1168e-03,\n",
       "                        6.5729e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])),\n",
       "              ('net.models.0.interactions.1.interatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0852, -0.0059, -0.0003,  ...,  0.0802,  0.0407,  0.0630],\n",
       "                       [ 0.1349, -0.0925, -0.1345,  ..., -0.0768,  0.0697,  0.1388],\n",
       "                       [-0.0984,  0.0271,  0.0264,  ...,  0.0838,  0.0659,  0.1297],\n",
       "                       ...,\n",
       "                       [-0.0310, -0.1206,  0.1396,  ...,  0.0799, -0.1457, -0.0956],\n",
       "                       [-0.0673, -0.0404, -0.0786,  ..., -0.0740,  0.1414,  0.0405],\n",
       "                       [ 0.0267,  0.0107, -0.0457,  ...,  0.0677, -0.1123,  0.1229]])),\n",
       "              ('net.models.0.interactions.1.interatomic_context_net.0.bias',\n",
       "               tensor([-0.0085,  0.0094, -0.0038,  0.0035, -0.0102, -0.0058, -0.0004, -0.0052,\n",
       "                       -0.0163, -0.0009,  0.0064,  0.0030,  0.0068, -0.0003, -0.0019,  0.0137,\n",
       "                       -0.0035, -0.0028, -0.0023, -0.0039, -0.0074,  0.0017,  0.0056,  0.0098,\n",
       "                       -0.0112, -0.0089, -0.0011, -0.0007, -0.0067,  0.0063, -0.0126,  0.0038,\n",
       "                       -0.0090,  0.0003,  0.0082, -0.0057,  0.0021, -0.0075, -0.0049, -0.0009,\n",
       "                       -0.0033, -0.0045, -0.0072, -0.0039,  0.0044, -0.0017,  0.0019, -0.0065,\n",
       "                        0.0003,  0.0026, -0.0058,  0.0053, -0.0022, -0.0053, -0.0106, -0.0035,\n",
       "                       -0.0110, -0.0007,  0.0014,  0.0042, -0.0025, -0.0075, -0.0097, -0.0055,\n",
       "                        0.0038, -0.0032,  0.0013, -0.0046,  0.0028, -0.0061, -0.0020, -0.0097,\n",
       "                       -0.0024, -0.0105,  0.0008, -0.0013, -0.0174, -0.0115, -0.0039,  0.0088,\n",
       "                       -0.0001, -0.0020,  0.0063,  0.0049, -0.0096, -0.0129,  0.0026,  0.0022,\n",
       "                        0.0065,  0.0094,  0.0031, -0.0032, -0.0089, -0.0033, -0.0044,  0.0005,\n",
       "                        0.0044, -0.0004, -0.0049,  0.0097,  0.0066, -0.0017, -0.0018, -0.0058,\n",
       "                        0.0035, -0.0053, -0.0137, -0.0098,  0.0009, -0.0093, -0.0078,  0.0013,\n",
       "                       -0.0058,  0.0070, -0.0032, -0.0061, -0.0041, -0.0043, -0.0002,  0.0048,\n",
       "                       -0.0106, -0.0028, -0.0004, -0.0049, -0.0141, -0.0003, -0.0141,  0.0061])),\n",
       "              ('net.models.0.interactions.1.interatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0983, -0.0143,  0.0098,  ...,  0.0703, -0.0322, -0.0865],\n",
       "                       [ 0.0887,  0.0990, -0.1009,  ...,  0.0403, -0.0019,  0.0177],\n",
       "                       [ 0.0496,  0.0709, -0.0501,  ...,  0.0579,  0.0078,  0.0631],\n",
       "                       ...,\n",
       "                       [-0.0306,  0.0695,  0.0697,  ...,  0.0735, -0.0168,  0.0528],\n",
       "                       [ 0.0207, -0.1025,  0.0067,  ..., -0.0204,  0.0762,  0.0820],\n",
       "                       [-0.0289,  0.0262,  0.0899,  ..., -0.0701,  0.0357, -0.0572]])),\n",
       "              ('net.models.0.interactions.1.interatomic_context_net.1.bias',\n",
       "               tensor([-3.7008e-03,  7.8720e-03,  3.2360e-03,  9.0555e-03, -3.0978e-03,\n",
       "                        2.3236e-03, -4.3470e-03,  4.7035e-03,  2.4690e-03, -2.2659e-04,\n",
       "                        1.0365e-02, -1.3139e-03,  2.5295e-03, -6.2932e-03,  6.5490e-03,\n",
       "                        1.0562e-03, -4.4826e-03, -6.6397e-03,  1.0724e-02, -1.1180e-02,\n",
       "                       -2.1097e-03, -2.1724e-03,  3.0763e-03,  7.9619e-03, -3.7828e-03,\n",
       "                       -1.5022e-02, -8.7039e-03, -2.4545e-03,  5.0744e-04,  4.7359e-03,\n",
       "                       -7.9417e-03, -1.5460e-03, -5.8090e-03,  4.0704e-03,  7.3529e-03,\n",
       "                        2.3458e-03,  8.0526e-03,  3.9583e-03, -6.4074e-03, -9.1137e-04,\n",
       "                       -1.3091e-02,  1.9131e-03,  7.5437e-03, -4.5874e-03,  4.4395e-03,\n",
       "                       -1.4117e-03,  1.4157e-02, -2.1377e-03,  9.5014e-03, -5.3959e-04,\n",
       "                        9.1404e-03,  3.3900e-03, -2.1052e-03, -3.9412e-03, -7.4547e-03,\n",
       "                        3.6994e-03,  9.2186e-03,  9.6783e-03,  5.0847e-03, -7.8573e-03,\n",
       "                        1.1266e-02, -1.1203e-03, -1.1581e-03,  2.0060e-03,  9.1581e-03,\n",
       "                        7.2650e-03, -3.7156e-03,  4.1444e-04,  1.0428e-02, -2.7022e-03,\n",
       "                        5.1073e-03, -8.2731e-04,  3.1388e-03, -4.6189e-03, -1.7241e-03,\n",
       "                        1.4942e-03, -4.9280e-03,  7.2189e-03, -4.5709e-03, -1.4482e-02,\n",
       "                        4.9444e-03,  3.3431e-03,  1.0137e-03, -7.9892e-03, -7.9480e-03,\n",
       "                        8.4576e-05,  3.8662e-03,  1.5480e-03,  2.8890e-03,  1.2993e-02,\n",
       "                        1.4005e-02,  3.0963e-03,  1.2052e-03, -1.0373e-03, -6.7566e-03,\n",
       "                       -5.2564e-03, -8.8461e-03,  2.2730e-03, -3.3733e-03,  1.3780e-02,\n",
       "                       -6.2329e-03,  5.9038e-03,  5.2018e-03, -9.8301e-04, -3.0324e-03,\n",
       "                       -8.6507e-03, -9.5658e-03,  9.1594e-03,  6.2678e-03, -7.6898e-03,\n",
       "                       -1.0508e-02,  6.9127e-03, -1.2934e-03,  6.4953e-03, -1.2677e-03,\n",
       "                       -1.2906e-03, -1.8532e-02, -6.9246e-03, -6.9750e-03, -5.8947e-03,\n",
       "                        9.7376e-03,  2.4287e-03,  9.7221e-03, -6.7525e-03, -2.8100e-04,\n",
       "                       -9.8731e-03,  6.8800e-03,  3.0704e-03,  6.5700e-03,  5.3489e-03,\n",
       "                        8.8446e-03,  1.7013e-03, -3.6326e-03,  1.0267e-02, -1.9321e-03,\n",
       "                       -8.6616e-03,  1.0652e-02, -4.7830e-03, -1.1570e-02, -4.3763e-03,\n",
       "                       -4.2060e-03,  1.9435e-03, -1.2531e-02,  2.0959e-03,  3.6956e-03,\n",
       "                        1.2983e-03,  9.6707e-03, -3.6115e-03, -1.1683e-02, -1.4112e-02,\n",
       "                       -4.3456e-03, -1.0075e-03,  5.5508e-03, -8.8046e-03, -6.5469e-03,\n",
       "                       -1.6724e-02,  8.7812e-03,  6.8206e-04,  1.8869e-03,  2.2982e-03,\n",
       "                       -3.8774e-04, -1.0716e-02,  1.4037e-02,  2.9458e-03,  1.2862e-02,\n",
       "                       -2.9271e-03,  4.2422e-03,  9.5660e-03, -2.6688e-03, -6.4513e-03,\n",
       "                       -4.3283e-03,  1.8793e-02,  4.0914e-03,  3.5103e-03, -1.8103e-04,\n",
       "                        1.0774e-02, -6.5086e-03,  1.1123e-02, -8.2028e-04, -1.7831e-02,\n",
       "                       -2.6680e-03, -1.0078e-02,  3.7302e-04, -1.2904e-02,  1.3411e-02,\n",
       "                       -2.4407e-03,  1.1139e-04, -6.8754e-04, -7.1232e-04, -9.6609e-03,\n",
       "                       -5.8360e-03,  8.4844e-03,  1.2210e-02,  5.5481e-03,  9.1993e-04,\n",
       "                       -6.0967e-03, -8.8812e-03,  1.1475e-03, -8.8686e-03,  4.4476e-03,\n",
       "                        8.6729e-03,  4.1407e-03, -4.9294e-03, -2.4628e-03, -1.0180e-02,\n",
       "                       -6.6579e-03, -5.6286e-04,  3.0621e-04,  8.4561e-04,  5.3353e-03,\n",
       "                       -1.5122e-02, -2.9728e-03,  1.2121e-04,  4.5603e-03, -4.5534e-03,\n",
       "                       -1.8641e-02,  3.1474e-03, -2.0771e-03, -1.1748e-03,  1.1725e-02,\n",
       "                       -8.6376e-03,  4.9934e-04, -1.0379e-03,  7.7633e-03, -2.6342e-04,\n",
       "                       -4.5558e-03,  2.8005e-03,  1.0126e-02, -1.1431e-02,  1.0324e-02,\n",
       "                        3.9535e-03, -3.2286e-04,  2.2339e-03,  9.2223e-03, -6.3393e-04,\n",
       "                        1.3732e-02,  9.7859e-04, -1.6197e-03, -1.5004e-02, -4.7015e-03,\n",
       "                        7.6827e-03, -2.2766e-03,  1.3001e-02,  2.0610e-04, -4.3062e-04,\n",
       "                       -4.6101e-03, -2.4687e-03,  7.7278e-03, -1.0953e-02, -1.0834e-04,\n",
       "                        2.7073e-03,  1.3230e-02,  2.6672e-03,  5.5285e-03, -6.5740e-04,\n",
       "                       -3.6626e-03, -2.0205e-02,  9.0973e-03, -1.1968e-02,  1.9024e-02,\n",
       "                       -5.3356e-03,  4.1875e-03,  7.6128e-03,  1.1865e-02, -1.5347e-02,\n",
       "                        5.6092e-03, -3.2513e-03, -1.5746e-02, -7.6490e-03,  8.9808e-05,\n",
       "                       -9.8879e-03, -1.3614e-03, -4.8708e-03, -1.3954e-02,  1.5547e-02,\n",
       "                       -1.5663e-02, -4.0400e-03, -3.5113e-03, -7.6580e-03, -7.4842e-03,\n",
       "                        1.4582e-03,  3.3224e-03, -7.0255e-03,  9.8279e-03,  2.1316e-03,\n",
       "                       -2.5529e-03, -7.4964e-03,  4.9526e-03,  1.1018e-03, -1.8236e-03,\n",
       "                       -5.3022e-03,  4.2987e-03, -5.4304e-03,  5.9948e-03, -1.2366e-02,\n",
       "                       -4.1127e-03,  1.8733e-03,  4.5609e-03,  5.6922e-03,  1.7011e-03,\n",
       "                       -1.2958e-02, -1.3662e-03,  1.4417e-03,  1.2776e-03, -4.4449e-03,\n",
       "                        8.0792e-03,  2.4011e-03, -1.2867e-02, -1.5046e-03,  1.3598e-03,\n",
       "                       -6.6311e-03, -6.0509e-03, -3.1591e-03, -4.6109e-03,  8.6968e-03,\n",
       "                       -9.9773e-03, -6.5179e-03, -9.0940e-04, -8.8965e-03, -4.3777e-03,\n",
       "                       -3.7526e-03,  1.2575e-02,  1.5102e-02,  2.2562e-03,  9.1938e-04,\n",
       "                        1.5923e-03, -1.5917e-03, -6.8190e-03,  5.5946e-03, -7.6901e-03,\n",
       "                       -6.1605e-03,  8.8322e-04,  7.1072e-03, -6.5297e-05, -5.1215e-03,\n",
       "                        6.0273e-03,  2.1690e-03, -4.4830e-03, -1.9319e-03,  1.3798e-02,\n",
       "                       -1.1868e-02, -2.6158e-04,  2.2992e-03,  5.8411e-03,  4.0744e-03,\n",
       "                        1.3938e-02, -2.9783e-03, -1.0666e-02, -1.1485e-02,  3.8020e-03,\n",
       "                        9.8571e-03,  1.2149e-02, -5.9372e-03, -3.3639e-03,  6.5046e-03,\n",
       "                        8.9404e-03, -5.5097e-03,  1.4737e-02,  2.4809e-03,  1.0784e-02,\n",
       "                        1.6394e-02, -1.6292e-02, -2.6917e-03, -2.2414e-02, -6.2100e-03,\n",
       "                        8.7880e-03,  2.8728e-03,  3.7602e-03,  5.8515e-04, -1.6503e-02,\n",
       "                        1.4653e-02, -3.8781e-03, -2.7887e-03, -2.5663e-03, -3.9573e-03,\n",
       "                       -1.7569e-03,  8.5432e-05, -7.1933e-03, -1.1376e-02,  8.1858e-03,\n",
       "                        2.9314e-03,  3.2712e-03, -1.1030e-02,  1.2451e-02])),\n",
       "              ('net.models.0.interactions.2.interatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0240,  0.0323, -0.1331,  ...,  0.0686,  0.1556,  0.0314],\n",
       "                       [-0.0061, -0.1604, -0.1288,  ..., -0.0288,  0.0180, -0.0909],\n",
       "                       [-0.1138,  0.1280,  0.0857,  ...,  0.0698, -0.0417,  0.0337],\n",
       "                       ...,\n",
       "                       [-0.1059,  0.1180, -0.0557,  ..., -0.0536, -0.1395,  0.1678],\n",
       "                       [ 0.0853,  0.0763,  0.0897,  ..., -0.0114,  0.0364, -0.0513],\n",
       "                       [-0.0803,  0.1179,  0.0431,  ..., -0.0181,  0.1469, -0.1449]])),\n",
       "              ('net.models.0.interactions.2.interatomic_context_net.0.bias',\n",
       "               tensor([ 4.9414e-03,  6.3207e-03, -2.8259e-04, -1.2010e-04,  8.6560e-03,\n",
       "                        8.6123e-03, -5.9845e-03, -1.5567e-02, -7.9418e-03, -2.6825e-03,\n",
       "                        4.7021e-03, -1.0940e-02, -6.0659e-03,  5.8429e-03,  9.4332e-03,\n",
       "                       -1.8197e-02,  3.6702e-03, -1.5003e-03, -6.7322e-03, -6.0148e-03,\n",
       "                        1.2971e-03, -7.7873e-05, -1.2422e-02, -9.2607e-03, -9.8899e-03,\n",
       "                        3.5035e-03,  9.4009e-04, -5.2734e-03, -3.3702e-03, -3.2700e-03,\n",
       "                       -2.3251e-03, -1.3918e-02, -5.5210e-03,  1.4587e-03, -1.1367e-03,\n",
       "                       -1.6961e-03, -6.2051e-03, -4.9921e-03, -1.5416e-03,  2.7020e-03,\n",
       "                        3.7928e-04, -2.9812e-03, -1.1177e-02, -1.0729e-02, -3.1824e-03,\n",
       "                       -6.3292e-03,  5.6097e-03, -1.2404e-02, -1.1129e-02,  3.4238e-03,\n",
       "                       -8.6657e-03, -1.4924e-03, -7.9005e-03,  7.3550e-03,  5.9798e-03,\n",
       "                       -7.3696e-03, -9.4496e-03, -2.1724e-03, -1.1632e-03,  6.2596e-03,\n",
       "                        8.0311e-03,  3.1306e-03,  4.0176e-03, -3.4126e-03, -5.7615e-03,\n",
       "                       -4.4699e-03, -8.5399e-03, -1.3579e-03, -5.6034e-03, -8.0024e-03,\n",
       "                       -7.4044e-03, -1.0557e-02,  7.9930e-03,  1.4588e-03, -1.0121e-02,\n",
       "                        2.4859e-04, -9.6953e-03,  2.7545e-03, -9.2137e-04, -1.5095e-02,\n",
       "                       -6.2481e-04,  3.8165e-03,  1.7114e-03, -1.6928e-02, -1.0701e-02,\n",
       "                       -2.6308e-03,  1.0874e-02, -4.4368e-03,  6.0128e-04,  3.7728e-03,\n",
       "                       -1.2491e-02, -3.3661e-03,  1.0160e-02,  2.6308e-03,  2.4639e-03,\n",
       "                       -1.1525e-02,  4.2788e-03,  2.0640e-04,  1.4630e-03, -2.9045e-03,\n",
       "                       -2.7946e-03, -3.2527e-03, -8.4967e-03, -9.6555e-03, -8.5923e-04,\n",
       "                       -2.2424e-03,  1.6847e-03, -9.4191e-03, -4.8832e-03,  5.3814e-03,\n",
       "                        3.4468e-03, -5.0243e-03,  4.0432e-03, -5.3783e-03,  2.0329e-03,\n",
       "                       -2.4089e-03, -2.1897e-03, -7.5254e-03, -9.2401e-03, -2.4359e-03,\n",
       "                        3.9493e-04, -1.0774e-03,  6.8008e-05,  5.6126e-03, -1.3802e-03,\n",
       "                        5.1818e-03, -8.8004e-03, -2.3955e-04])),\n",
       "              ('net.models.0.interactions.2.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0285, -0.0559,  0.0406,  ...,  0.1098, -0.0897, -0.0761],\n",
       "                       [ 0.0798, -0.0197,  0.1010,  ...,  0.0185,  0.0496,  0.0140],\n",
       "                       [ 0.0180,  0.0777, -0.0860,  ..., -0.0769,  0.0569, -0.0188],\n",
       "                       ...,\n",
       "                       [ 0.0384, -0.0489,  0.0716,  ..., -0.0649,  0.0707, -0.0785],\n",
       "                       [ 0.0757, -0.0374, -0.0280,  ...,  0.1126,  0.0866,  0.0025],\n",
       "                       [ 0.0763,  0.0211, -0.0681,  ..., -0.0890,  0.0439,  0.1106]])),\n",
       "              ('net.models.0.interactions.2.interatomic_context_net.1.bias',\n",
       "               tensor([-6.1820e-03,  4.4357e-03,  5.0304e-03, -2.3861e-03, -1.2104e-02,\n",
       "                       -2.4567e-03,  3.7245e-03,  9.5404e-04,  2.1605e-03, -1.9890e-03,\n",
       "                       -1.5190e-02,  2.9692e-03,  2.6928e-03, -7.4950e-03, -1.7165e-03,\n",
       "                       -3.1512e-03,  1.9520e-03,  1.0892e-03,  7.4393e-03,  3.0799e-03,\n",
       "                       -4.4780e-03,  4.0984e-03,  1.1035e-02, -5.4747e-03, -5.2347e-03,\n",
       "                        4.6665e-03, -2.1916e-03,  7.3826e-05, -7.6495e-04, -4.5807e-03,\n",
       "                        2.9980e-03,  6.3558e-03,  7.2144e-03, -3.3652e-03,  9.8695e-03,\n",
       "                       -6.0466e-05,  7.7832e-04,  2.0361e-03, -9.4623e-03,  3.8859e-03,\n",
       "                       -3.1926e-03,  3.5258e-03, -1.4632e-04, -2.0618e-03, -1.0930e-02,\n",
       "                       -9.0300e-03,  9.9085e-03,  3.2471e-03,  1.5061e-03, -4.1663e-03,\n",
       "                        2.9269e-03, -8.1675e-05,  4.4675e-03, -3.9896e-03,  1.7663e-03,\n",
       "                        4.1676e-03, -1.5106e-02,  2.3192e-03, -1.9752e-03,  4.2674e-03,\n",
       "                        1.4012e-02,  2.4603e-03,  3.3500e-03, -8.4394e-04,  3.2134e-03,\n",
       "                        3.2268e-04,  9.6798e-03,  8.5785e-03, -1.5575e-02,  1.3488e-03,\n",
       "                        8.6215e-04, -7.6647e-03, -6.3747e-03, -3.8506e-03, -1.2807e-03,\n",
       "                       -4.9393e-03,  1.0574e-03,  1.4140e-03, -1.1195e-02, -1.2086e-02,\n",
       "                       -6.9257e-03,  4.4193e-03,  1.2056e-03,  3.2801e-03, -6.7050e-03,\n",
       "                        6.8352e-03,  2.5926e-03,  1.6826e-03,  5.4317e-03, -5.5195e-03,\n",
       "                       -1.4840e-02,  4.5611e-03, -3.6872e-03,  5.1877e-03, -1.1719e-02,\n",
       "                        4.8049e-03,  2.3331e-03,  4.1109e-03,  1.1466e-02,  4.1886e-03,\n",
       "                       -6.3686e-03, -6.3415e-03, -3.0929e-03, -5.8470e-03,  3.3880e-03,\n",
       "                       -2.8314e-03, -1.1355e-02,  1.0967e-03, -2.8034e-03, -8.0381e-03,\n",
       "                       -6.2330e-03,  1.0590e-05, -5.4844e-03, -1.5337e-03, -6.3514e-03,\n",
       "                        6.6038e-03, -7.9502e-03, -5.0565e-03, -4.0899e-03, -1.5101e-03,\n",
       "                       -2.3095e-03, -7.9387e-04,  7.6716e-03, -4.2289e-03,  3.0661e-03,\n",
       "                       -1.0373e-02,  5.2901e-03, -7.5089e-04, -1.5526e-03, -8.7472e-03,\n",
       "                       -5.8661e-04,  2.0347e-03, -8.7445e-03,  2.6433e-03,  5.3656e-03,\n",
       "                       -7.9166e-03, -7.8473e-03,  3.4781e-03,  1.8453e-03, -3.3712e-03,\n",
       "                        1.9454e-03,  7.9518e-03,  8.2267e-04,  5.7184e-03, -2.4042e-03,\n",
       "                       -1.1058e-03,  2.3324e-03, -4.1959e-03, -5.2713e-03,  1.9255e-03,\n",
       "                        5.0692e-03, -8.0194e-04,  7.8154e-03, -7.7505e-03, -5.1091e-03,\n",
       "                       -8.5316e-03, -4.3883e-03, -1.9177e-04,  1.6153e-03,  1.9046e-03,\n",
       "                        1.8832e-03, -6.2147e-03, -5.5230e-03,  6.7673e-03, -5.3879e-03,\n",
       "                        1.2470e-03, -2.9469e-03,  4.1432e-03,  6.7377e-03, -4.9068e-03,\n",
       "                        7.6377e-03,  2.2759e-03,  6.4161e-03, -4.4321e-03, -1.6212e-03,\n",
       "                        2.4633e-03, -5.7632e-04,  1.5041e-02, -1.1249e-02, -1.1761e-02,\n",
       "                        3.9422e-04, -9.3772e-03, -2.3358e-03,  1.4017e-02,  2.7497e-03,\n",
       "                        1.8426e-03, -1.4556e-02,  1.5524e-02, -3.8270e-03,  3.5364e-03,\n",
       "                        9.3285e-04, -1.2357e-02,  5.4686e-03,  7.1060e-03, -6.8575e-04,\n",
       "                       -1.7121e-03,  2.4975e-03,  1.2438e-02,  1.2858e-02, -5.2741e-03,\n",
       "                        4.7352e-03, -2.8169e-03,  6.0020e-03,  2.1967e-03,  4.0583e-03,\n",
       "                       -1.3037e-03,  6.9602e-03, -2.5381e-03, -7.0305e-03,  5.0679e-03,\n",
       "                       -2.7184e-03, -3.2421e-03,  1.2041e-02, -9.3919e-04, -6.7661e-03,\n",
       "                       -5.3342e-03, -5.4536e-03,  1.6524e-02, -5.6992e-03,  4.2892e-04,\n",
       "                       -1.1219e-02, -2.0030e-03,  3.5546e-04, -7.1521e-03,  1.3318e-02,\n",
       "                        5.5752e-04,  1.1528e-02, -6.6526e-03,  1.3048e-03,  8.3167e-03,\n",
       "                       -5.2821e-03,  5.9717e-03,  7.6054e-03,  1.2026e-02,  3.4922e-03,\n",
       "                        5.7501e-03,  7.2623e-03, -9.3478e-03, -3.7388e-03, -8.7819e-03,\n",
       "                        6.9301e-03,  1.5978e-02,  5.1837e-03, -5.9979e-03, -1.0544e-03,\n",
       "                       -4.5645e-03,  1.3745e-03,  2.1700e-03, -1.4608e-02, -5.5598e-04,\n",
       "                        3.7273e-03, -5.8350e-03,  1.8480e-02,  6.6423e-04, -2.5660e-03,\n",
       "                        6.2722e-03,  9.1174e-03,  1.5177e-02, -3.2068e-03, -4.2781e-03,\n",
       "                        1.6332e-03,  1.8279e-02, -8.4055e-03, -1.1626e-03,  9.4073e-03,\n",
       "                        1.4651e-02, -4.7383e-03,  1.3478e-02, -1.0464e-02, -1.2431e-03,\n",
       "                        3.6817e-03, -2.0794e-03, -1.6897e-02, -7.9663e-03,  1.3147e-02,\n",
       "                       -7.7318e-03,  8.8557e-03,  1.1652e-02, -4.1472e-03, -4.6914e-03,\n",
       "                       -1.4921e-02, -7.4054e-03, -1.2392e-02, -1.1345e-02, -9.9964e-03,\n",
       "                        4.6104e-04, -5.2815e-03,  1.0537e-02,  1.1073e-02,  8.2428e-03,\n",
       "                       -5.6367e-04,  5.6910e-03,  3.3774e-03,  1.8281e-02, -1.9014e-02,\n",
       "                       -7.4535e-03,  1.2530e-02, -1.0071e-02, -1.1171e-02, -1.8324e-03,\n",
       "                       -1.2815e-02,  1.8581e-02, -1.2245e-02,  7.7961e-03,  7.4304e-03,\n",
       "                       -1.0063e-02, -3.4530e-03, -2.2695e-03, -4.6933e-03,  1.2868e-03,\n",
       "                        1.7504e-02,  1.7368e-02,  3.2378e-04,  6.7686e-03,  2.9929e-03,\n",
       "                        2.0347e-03, -2.7396e-03,  2.4749e-03, -4.8082e-03, -1.2310e-02,\n",
       "                        5.2764e-03,  4.5255e-03, -6.9334e-04,  1.1279e-02, -6.3457e-03,\n",
       "                       -4.2541e-04,  4.0423e-03, -1.3165e-02,  2.1264e-03,  7.8402e-04,\n",
       "                       -9.4488e-03,  1.0584e-02, -1.3238e-02,  6.6466e-03, -9.2266e-03,\n",
       "                        3.5160e-04, -6.8543e-03,  1.2224e-02,  1.0265e-02, -1.0200e-03,\n",
       "                       -5.5682e-03, -4.1998e-03, -3.5992e-03, -7.3348e-03,  7.1815e-03,\n",
       "                       -1.2203e-02,  6.6583e-03,  1.2708e-02, -2.2767e-02, -4.2142e-03,\n",
       "                        9.8707e-03,  5.4117e-04, -1.7793e-02,  1.3636e-02, -9.7328e-03,\n",
       "                       -2.0407e-02, -1.5710e-02, -3.1534e-03, -2.1246e-02,  5.9142e-03,\n",
       "                        3.6049e-03,  1.7666e-02, -3.8418e-03, -1.4443e-02, -5.2533e-04,\n",
       "                        1.1803e-02,  8.8382e-04, -7.4278e-03,  1.8978e-03,  1.2647e-02,\n",
       "                       -1.1369e-02, -3.5226e-04,  6.2564e-03,  1.3257e-03, -9.2264e-03,\n",
       "                       -9.6434e-03, -1.7875e-03,  1.0440e-02, -9.9592e-04, -1.2339e-02,\n",
       "                        2.9593e-03,  1.1566e-03, -5.5904e-03,  6.9957e-03])),\n",
       "              ('net.models.0.interactions.3.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.0009, -0.1523,  0.0909,  ...,  0.1220,  0.0743, -0.1415],\n",
       "                       [-0.1272,  0.0645,  0.0548,  ...,  0.0395,  0.0284,  0.0036],\n",
       "                       [-0.1362,  0.1223,  0.0461,  ...,  0.1465,  0.0042,  0.0437],\n",
       "                       ...,\n",
       "                       [ 0.1190,  0.0441, -0.0673,  ..., -0.1005,  0.0809,  0.0635],\n",
       "                       [ 0.1448,  0.1152,  0.0433,  ...,  0.0310,  0.1290,  0.1532],\n",
       "                       [-0.0315, -0.0735,  0.0725,  ..., -0.0842,  0.1203,  0.0129]])),\n",
       "              ('net.models.0.interactions.3.interatomic_context_net.0.bias',\n",
       "               tensor([-5.7756e-04, -5.3324e-03,  1.0354e-02, -7.8569e-03,  4.1876e-03,\n",
       "                        1.9396e-03, -7.8464e-04, -6.8273e-03,  5.6454e-03, -5.6714e-03,\n",
       "                       -3.3290e-03,  4.0535e-03, -6.5108e-03, -2.6891e-03,  3.4488e-04,\n",
       "                       -5.3191e-03, -6.0858e-03,  2.2978e-04, -2.6843e-03,  3.3788e-03,\n",
       "                       -3.7942e-03, -6.1498e-03, -1.8156e-03, -6.4251e-03, -1.0202e-02,\n",
       "                        3.8295e-03, -6.7068e-03, -7.7811e-03, -9.2626e-04, -9.8242e-03,\n",
       "                        8.1626e-03, -5.5740e-03, -1.5177e-02, -1.6836e-02, -5.2021e-03,\n",
       "                       -6.0710e-03, -5.6250e-03, -2.3764e-03, -1.0039e-02,  2.1101e-03,\n",
       "                       -5.0733e-03,  1.0441e-02,  1.2756e-02, -7.8728e-03,  5.7657e-03,\n",
       "                       -3.3608e-03, -4.5030e-04,  5.6367e-03, -1.3958e-03,  5.1459e-04,\n",
       "                       -5.0964e-04, -7.2953e-03, -8.2169e-03,  2.0906e-03, -1.1474e-02,\n",
       "                       -1.4774e-03, -1.0489e-02, -9.0943e-04, -1.9300e-03,  4.6421e-03,\n",
       "                       -3.7430e-03,  5.8602e-03, -7.6206e-03,  6.1122e-03, -5.5998e-04,\n",
       "                        2.1516e-03,  6.6942e-03, -8.5085e-03, -4.7346e-03, -1.7983e-03,\n",
       "                       -4.9867e-03, -4.4131e-03,  1.1837e-03, -7.0303e-03, -7.6395e-03,\n",
       "                       -1.3148e-03, -1.7409e-03,  4.3404e-03, -2.9385e-03, -5.4290e-03,\n",
       "                       -7.7150e-03, -8.1124e-03, -1.2529e-03, -6.4546e-03, -5.1232e-03,\n",
       "                        4.7768e-03, -2.0791e-03, -4.3764e-05,  1.9345e-04, -4.6985e-03,\n",
       "                       -1.0561e-02,  1.1179e-02, -1.6677e-02, -2.4371e-03, -2.4075e-03,\n",
       "                        4.3745e-03, -2.2159e-03, -2.0718e-03, -1.2330e-02, -2.8898e-03,\n",
       "                       -1.0238e-03, -1.9424e-03, -3.1724e-04, -8.2371e-03, -1.1368e-02,\n",
       "                       -7.4523e-04, -4.4471e-03, -6.6658e-03,  4.4420e-03, -3.2177e-04,\n",
       "                       -1.5378e-03, -5.7910e-03,  8.3187e-03, -2.0442e-03, -2.7829e-03,\n",
       "                        8.8383e-04, -1.1596e-03, -3.6065e-03, -6.6964e-03, -4.0339e-04,\n",
       "                       -7.7168e-03, -2.8582e-03,  6.7406e-04,  4.6540e-03,  6.7084e-03,\n",
       "                        6.6676e-04, -1.5752e-04, -2.4701e-05])),\n",
       "              ('net.models.0.interactions.3.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.1137,  0.0355, -0.0200,  ..., -0.0591,  0.0999,  0.0732],\n",
       "                       [ 0.1059,  0.0941, -0.0687,  ...,  0.0148, -0.0252, -0.0369],\n",
       "                       [-0.0977, -0.0099,  0.0453,  ...,  0.0940,  0.0038, -0.0555],\n",
       "                       ...,\n",
       "                       [ 0.0736,  0.0189, -0.0805,  ...,  0.0687,  0.0257, -0.0944],\n",
       "                       [-0.0345, -0.0188,  0.0254,  ..., -0.0431, -0.0110,  0.0962],\n",
       "                       [ 0.0422, -0.0701, -0.0487,  ..., -0.0319,  0.0560, -0.0972]])),\n",
       "              ('net.models.0.interactions.3.interatomic_context_net.1.bias',\n",
       "               tensor([-2.8753e-03, -7.4704e-05, -8.8222e-05, -2.5764e-03, -5.3638e-03,\n",
       "                        2.0782e-03, -7.6584e-03,  1.7005e-03,  3.6497e-03, -4.7990e-03,\n",
       "                       -3.5081e-03,  3.6115e-03, -4.7509e-03,  6.7517e-04, -9.1498e-03,\n",
       "                        1.3517e-03, -4.2718e-03, -1.5808e-03,  1.8325e-02, -1.0467e-03,\n",
       "                        5.5155e-03, -1.0443e-03,  1.6590e-03,  6.7900e-03,  2.5030e-03,\n",
       "                        4.0841e-03,  8.6095e-04, -8.3335e-03, -2.9851e-03, -1.2656e-03,\n",
       "                       -4.5765e-03,  1.9614e-03,  1.2804e-02, -2.0668e-03, -3.6703e-04,\n",
       "                       -8.1970e-05,  3.5820e-03, -1.9748e-03, -5.6763e-03,  2.9527e-03,\n",
       "                        1.8620e-03, -1.6583e-03,  6.6249e-04,  2.4610e-04, -8.2225e-03,\n",
       "                       -1.1865e-03,  1.5350e-03, -5.0410e-03,  1.0702e-02,  9.3866e-03,\n",
       "                        2.1296e-03, -8.4181e-03, -3.8646e-03,  1.3064e-03,  3.3038e-03,\n",
       "                        4.5778e-03, -9.3384e-03,  4.6657e-03,  3.4731e-03, -1.4490e-03,\n",
       "                        5.2427e-03, -3.7334e-03,  3.4097e-03,  4.9683e-03,  6.9678e-03,\n",
       "                       -1.0505e-04,  4.9700e-03,  5.2563e-03, -1.0040e-02,  6.0222e-03,\n",
       "                        2.0736e-03,  1.2917e-03,  6.0244e-03, -1.0359e-02,  5.7421e-04,\n",
       "                       -3.6965e-03, -1.4401e-02, -2.5332e-03,  4.2529e-03,  2.6934e-03,\n",
       "                       -2.2389e-03, -1.2170e-03,  1.2279e-03, -1.3211e-02, -5.5883e-03,\n",
       "                       -2.6954e-03,  1.5177e-02, -2.2265e-03,  2.1954e-05, -1.1986e-03,\n",
       "                       -7.5006e-03, -4.8082e-03,  1.3370e-03, -9.1170e-04,  1.2816e-03,\n",
       "                        4.8904e-05, -5.9664e-03, -6.2132e-03,  3.2847e-03, -3.0931e-03,\n",
       "                        4.3011e-03,  2.9251e-05, -5.3121e-03,  4.7631e-03,  6.5362e-03,\n",
       "                        5.0127e-03, -1.8747e-03,  4.0939e-03, -6.3447e-04, -9.4054e-03,\n",
       "                        1.4523e-03,  3.6147e-03,  9.1668e-04, -7.7391e-03,  3.2228e-03,\n",
       "                       -9.2224e-03,  8.1784e-03,  1.7874e-03,  8.9528e-03,  6.1812e-03,\n",
       "                        6.7008e-03,  1.1605e-02,  1.2629e-03, -1.0981e-03,  3.1759e-04,\n",
       "                        9.8613e-03,  7.7256e-03,  1.6719e-04,  1.0041e-02, -9.7595e-04,\n",
       "                        4.5730e-04, -3.8519e-03,  2.3727e-05, -1.3766e-03, -6.1402e-04,\n",
       "                       -4.5729e-03, -1.0450e-02,  2.2323e-03, -9.8272e-03, -2.2154e-03,\n",
       "                        1.6642e-03, -1.4602e-04, -1.5071e-03,  3.1251e-03, -5.9652e-03,\n",
       "                       -1.3009e-02, -1.1681e-02, -3.4765e-03, -1.2307e-03,  2.6817e-03,\n",
       "                        1.0223e-02,  5.2905e-03,  1.9642e-03,  3.1692e-03,  3.7300e-03,\n",
       "                        1.0474e-03, -6.0790e-03,  1.1674e-02,  9.9389e-03, -2.6961e-03,\n",
       "                        6.6224e-03, -9.7533e-03, -8.0457e-03,  2.7480e-03, -2.1426e-03,\n",
       "                       -7.7280e-04, -6.1124e-03, -8.1820e-04, -4.5277e-03,  5.5246e-03,\n",
       "                        7.2806e-03, -7.4393e-04,  1.1441e-02,  1.7611e-02, -1.7182e-03,\n",
       "                       -6.9530e-03,  1.7263e-03,  5.5417e-03,  6.7342e-03,  9.7652e-03,\n",
       "                       -5.0563e-03,  1.3598e-02,  6.6469e-03, -2.2411e-03,  5.1698e-03,\n",
       "                       -1.4615e-02, -7.8826e-03,  2.0928e-03, -7.5746e-04,  7.3026e-04,\n",
       "                        2.1582e-02,  1.2151e-02,  2.6068e-03,  4.1765e-03, -9.2105e-03,\n",
       "                       -1.8108e-03, -1.0353e-03,  1.0553e-02, -4.2470e-03,  1.0560e-03,\n",
       "                        9.0550e-03, -4.3373e-03,  9.1227e-03,  3.7978e-03, -8.3693e-03,\n",
       "                       -2.5027e-03,  1.9076e-03, -1.6111e-02, -1.5020e-02, -6.0052e-03,\n",
       "                       -1.6703e-03, -1.2319e-03,  4.7517e-03,  2.5462e-03, -2.2367e-03,\n",
       "                       -5.6522e-03, -1.9016e-03,  1.1553e-03, -3.4834e-03,  2.4817e-03,\n",
       "                       -1.8056e-03,  3.0991e-03,  5.9115e-03,  3.1684e-03, -6.6379e-03,\n",
       "                       -2.4574e-03, -1.3984e-03, -3.0867e-03, -3.3418e-03, -7.1236e-04,\n",
       "                        4.6565e-03, -2.5333e-03, -9.0173e-03,  1.1566e-02,  2.8834e-03,\n",
       "                        4.5595e-04,  3.9136e-03, -4.5917e-03, -1.0043e-03, -1.6708e-03,\n",
       "                       -3.3010e-03,  1.4399e-02, -4.1747e-03,  1.2185e-02,  7.4905e-05,\n",
       "                        2.0881e-03, -3.2102e-03, -3.6660e-03,  9.9360e-03, -8.5754e-04,\n",
       "                        1.5498e-02, -4.2355e-03, -7.0854e-03,  4.9818e-03, -3.6855e-03,\n",
       "                        4.5535e-03,  1.6610e-02,  1.4710e-02,  9.5605e-04,  8.3357e-04,\n",
       "                       -1.1845e-02, -1.1556e-02,  4.1065e-03, -1.6218e-02, -3.4351e-03,\n",
       "                       -1.6084e-02, -1.0514e-03, -1.7341e-02, -5.2028e-03,  1.4692e-03,\n",
       "                       -1.6940e-02,  1.1721e-02,  1.2119e-02,  5.9850e-03, -4.6457e-03,\n",
       "                       -7.7513e-04,  1.4622e-02,  5.3407e-03, -4.0030e-03, -4.7143e-03,\n",
       "                        4.7514e-04,  4.4025e-03,  9.2094e-03, -2.6117e-03, -5.2069e-03,\n",
       "                       -3.5808e-03,  1.9264e-02,  8.3161e-03,  7.9549e-03,  3.8450e-03,\n",
       "                        1.2572e-02,  5.8324e-03, -4.4331e-03,  3.7946e-03,  9.4104e-03,\n",
       "                        7.5969e-04,  6.7403e-03,  7.7950e-03,  3.6207e-03,  1.6970e-02,\n",
       "                        9.5656e-03, -1.8627e-02, -2.2071e-03,  9.6639e-03,  1.0902e-02,\n",
       "                       -1.0714e-02,  1.0108e-03,  1.5164e-02,  2.3332e-03, -2.6758e-03,\n",
       "                        1.3456e-02,  1.0287e-02,  2.1576e-02, -1.4505e-02,  1.4550e-02,\n",
       "                        1.2847e-03,  5.8164e-03, -5.9178e-03, -1.7467e-03, -8.1052e-03,\n",
       "                       -1.8262e-02, -1.4842e-02, -1.0199e-02,  1.4652e-03,  1.4032e-05,\n",
       "                        1.4747e-02, -1.8114e-02, -7.5510e-03, -2.8617e-03, -5.5528e-03,\n",
       "                       -1.0254e-02,  9.1267e-03, -1.8867e-02, -4.5117e-03, -9.5269e-03,\n",
       "                        5.0974e-03, -5.5622e-04,  5.3082e-03,  2.9469e-03,  1.7047e-02,\n",
       "                       -9.7605e-03,  3.3276e-03,  1.1868e-02,  5.6116e-03, -3.7524e-03,\n",
       "                       -1.3393e-02,  1.3427e-02,  2.0339e-02,  8.8157e-04,  1.1659e-04,\n",
       "                        1.2885e-02, -3.6458e-03, -1.5060e-02,  1.5471e-02,  3.7544e-03,\n",
       "                       -2.0459e-02, -1.4624e-02, -8.4513e-03, -2.1770e-02,  4.9513e-03,\n",
       "                       -2.8438e-03, -5.3260e-04,  1.0410e-02, -1.1010e-02,  8.3528e-03,\n",
       "                       -6.2565e-03, -2.2281e-04,  9.7155e-03, -1.7636e-02,  1.1902e-02,\n",
       "                       -5.4348e-03, -1.2570e-02,  1.2204e-03,  5.7178e-03,  6.7977e-03,\n",
       "                       -2.6533e-03,  4.6689e-03,  4.6730e-03,  1.4184e-02,  1.4949e-02,\n",
       "                        1.4374e-03, -1.3661e-03, -3.2212e-03, -1.1069e-02])),\n",
       "              ('net.models.0.interactions.4.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.0103,  0.1511, -0.0531,  ..., -0.1640, -0.0476,  0.0732],\n",
       "                       [-0.0204,  0.1075,  0.0738,  ..., -0.1261, -0.1376,  0.1513],\n",
       "                       [-0.0263,  0.0618,  0.1168,  ..., -0.0832,  0.0635, -0.1556],\n",
       "                       ...,\n",
       "                       [-0.1006, -0.0950, -0.1373,  ..., -0.0855, -0.1430, -0.1084],\n",
       "                       [-0.0978, -0.1346,  0.0887,  ...,  0.0240,  0.0143,  0.1338],\n",
       "                       [-0.0314, -0.0650, -0.1180,  ..., -0.1181,  0.1059, -0.1417]])),\n",
       "              ('net.models.0.interactions.4.interatomic_context_net.0.bias',\n",
       "               tensor([-0.0077,  0.0028, -0.0092, -0.0010, -0.0052,  0.0032,  0.0036, -0.0024,\n",
       "                       -0.0098, -0.0007, -0.0020, -0.0005,  0.0006,  0.0018, -0.0049, -0.0045,\n",
       "                       -0.0053, -0.0054, -0.0036,  0.0004, -0.0057,  0.0068,  0.0054, -0.0005,\n",
       "                       -0.0030, -0.0095, -0.0041, -0.0036,  0.0024, -0.0137, -0.0016, -0.0047,\n",
       "                        0.0036, -0.0027,  0.0030,  0.0002, -0.0026,  0.0061,  0.0036,  0.0048,\n",
       "                       -0.0151,  0.0050, -0.0036, -0.0101, -0.0036, -0.0012, -0.0092, -0.0059,\n",
       "                       -0.0110,  0.0013, -0.0032, -0.0008, -0.0018, -0.0072, -0.0019, -0.0079,\n",
       "                       -0.0043, -0.0193, -0.0020, -0.0033, -0.0059, -0.0022,  0.0011, -0.0025,\n",
       "                       -0.0022,  0.0003, -0.0076,  0.0022, -0.0068, -0.0087,  0.0044, -0.0072,\n",
       "                       -0.0035, -0.0037, -0.0083, -0.0103, -0.0098,  0.0004, -0.0073,  0.0004,\n",
       "                       -0.0022, -0.0077, -0.0098, -0.0095, -0.0056,  0.0081, -0.0020, -0.0013,\n",
       "                       -0.0028, -0.0043, -0.0092, -0.0057,  0.0077,  0.0045, -0.0092, -0.0022,\n",
       "                       -0.0034, -0.0040, -0.0057, -0.0046, -0.0040, -0.0037,  0.0006, -0.0010,\n",
       "                       -0.0075, -0.0122, -0.0100,  0.0094,  0.0069, -0.0012, -0.0029, -0.0036,\n",
       "                        0.0007,  0.0046,  0.0075,  0.0015, -0.0020, -0.0044,  0.0068, -0.0042,\n",
       "                       -0.0023, -0.0032, -0.0038,  0.0042, -0.0001, -0.0065, -0.0102, -0.0114])),\n",
       "              ('net.models.0.interactions.4.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0106, -0.0011, -0.0973,  ..., -0.0930, -0.0944, -0.0873],\n",
       "                       [ 0.0230, -0.0368,  0.0088,  ..., -0.0044,  0.0826, -0.0413],\n",
       "                       [ 0.0107,  0.0298, -0.0655,  ..., -0.0094, -0.0127, -0.0444],\n",
       "                       ...,\n",
       "                       [ 0.0973,  0.1080, -0.0414,  ...,  0.0748,  0.0362,  0.0134],\n",
       "                       [ 0.0557,  0.0492, -0.0328,  ..., -0.0511, -0.0462, -0.0327],\n",
       "                       [ 0.0245,  0.0754, -0.0857,  ..., -0.0275,  0.0317,  0.0785]])),\n",
       "              ('net.models.0.interactions.4.interatomic_context_net.1.bias',\n",
       "               tensor([ 5.4676e-03,  1.8023e-03, -1.3110e-03, -1.6095e-03, -7.5888e-04,\n",
       "                       -5.3083e-05,  6.7273e-03,  1.7599e-02, -2.2754e-04, -5.3505e-03,\n",
       "                        4.3176e-03, -4.2388e-03,  2.8694e-03, -7.2486e-03, -1.5954e-03,\n",
       "                        7.5580e-03,  1.0047e-02,  2.6595e-03, -9.9239e-04,  2.2286e-03,\n",
       "                       -4.1505e-04, -4.3114e-03,  5.5392e-03,  6.2048e-04, -1.3473e-03,\n",
       "                       -2.6406e-03, -1.1163e-02,  2.2353e-03, -4.6399e-03, -1.6340e-03,\n",
       "                       -5.4794e-03, -2.0006e-03,  2.1523e-04,  2.4738e-03, -5.2180e-03,\n",
       "                       -4.5169e-03,  7.0640e-04, -4.9099e-03,  8.6582e-04, -4.1035e-03,\n",
       "                        2.8954e-03,  1.6876e-03,  1.7374e-03,  8.4250e-03,  2.9448e-03,\n",
       "                        7.7825e-03,  2.6980e-03,  2.2640e-03, -3.2571e-03, -3.3893e-03,\n",
       "                        3.2364e-03, -1.1688e-03,  6.2435e-03,  8.0178e-04,  4.7221e-03,\n",
       "                        2.6561e-03,  3.3774e-03,  5.6063e-03,  3.1142e-03,  1.0498e-02,\n",
       "                       -4.7861e-04,  1.1693e-03, -2.4704e-03,  2.8489e-03,  3.1670e-03,\n",
       "                        4.7235e-03,  6.3952e-04,  3.1732e-03, -3.4381e-03, -1.9320e-03,\n",
       "                        8.2667e-03, -1.2224e-02,  9.9036e-03, -4.8942e-03,  3.8027e-03,\n",
       "                       -3.1184e-03,  5.2738e-03,  2.0912e-03,  4.3387e-03, -9.8225e-03,\n",
       "                       -3.9670e-03,  4.2952e-04, -9.8519e-03,  1.0159e-03, -3.6748e-03,\n",
       "                        1.6213e-03,  8.5597e-03, -5.2134e-03,  8.8924e-04, -1.3763e-03,\n",
       "                        4.7844e-03,  1.8418e-03, -9.5411e-03,  7.3734e-03, -6.1227e-04,\n",
       "                       -3.9821e-03, -7.4633e-03, -7.6742e-03, -3.0945e-03,  5.7874e-03,\n",
       "                        4.8892e-04,  2.5334e-03,  3.4937e-03, -1.7892e-03,  7.6609e-03,\n",
       "                       -4.3352e-03, -2.6401e-03, -4.3515e-03, -2.3293e-05, -7.9513e-03,\n",
       "                        2.5677e-03, -5.2440e-03,  8.5354e-03,  1.3355e-02, -5.1328e-03,\n",
       "                        1.3473e-03, -8.6826e-03,  1.0671e-02,  5.8300e-03, -9.1354e-03,\n",
       "                        8.6311e-04, -1.7442e-03,  8.3391e-03, -6.6105e-03, -1.3071e-04,\n",
       "                        7.0577e-04,  5.4999e-03,  3.4872e-03, -6.2538e-03, -4.2286e-03,\n",
       "                        1.2800e-03, -1.4531e-02, -7.3064e-03,  1.1991e-02,  1.5870e-03,\n",
       "                        6.9004e-03, -1.5498e-03,  6.5821e-03,  4.2125e-03, -1.1787e-02,\n",
       "                        2.9778e-03,  2.7305e-03, -6.4312e-04,  4.3108e-03, -2.9243e-03,\n",
       "                        4.7360e-03,  2.7586e-03, -6.9335e-03,  4.2249e-03, -1.4917e-03,\n",
       "                        2.9925e-03,  1.0797e-03, -6.5700e-03,  3.6515e-03,  1.0377e-03,\n",
       "                        7.0029e-03,  3.5390e-03, -1.9677e-03,  6.7327e-03,  4.3171e-03,\n",
       "                       -6.7792e-03, -2.6213e-03, -3.3318e-03, -7.2625e-03, -3.7141e-03,\n",
       "                       -1.1418e-03,  5.4588e-03, -3.5878e-03, -2.3366e-03,  1.5531e-02,\n",
       "                        7.6612e-03,  6.2405e-03,  3.8862e-03, -6.5083e-03, -1.8046e-03,\n",
       "                       -3.2084e-03, -4.0065e-04, -3.1367e-03, -1.5624e-03, -9.9186e-03,\n",
       "                        7.2457e-03, -5.6321e-03, -7.8776e-03,  2.0467e-03, -2.0340e-02,\n",
       "                        3.1189e-03,  5.2626e-03,  5.8972e-03,  5.3102e-03, -8.0816e-03,\n",
       "                        8.9131e-03,  8.3253e-03, -2.6482e-03,  3.7437e-03, -2.2344e-03,\n",
       "                        1.0096e-02, -2.9650e-03, -2.5339e-03,  4.6235e-03, -5.6475e-03,\n",
       "                       -6.4739e-03,  6.0105e-03,  3.0499e-03, -3.9574e-04,  1.1509e-03,\n",
       "                        2.5194e-03,  3.4222e-03,  2.9369e-03,  4.2948e-03,  5.2064e-04,\n",
       "                       -2.1721e-03, -2.9588e-04, -5.9118e-03, -8.0487e-05, -1.0731e-03,\n",
       "                       -4.2764e-03,  1.1233e-02, -1.2031e-02,  6.7297e-03, -3.9360e-03,\n",
       "                        1.0102e-03,  5.1826e-03, -6.8029e-03, -9.1919e-03, -8.9493e-03,\n",
       "                        1.1794e-02, -7.1761e-03, -8.4983e-03, -2.0793e-04, -7.7447e-03,\n",
       "                       -8.0127e-03,  2.6642e-04,  1.0975e-02,  7.9336e-03, -6.2389e-03,\n",
       "                        3.5130e-03, -5.1361e-03,  7.2248e-03,  3.2766e-03,  2.4544e-04,\n",
       "                        1.3204e-04,  7.2396e-03,  8.0919e-03, -6.9969e-05,  6.3043e-03,\n",
       "                       -4.1722e-03, -3.5095e-03,  1.5403e-03, -1.7836e-03,  3.6676e-03,\n",
       "                       -3.1901e-03, -4.2641e-03, -1.2505e-02, -1.6176e-03, -3.3812e-05,\n",
       "                        4.1674e-03,  8.5405e-03,  6.4913e-03,  1.5916e-02,  7.3193e-03,\n",
       "                        7.1560e-03, -6.9218e-03, -2.4988e-03,  7.8204e-03, -2.8328e-02,\n",
       "                       -5.5649e-03, -1.5403e-02, -9.7794e-04,  1.6240e-02,  9.5565e-03,\n",
       "                        1.8991e-02,  4.2406e-03, -1.0417e-02,  1.2414e-02,  7.6415e-03,\n",
       "                       -2.6005e-03, -8.4003e-03,  1.1386e-02, -1.8344e-02,  5.3230e-03,\n",
       "                        1.1817e-02,  1.7940e-02, -1.3254e-02,  1.3899e-03, -1.6976e-02,\n",
       "                        2.3260e-03,  9.8378e-03,  1.1595e-02, -9.0237e-03,  3.4271e-03,\n",
       "                       -1.2402e-02, -4.1880e-03, -1.3467e-02, -1.3205e-02, -5.8987e-03,\n",
       "                        5.5535e-03,  1.1447e-02,  4.3745e-03, -4.9733e-03, -9.3364e-03,\n",
       "                       -1.6171e-03,  9.9873e-03, -7.2870e-03, -9.4976e-03, -8.1814e-03,\n",
       "                        7.5861e-03,  3.3806e-03, -1.3475e-03, -3.0665e-03, -5.2416e-03,\n",
       "                       -1.0203e-02, -1.3308e-02,  9.1911e-03,  5.2907e-03, -1.7127e-02,\n",
       "                        5.6631e-03,  1.0961e-02, -5.9801e-03,  1.1318e-02, -8.7284e-03,\n",
       "                        8.2093e-04, -1.0924e-02,  1.0621e-02, -7.8586e-03, -6.8450e-04,\n",
       "                       -1.1496e-02,  1.3206e-02, -1.5754e-02, -5.2120e-03, -1.4836e-02,\n",
       "                        9.3625e-03,  4.2741e-03,  1.3737e-02,  3.7788e-03, -1.3959e-02,\n",
       "                        4.8506e-03,  4.2651e-03, -1.1028e-03,  1.2704e-03, -1.8464e-02,\n",
       "                       -2.3312e-03,  3.9047e-03, -2.2893e-03, -1.4016e-02,  1.0850e-02,\n",
       "                       -9.6884e-03,  4.6764e-03,  1.4323e-02, -6.0849e-03, -4.9495e-03,\n",
       "                       -8.5302e-04,  7.2074e-04,  1.9292e-02,  2.1848e-03,  3.5152e-03,\n",
       "                        1.0573e-02,  1.2871e-03,  1.0101e-03, -2.2515e-02, -2.1527e-03,\n",
       "                        2.0684e-03, -2.4031e-03,  8.6959e-03, -7.2296e-03, -6.8061e-03,\n",
       "                       -1.5650e-02,  8.8448e-03, -5.2453e-03, -1.5527e-02,  8.1570e-03,\n",
       "                       -9.8861e-04,  8.5447e-03,  1.4478e-02,  1.0233e-02,  9.8834e-03,\n",
       "                       -1.4299e-02, -7.7215e-03,  7.5050e-03,  1.5185e-02,  1.2570e-02,\n",
       "                       -1.0593e-02,  5.1781e-03, -1.6246e-02,  1.2603e-02])),\n",
       "              ('net.models.0.interactions.5.interatomic_context_net.0.weight',\n",
       "               tensor([[ 0.1236,  0.1204,  0.1334,  ..., -0.0685,  0.0093, -0.0005],\n",
       "                       [-0.1662, -0.0840,  0.1278,  ...,  0.0931,  0.1162,  0.0427],\n",
       "                       [ 0.0871,  0.1043,  0.0586,  ..., -0.0691,  0.1311, -0.0995],\n",
       "                       ...,\n",
       "                       [-0.1207, -0.0118, -0.0442,  ...,  0.0627, -0.0293,  0.0852],\n",
       "                       [-0.0066, -0.0346, -0.0695,  ...,  0.1163,  0.0127,  0.1436],\n",
       "                       [ 0.0475,  0.1012,  0.1109,  ...,  0.0936,  0.0837,  0.0710]])),\n",
       "              ('net.models.0.interactions.5.interatomic_context_net.0.bias',\n",
       "               tensor([-9.7885e-03, -5.3997e-03,  4.0636e-03, -8.1694e-03, -4.4507e-03,\n",
       "                       -7.2053e-03, -2.4845e-03, -7.3382e-03,  3.8169e-03, -9.5464e-03,\n",
       "                       -4.8860e-03,  3.6805e-04, -1.0965e-03,  4.7440e-04, -1.1086e-02,\n",
       "                       -5.8401e-03, -3.0184e-03, -5.2142e-03, -3.4696e-03, -3.8552e-03,\n",
       "                       -1.3643e-02, -3.2115e-04,  6.3745e-03,  1.1521e-04,  2.9767e-03,\n",
       "                        5.5010e-04, -4.2950e-03,  5.5338e-03,  4.2529e-03, -6.5189e-03,\n",
       "                       -9.0487e-04, -1.4068e-02, -9.2889e-03, -8.2138e-03, -2.4185e-03,\n",
       "                       -1.3381e-02, -2.1442e-03,  3.1424e-03,  1.5807e-03, -7.1930e-04,\n",
       "                       -8.2421e-04, -4.1720e-03, -3.2362e-03,  1.0366e-03, -1.1601e-02,\n",
       "                       -3.5943e-03, -1.1423e-02,  2.3950e-03, -1.6993e-03, -1.9649e-03,\n",
       "                       -8.8264e-03, -1.2598e-03, -8.1253e-03, -3.6642e-04,  3.5974e-03,\n",
       "                        6.2389e-04,  6.4434e-03, -3.6229e-03, -6.3632e-03, -5.4289e-03,\n",
       "                       -2.8853e-03,  1.4394e-03,  1.4676e-03,  3.0909e-03, -5.3343e-03,\n",
       "                       -4.6335e-03,  1.2923e-04,  1.9298e-03, -6.5272e-03,  2.5631e-03,\n",
       "                       -1.6626e-03,  1.6799e-03, -2.3760e-04,  1.7582e-03,  3.8011e-05,\n",
       "                       -1.3942e-03, -4.6199e-03, -4.9655e-03, -5.2688e-03, -3.2739e-03,\n",
       "                       -6.6702e-03, -7.7797e-03,  6.6411e-04,  6.7967e-03, -3.0510e-03,\n",
       "                       -4.4695e-03, -7.8329e-03,  3.3517e-03,  5.4127e-03,  2.9121e-03,\n",
       "                       -9.1450e-03, -7.3481e-04, -1.0533e-04, -4.0551e-03, -3.2664e-03,\n",
       "                       -3.5671e-03, -3.0687e-03, -7.2055e-03, -4.2363e-04, -1.9127e-03,\n",
       "                       -4.0733e-03, -5.4985e-05, -2.7264e-03, -2.9222e-03, -3.3230e-03,\n",
       "                       -1.2076e-02, -4.0035e-03, -8.3429e-03, -6.9465e-03, -1.0243e-02,\n",
       "                        1.5416e-04, -1.3038e-03, -6.1581e-03, -7.0517e-03, -4.9872e-04,\n",
       "                       -1.1714e-02,  2.6672e-03, -3.9910e-03, -4.0009e-03, -2.0430e-02,\n",
       "                        2.2688e-03,  8.2347e-03, -6.9107e-03, -1.5277e-02, -1.1528e-03,\n",
       "                        3.0809e-03, -6.2067e-03, -5.7726e-03])),\n",
       "              ('net.models.0.interactions.5.interatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0271, -0.0430, -0.1094,  ..., -0.1131, -0.0877,  0.0434],\n",
       "                       [ 0.0010, -0.0197, -0.0717,  ...,  0.0077,  0.0876, -0.0025],\n",
       "                       [ 0.0440, -0.0531,  0.0941,  ..., -0.0892, -0.0663, -0.0217],\n",
       "                       ...,\n",
       "                       [ 0.0978, -0.0597, -0.0219,  ...,  0.0827, -0.0405,  0.0071],\n",
       "                       [-0.0012,  0.0073,  0.0997,  ...,  0.0616, -0.0191,  0.0867],\n",
       "                       [-0.1001,  0.0115, -0.1133,  ..., -0.0404,  0.0517,  0.0438]])),\n",
       "              ('net.models.0.interactions.5.interatomic_context_net.1.bias',\n",
       "               tensor([-4.0383e-03, -6.2099e-03, -1.6267e-03,  1.7408e-03,  3.0704e-03,\n",
       "                        3.1879e-03,  3.9780e-03,  1.5545e-03,  5.3906e-04, -1.6330e-03,\n",
       "                       -1.0511e-02,  1.7458e-03, -6.4719e-03,  1.7927e-03, -6.9299e-03,\n",
       "                       -6.4969e-04,  7.6007e-03,  1.6805e-03, -3.6181e-03, -5.1975e-03,\n",
       "                        4.1605e-03,  9.7025e-04,  6.4975e-03, -9.1925e-03, -4.8871e-03,\n",
       "                        5.6721e-04,  7.3078e-03,  1.4878e-03, -4.0294e-03, -4.4309e-04,\n",
       "                        5.1295e-04,  3.7969e-03, -1.5936e-03,  7.6177e-03, -4.5290e-03,\n",
       "                       -1.0696e-03, -8.8780e-03, -3.9754e-03,  5.5994e-03, -5.2694e-03,\n",
       "                       -1.5993e-04,  4.4542e-04,  1.2273e-02,  4.6931e-04, -2.2266e-03,\n",
       "                       -1.5920e-03, -3.7342e-03, -3.1845e-03, -2.6888e-03, -7.1558e-04,\n",
       "                        7.4780e-03, -6.1625e-04, -1.4770e-03, -1.7318e-03, -5.8601e-03,\n",
       "                        5.3341e-03,  2.7067e-03,  2.3999e-03, -2.3651e-03,  5.4083e-04,\n",
       "                        5.0807e-04, -5.1245e-03, -1.5984e-03,  2.7488e-03, -2.7909e-03,\n",
       "                        4.4551e-03,  2.9063e-04,  4.4957e-04, -5.7553e-03,  4.1369e-03,\n",
       "                        8.3911e-04,  5.4802e-03,  1.5381e-02, -1.1539e-03, -6.5204e-03,\n",
       "                       -1.2681e-03, -1.9878e-03,  5.9952e-03,  2.0913e-04,  3.5201e-03,\n",
       "                        3.1000e-03,  6.8643e-03,  7.6431e-03, -6.3658e-03, -8.7962e-05,\n",
       "                       -6.6461e-04,  4.3853e-03,  3.7674e-04, -3.2473e-03, -1.2982e-03,\n",
       "                        1.5113e-03,  1.8525e-03,  1.2804e-03,  4.0056e-03,  2.4409e-04,\n",
       "                       -4.7047e-03, -4.5962e-04,  3.0995e-03,  3.5658e-04, -6.9143e-04,\n",
       "                       -7.0328e-03,  2.2797e-03,  2.8186e-03,  1.9616e-03,  4.5922e-04,\n",
       "                       -1.3395e-03,  3.8305e-03,  3.4722e-03, -8.4302e-04, -9.8987e-03,\n",
       "                       -8.2519e-03, -2.6875e-03, -3.8874e-04, -3.1806e-03,  7.5056e-03,\n",
       "                       -1.2403e-02, -2.1720e-04, -9.8166e-04,  4.6732e-03,  3.2175e-03,\n",
       "                       -9.9785e-04, -6.6610e-03, -1.9434e-03, -3.3867e-04, -7.1095e-03,\n",
       "                       -7.2591e-03, -3.7749e-03, -4.2912e-03, -1.4816e-02, -2.8203e-03,\n",
       "                        6.9465e-03,  8.6465e-03, -7.0007e-03, -1.2278e-02, -3.9391e-03,\n",
       "                       -3.6035e-03, -4.7910e-03, -2.1466e-03, -6.4721e-03,  5.3736e-03,\n",
       "                        2.7245e-03,  1.0375e-02, -4.1742e-03,  1.9178e-04, -7.5064e-04,\n",
       "                        7.0781e-03, -5.4239e-03,  2.5493e-03, -9.5206e-03, -2.0291e-03,\n",
       "                        7.6808e-03,  2.9203e-03,  1.5809e-02, -1.0087e-02,  2.2173e-04,\n",
       "                       -3.3495e-03,  3.5150e-03,  3.2667e-03, -1.0675e-03,  9.6004e-04,\n",
       "                        1.3316e-02, -1.4000e-02, -1.3005e-02, -9.7009e-04,  1.9684e-04,\n",
       "                        8.0420e-03, -1.2885e-02, -1.3578e-03,  3.3447e-03,  9.5637e-04,\n",
       "                       -6.1177e-03,  2.4597e-03,  5.9466e-03,  2.4418e-03, -4.3198e-03,\n",
       "                       -8.1846e-03,  2.1334e-03, -7.1427e-03,  1.7330e-03,  2.0712e-03,\n",
       "                        2.8262e-03,  4.5405e-03,  4.8018e-03, -5.9017e-03, -4.8852e-03,\n",
       "                       -7.9030e-03,  6.8601e-04, -4.0798e-03,  8.5319e-03, -5.3759e-03,\n",
       "                       -2.5151e-03, -4.5098e-03,  2.6444e-03,  2.8254e-03, -1.0721e-03,\n",
       "                        1.1414e-03,  5.5293e-03,  8.7599e-04,  1.6562e-03,  1.4852e-03,\n",
       "                       -2.5124e-03, -5.6764e-03,  1.9663e-03, -1.2847e-02,  1.0394e-02,\n",
       "                        7.5686e-03, -6.7518e-03, -4.8457e-03,  7.3578e-03, -1.5667e-03,\n",
       "                       -9.6802e-03, -1.2479e-02,  5.3721e-03, -8.1993e-03,  3.9046e-03,\n",
       "                       -2.5190e-03,  1.2015e-02, -3.4104e-03,  1.8334e-03,  2.1674e-03,\n",
       "                       -3.1915e-03, -7.5232e-03, -8.0212e-03,  7.9373e-03, -5.1898e-03,\n",
       "                       -1.1759e-02,  1.7877e-02, -4.0921e-04,  1.0717e-02,  8.9426e-03,\n",
       "                        2.5731e-03, -4.1667e-04,  9.2192e-05, -1.2227e-02, -5.5063e-03,\n",
       "                        6.0886e-03, -6.6379e-03, -1.0237e-02, -6.6338e-03, -5.0255e-03,\n",
       "                        1.2935e-02,  9.0178e-03,  3.8474e-03, -7.7988e-03,  9.2228e-03,\n",
       "                       -6.2600e-03,  4.4651e-03,  9.6147e-05,  6.1917e-03, -3.4821e-03,\n",
       "                        2.6374e-03, -9.4329e-03,  7.1513e-03,  4.7425e-03, -7.6473e-03,\n",
       "                        5.1909e-03,  8.1948e-03,  3.7752e-03, -6.0454e-03, -1.0701e-02,\n",
       "                       -2.4636e-03,  6.3282e-03, -1.5883e-03,  1.5499e-03,  6.1913e-03,\n",
       "                        3.9677e-03, -1.6952e-02, -1.0850e-02, -2.0861e-02,  8.7590e-03,\n",
       "                       -2.4488e-03, -1.5863e-03, -2.5337e-02, -3.8737e-03,  6.8966e-03,\n",
       "                       -9.3332e-04, -5.8582e-03,  1.3227e-02,  1.9300e-02,  2.2139e-04,\n",
       "                        4.5777e-03, -5.4979e-03,  1.2786e-02, -7.3775e-03, -9.8979e-03,\n",
       "                       -1.7948e-02, -5.9636e-03,  8.0165e-03,  6.1386e-06, -2.5363e-03,\n",
       "                        9.1471e-03, -9.0887e-03, -9.0697e-03,  1.2145e-03,  1.7040e-03,\n",
       "                       -9.9447e-03, -1.6568e-03, -9.2038e-03,  1.4584e-02, -5.3058e-03,\n",
       "                       -9.8977e-03,  1.5800e-02,  4.0228e-03,  2.0165e-03,  1.0555e-02,\n",
       "                        1.7367e-03, -1.4553e-04, -3.8818e-04,  1.0762e-02,  4.5553e-03,\n",
       "                        5.0381e-03, -6.7350e-03,  2.3405e-03,  1.0998e-02, -7.9564e-03,\n",
       "                       -7.5867e-03,  1.5940e-02,  1.2957e-02, -1.7716e-02,  4.6793e-03,\n",
       "                       -8.7256e-03, -3.4280e-06, -9.9374e-03,  7.3291e-03,  1.6724e-03,\n",
       "                       -1.6445e-02,  1.6001e-02, -3.1150e-03,  1.3981e-02, -6.7233e-03,\n",
       "                       -1.8967e-02, -1.5542e-02,  1.0079e-02,  1.0647e-02, -4.5291e-03,\n",
       "                       -7.4709e-03, -8.3952e-03, -2.0425e-04, -1.1171e-02, -8.0143e-03,\n",
       "                        3.5194e-03,  1.2804e-02,  2.5484e-03,  3.7058e-04, -1.6303e-02,\n",
       "                        2.5731e-03, -1.1803e-02, -8.6698e-03, -3.4311e-03,  6.2759e-03,\n",
       "                        1.4905e-02,  2.9471e-03, -9.9909e-03,  8.5970e-03, -2.2102e-03,\n",
       "                        1.4904e-02, -4.5586e-03,  1.6977e-04,  7.8903e-03,  7.1207e-03,\n",
       "                       -2.3177e-03, -1.0521e-02,  9.5846e-03, -6.2679e-03, -1.8870e-03,\n",
       "                       -1.2558e-03,  7.8199e-03,  8.3003e-03, -4.9547e-04,  1.3487e-02,\n",
       "                       -8.2363e-03,  9.1660e-03,  5.6771e-03,  6.5019e-03, -5.1662e-03,\n",
       "                       -9.5293e-03,  3.6195e-03,  9.7989e-03,  4.1105e-03, -6.6221e-03,\n",
       "                        1.6273e-03,  2.5853e-03, -1.5632e-02, -1.3685e-02])),\n",
       "              ('net.models.0.mixing.0.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0267,  0.0414,  0.1102,  ...,  0.1256, -0.0669, -0.0155],\n",
       "                       [-0.0054,  0.0681,  0.1062,  ..., -0.0319,  0.1027, -0.0243],\n",
       "                       [-0.0774,  0.0831,  0.0020,  ...,  0.0249,  0.0923,  0.0560],\n",
       "                       ...,\n",
       "                       [ 0.0176,  0.0414, -0.0801,  ...,  0.0807,  0.1288, -0.1033],\n",
       "                       [-0.0283, -0.1178,  0.0260,  ..., -0.1102, -0.0155, -0.1203],\n",
       "                       [ 0.0690, -0.1027, -0.0624,  ...,  0.0831, -0.0530,  0.1305]])),\n",
       "              ('net.models.0.mixing.0.intraatomic_context_net.0.bias',\n",
       "               tensor([ 2.9938e-03, -1.0124e-02, -5.1120e-03, -1.2638e-03,  7.0765e-03,\n",
       "                        4.2977e-03,  1.3070e-03, -4.1655e-03,  1.8795e-03, -2.1013e-03,\n",
       "                        1.9589e-03, -3.2994e-03, -2.3228e-03,  9.7191e-05, -1.4142e-02,\n",
       "                       -3.1266e-03, -6.3237e-03,  5.2756e-03,  4.0413e-03, -1.2053e-02,\n",
       "                       -1.1259e-03,  5.9251e-03, -4.0866e-03, -4.5030e-03,  9.2379e-03,\n",
       "                        3.5743e-03, -7.0223e-03, -3.7414e-03, -7.2242e-03, -9.2387e-03,\n",
       "                       -1.2553e-02, -9.7178e-03,  7.1607e-04, -8.8090e-03, -5.2441e-03,\n",
       "                       -5.6255e-03, -1.6681e-02, -5.0059e-03, -9.0428e-03, -1.0714e-02,\n",
       "                       -2.0099e-03,  3.1505e-03,  1.1833e-03, -3.2552e-03,  1.7269e-03,\n",
       "                       -9.8449e-03, -5.6368e-03, -2.4686e-03, -8.6981e-03, -6.1061e-03,\n",
       "                       -8.2561e-03, -2.3113e-02, -4.2795e-03, -3.8083e-03, -6.2318e-03,\n",
       "                       -2.5611e-03, -1.2261e-03,  2.3633e-03, -1.4645e-02, -6.9437e-03,\n",
       "                       -4.3946e-03, -7.1015e-03, -5.4481e-03,  4.0870e-03, -8.6509e-06,\n",
       "                        3.2191e-03, -1.2665e-02,  3.7828e-03, -6.9887e-03, -4.5632e-03,\n",
       "                       -2.5567e-02,  2.2240e-03, -6.3612e-03, -5.5752e-03, -3.0248e-03,\n",
       "                       -1.2640e-03,  7.2312e-03,  3.9428e-03,  1.8113e-02, -1.2950e-03,\n",
       "                       -3.0994e-03, -2.5630e-03, -3.4905e-03,  2.3028e-03, -1.1285e-02,\n",
       "                        4.7750e-03,  3.4993e-03,  3.5980e-03, -6.0722e-03, -1.6682e-03,\n",
       "                       -1.4738e-02, -3.0964e-03, -1.0549e-03, -4.5916e-03, -4.5911e-03,\n",
       "                       -4.0937e-03, -3.4904e-03, -1.0405e-02, -6.0463e-03, -3.9703e-04,\n",
       "                       -8.2187e-03, -4.5384e-03, -5.8075e-04,  5.9024e-03,  9.6326e-03,\n",
       "                        1.5232e-03, -2.2100e-02,  4.5187e-04,  5.1185e-03,  5.8639e-03,\n",
       "                       -1.5922e-02, -1.3135e-03, -3.0282e-03, -2.3660e-03, -6.8613e-03,\n",
       "                        6.5425e-03, -3.6568e-03,  7.6457e-04, -1.2321e-03, -6.2119e-03,\n",
       "                       -5.3441e-03,  1.6846e-03,  6.5876e-03, -7.7850e-03,  8.4426e-04,\n",
       "                        3.8505e-03, -1.5467e-03,  9.7480e-03])),\n",
       "              ('net.models.0.mixing.0.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0448, -0.0599,  0.0298,  ...,  0.0628,  0.0532, -0.0856],\n",
       "                       [ 0.0846,  0.0508,  0.0490,  ..., -0.0286,  0.0375, -0.0276],\n",
       "                       [ 0.0003, -0.0596, -0.0067,  ..., -0.0477, -0.0053,  0.0048],\n",
       "                       ...,\n",
       "                       [-0.0524,  0.0128, -0.0302,  ..., -0.0093, -0.0021, -0.0590],\n",
       "                       [-0.0002,  0.0157, -0.0362,  ..., -0.0020,  0.0552, -0.0887],\n",
       "                       [ 0.0447,  0.0526, -0.0802,  ...,  0.0502,  0.0472, -0.0338]])),\n",
       "              ('net.models.0.mixing.0.intraatomic_context_net.1.bias',\n",
       "               tensor([-3.7967e-03, -9.0244e-03,  6.4838e-04,  2.9372e-03, -1.0160e-02,\n",
       "                       -5.1364e-03,  8.5387e-03,  8.2701e-03, -3.1523e-03,  5.4392e-03,\n",
       "                        1.0244e-03,  4.3866e-04,  1.1268e-02,  9.4553e-03, -6.5840e-03,\n",
       "                       -9.2328e-03, -7.3566e-03, -9.2143e-04, -4.7678e-04,  1.8917e-03,\n",
       "                        8.1459e-03,  1.5300e-02,  6.1422e-03,  1.4450e-02, -3.1696e-03,\n",
       "                       -9.2585e-03,  2.4854e-03,  8.2166e-03,  1.0548e-02,  1.0587e-02,\n",
       "                        1.0210e-02,  5.6384e-04, -1.1337e-02, -4.8967e-03, -1.6269e-02,\n",
       "                       -5.1412e-03, -2.9990e-03, -1.5491e-03, -1.5622e-02,  1.3867e-04,\n",
       "                       -4.8813e-05, -5.3726e-03, -4.2400e-03,  6.5509e-03, -4.5682e-04,\n",
       "                       -4.6195e-03, -1.2071e-03, -5.4379e-03, -1.5598e-03,  3.9614e-03,\n",
       "                        9.9903e-03,  2.7387e-03,  8.1068e-03, -2.4665e-03,  7.1570e-04,\n",
       "                       -6.8732e-03, -3.2646e-04,  1.2280e-02, -4.0282e-03,  1.2219e-02,\n",
       "                        6.6298e-03, -2.0481e-03,  5.3549e-03,  1.0152e-02, -6.3565e-03,\n",
       "                       -5.6780e-03,  3.8805e-04, -3.5372e-03,  1.3192e-03,  2.5592e-03,\n",
       "                       -7.1898e-03,  1.0158e-02, -1.4350e-02, -7.1088e-03,  9.5456e-03,\n",
       "                        2.5814e-03, -2.1038e-03,  8.9226e-03,  2.6631e-03,  4.7501e-03,\n",
       "                       -9.1618e-03,  9.8271e-05,  7.6572e-04, -6.1030e-03,  1.3027e-02,\n",
       "                        9.3575e-03, -6.6538e-03,  4.3979e-03,  2.9878e-04,  1.4969e-02,\n",
       "                       -1.7230e-02,  5.0764e-03,  4.1170e-03, -6.7109e-03, -9.0793e-03,\n",
       "                       -3.7736e-03, -3.7902e-03, -3.2838e-03, -3.5977e-03,  1.6455e-02,\n",
       "                       -9.7287e-03, -7.4036e-03,  6.4305e-03,  7.7384e-03,  5.6035e-03,\n",
       "                       -1.6306e-03,  3.9588e-03,  7.9484e-03, -1.4468e-03, -6.8712e-04,\n",
       "                       -5.0270e-03, -1.0488e-03,  2.3116e-03, -6.5514e-03, -6.9994e-03,\n",
       "                        5.9130e-03,  1.5627e-02, -1.3382e-03,  1.2775e-02,  3.7877e-03,\n",
       "                       -1.1056e-02, -1.2951e-03,  1.0982e-02,  1.6372e-03, -3.9487e-03,\n",
       "                       -1.1382e-02,  1.6737e-03, -1.6498e-03, -6.6492e-03, -8.1687e-03,\n",
       "                        6.9432e-03, -6.4363e-03,  2.0001e-03, -1.3093e-02, -1.0203e-02,\n",
       "                        5.6448e-03, -8.3310e-03, -2.3227e-03, -6.3184e-03, -1.9800e-03,\n",
       "                       -4.3040e-03,  4.6755e-03,  1.2090e-03,  2.2427e-03, -6.4207e-03,\n",
       "                       -5.5647e-03, -5.1513e-03,  1.1731e-02,  8.2862e-03,  1.4577e-02,\n",
       "                        4.2300e-03, -1.8989e-03,  6.5588e-03, -1.0981e-02,  1.3281e-02,\n",
       "                        7.2290e-03,  1.0312e-04, -1.8012e-03, -4.7335e-03, -3.6166e-03,\n",
       "                        2.3705e-04, -1.4208e-03,  8.7387e-04, -3.3770e-03,  2.1860e-03,\n",
       "                       -5.6712e-03,  4.4615e-03, -1.6140e-03, -2.6286e-03, -5.4567e-03,\n",
       "                        2.3599e-04,  6.6362e-04, -1.1228e-04,  6.9615e-03,  3.4257e-03,\n",
       "                       -7.1628e-03, -2.1705e-03,  1.5615e-02, -1.1260e-02,  5.1082e-03,\n",
       "                        1.4190e-02,  1.2997e-02,  2.8801e-03,  1.5865e-03, -4.2839e-03,\n",
       "                        5.9283e-03, -5.1600e-03,  7.5579e-03, -1.3988e-03,  7.3794e-03,\n",
       "                       -1.6319e-03,  5.1955e-04, -9.4264e-03,  4.6780e-03, -1.9628e-03,\n",
       "                       -4.2837e-04, -2.7028e-03,  2.4368e-03,  2.2014e-03, -8.3627e-03,\n",
       "                        2.2235e-02, -1.7901e-03, -5.9688e-03,  1.0790e-02,  3.1866e-04,\n",
       "                        3.9097e-03, -3.1519e-03, -6.4780e-03,  2.9004e-03, -7.4681e-03,\n",
       "                        5.2449e-03, -1.8241e-03, -6.1215e-04,  5.7604e-03,  8.0623e-03,\n",
       "                        4.5296e-03,  9.2167e-03, -3.4516e-03, -1.1001e-02,  1.4067e-02,\n",
       "                        1.8467e-02,  7.0151e-04,  1.4783e-02,  7.2331e-03,  4.2277e-03,\n",
       "                       -2.7507e-03, -5.8706e-03,  1.4157e-02,  1.1699e-02, -3.2150e-04,\n",
       "                       -1.4146e-03,  1.2096e-02, -7.3792e-03, -7.7192e-03,  8.3876e-03,\n",
       "                       -6.2320e-03, -1.4291e-02,  5.8001e-03,  3.7330e-03, -6.5687e-03,\n",
       "                        1.6671e-03, -2.2608e-03,  6.5772e-03, -4.6545e-03, -5.6989e-03,\n",
       "                        5.4417e-03, -4.5295e-03,  2.1635e-03,  1.1482e-02,  5.2744e-03,\n",
       "                        6.2158e-03, -3.0007e-03, -2.4871e-03,  8.2655e-03,  7.2301e-03,\n",
       "                        8.2178e-03, -5.6244e-03,  8.0283e-03,  8.1157e-04,  5.1216e-03,\n",
       "                       -1.3614e-03, -2.5429e-03,  2.8631e-03, -1.7640e-03, -2.6309e-03,\n",
       "                        1.6214e-02,  1.0286e-02, -4.8988e-03, -4.3645e-04, -4.2117e-04,\n",
       "                        6.6431e-03, -6.1751e-03,  1.1129e-02, -1.5702e-03, -1.7785e-02,\n",
       "                        1.6363e-03, -2.9131e-03,  1.6912e-02, -9.9940e-03,  1.3487e-03,\n",
       "                        2.4556e-03,  2.9423e-03,  9.5683e-03, -2.0811e-03, -1.0552e-02,\n",
       "                       -1.3922e-02, -1.1280e-02, -3.8054e-03,  3.4823e-03,  8.4337e-03,\n",
       "                       -1.4645e-02, -3.7207e-03,  5.6484e-03,  1.7807e-02, -3.6440e-03,\n",
       "                       -1.1217e-02,  1.8110e-03, -5.4267e-03, -8.1229e-03, -8.2848e-04,\n",
       "                        1.2200e-02, -2.7085e-03, -1.0922e-03,  7.1875e-03,  1.8737e-03,\n",
       "                        5.8130e-03, -1.5055e-03,  7.2409e-03, -2.7673e-04, -2.1394e-03,\n",
       "                       -1.9503e-03, -1.1529e-02, -5.8388e-04,  1.4629e-03, -8.9027e-03,\n",
       "                       -5.7463e-03,  3.8388e-03,  1.0378e-02, -8.3861e-03,  1.6847e-02,\n",
       "                       -2.4213e-03, -1.0655e-03, -2.9661e-03, -9.9476e-03,  4.1506e-03,\n",
       "                        1.1340e-02,  6.6736e-03, -8.3472e-03,  1.9000e-02,  4.4533e-04,\n",
       "                       -3.0964e-03,  6.1794e-04, -5.6336e-03, -7.9098e-03, -4.2107e-03,\n",
       "                       -1.4754e-02,  8.8835e-04, -5.5318e-03,  9.4647e-03, -1.4983e-02,\n",
       "                       -1.8971e-02, -7.0650e-03,  3.3356e-03,  3.5138e-03, -6.0561e-03,\n",
       "                        8.4638e-03,  2.2306e-03,  5.8549e-04,  1.2354e-02, -1.8296e-03,\n",
       "                        1.2925e-02,  5.3408e-04,  1.1204e-02, -2.4926e-05, -9.9634e-03,\n",
       "                        1.0857e-02, -1.7806e-03, -3.1166e-03, -8.4667e-03, -5.7191e-04,\n",
       "                        1.8471e-03, -3.6509e-04,  1.6468e-02, -1.0752e-02,  2.9015e-03,\n",
       "                       -6.8969e-03,  6.8132e-03, -5.1037e-03,  5.1766e-03,  1.4635e-02,\n",
       "                        2.8801e-03,  3.0851e-03,  6.8295e-03, -1.1919e-04, -1.0958e-03,\n",
       "                       -3.1721e-03, -7.1477e-03, -2.8328e-03,  9.5858e-03, -1.0170e-02,\n",
       "                       -8.8476e-04, -9.1533e-04,  4.3577e-03, -4.7246e-03])),\n",
       "              ('net.models.0.mixing.0.mu_channel_mix.weight',\n",
       "               tensor([[ 0.1225,  0.0291,  0.0970,  ..., -0.0689,  0.0118,  0.0801],\n",
       "                       [ 0.0672,  0.0043, -0.0438,  ...,  0.0811,  0.0831,  0.1106],\n",
       "                       [ 0.0931, -0.0796, -0.1351,  ..., -0.0195,  0.0754,  0.0371],\n",
       "                       ...,\n",
       "                       [-0.0763,  0.0278, -0.0532,  ...,  0.1079,  0.0925,  0.0731],\n",
       "                       [ 0.0036, -0.0739,  0.0957,  ..., -0.0244,  0.0829, -0.0796],\n",
       "                       [ 0.0508, -0.0350,  0.0753,  ...,  0.0945,  0.1169,  0.1291]])),\n",
       "              ('net.models.0.mixing.1.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0967,  0.1068,  0.0443,  ..., -0.0144,  0.0086,  0.0192],\n",
       "                       [-0.0303, -0.0442, -0.0932,  ...,  0.1041, -0.0146, -0.1009],\n",
       "                       [-0.1245, -0.1024,  0.0973,  ...,  0.1006, -0.0356,  0.0928],\n",
       "                       ...,\n",
       "                       [-0.0749, -0.0440, -0.0425,  ..., -0.0346,  0.0025, -0.0559],\n",
       "                       [ 0.0050,  0.0742, -0.1043,  ..., -0.0311,  0.0576,  0.0912],\n",
       "                       [ 0.0065, -0.0559,  0.0587,  ...,  0.0782, -0.1003, -0.0702]])),\n",
       "              ('net.models.0.mixing.1.intraatomic_context_net.0.bias',\n",
       "               tensor([ 6.7289e-03, -2.9227e-03, -1.0884e-02,  2.1212e-03,  7.8756e-03,\n",
       "                       -1.3143e-02, -3.8045e-03, -3.0357e-03,  1.4504e-02, -9.1103e-03,\n",
       "                       -3.5852e-03, -7.9702e-04, -4.2442e-03, -3.7455e-03, -4.3637e-03,\n",
       "                       -6.1968e-03, -5.3354e-03, -1.8929e-04, -1.4531e-02, -4.7787e-03,\n",
       "                       -1.7044e-03,  6.4225e-04, -1.0231e-02, -3.3748e-04, -4.1770e-03,\n",
       "                        1.7628e-04, -1.9206e-03,  2.8717e-03, -1.0027e-02,  3.2563e-03,\n",
       "                       -1.0407e-03,  2.6556e-03, -1.5939e-03,  1.1951e-03,  1.0691e-02,\n",
       "                       -9.9317e-03,  1.7746e-03,  2.1954e-03,  5.8721e-03, -1.5672e-02,\n",
       "                        6.7986e-03, -1.2958e-02,  5.1979e-04, -4.7293e-03,  9.6560e-03,\n",
       "                       -2.0741e-03,  6.1855e-04,  1.3780e-03, -6.6777e-03, -8.0057e-05,\n",
       "                       -5.7516e-03, -4.1550e-03, -1.1735e-02,  1.3995e-04,  4.4352e-03,\n",
       "                       -1.8586e-03, -6.0441e-03,  7.4664e-03, -8.1266e-03,  1.0639e-03,\n",
       "                        1.1354e-02, -2.8277e-03,  2.8483e-03, -2.6541e-03, -7.2326e-03,\n",
       "                        2.3372e-03, -2.8700e-03, -1.0924e-04, -2.4395e-03, -3.9398e-04,\n",
       "                       -9.6714e-03, -5.4854e-03, -3.8513e-03, -1.0399e-03, -5.2419e-03,\n",
       "                       -1.5194e-03,  3.9735e-03, -9.3731e-04, -1.0830e-03,  1.3806e-03,\n",
       "                       -1.0468e-02,  4.4371e-03, -3.1798e-03,  2.6841e-03, -2.1294e-02,\n",
       "                       -6.2192e-03,  6.4294e-03, -5.2372e-03, -1.7184e-02, -6.8207e-03,\n",
       "                       -2.7696e-03, -8.3681e-03, -1.5532e-03, -1.0946e-02,  5.0449e-04,\n",
       "                       -1.7485e-03,  3.4980e-03, -3.5715e-03, -7.9568e-03,  1.1036e-03,\n",
       "                       -7.6768e-03,  9.2947e-03,  1.1113e-02, -3.0400e-03, -6.0824e-03,\n",
       "                        1.2337e-02,  9.1600e-04, -7.2249e-03,  8.9393e-03,  8.7975e-03,\n",
       "                        1.6799e-03, -1.0822e-02, -7.7878e-03,  7.3004e-03, -6.2864e-04,\n",
       "                       -1.5036e-03, -4.5610e-03, -4.7621e-03,  4.9088e-03,  3.0219e-03,\n",
       "                       -5.3588e-03, -8.2663e-03, -2.3097e-03, -2.0106e-02,  8.8244e-03,\n",
       "                       -7.7248e-03, -8.4945e-03, -1.5152e-03])),\n",
       "              ('net.models.0.mixing.1.intraatomic_context_net.1.weight',\n",
       "               tensor([[-0.0950,  0.0742, -0.0784,  ...,  0.0355,  0.0202, -0.1003],\n",
       "                       [-0.0291, -0.0335,  0.0161,  ..., -0.0448, -0.0753, -0.0641],\n",
       "                       [ 0.0512, -0.1035, -0.0006,  ...,  0.0308, -0.0056, -0.0852],\n",
       "                       ...,\n",
       "                       [-0.0671,  0.0997,  0.1020,  ...,  0.0391,  0.0129,  0.0492],\n",
       "                       [-0.0839, -0.0254,  0.0472,  ...,  0.0961, -0.0183, -0.0224],\n",
       "                       [-0.0843,  0.0715, -0.0238,  ...,  0.0417, -0.0665,  0.0679]])),\n",
       "              ('net.models.0.mixing.1.intraatomic_context_net.1.bias',\n",
       "               tensor([-3.0600e-03, -6.7156e-03, -1.5309e-03,  3.9627e-03, -7.0997e-03,\n",
       "                       -5.4080e-04,  8.9204e-03,  7.3338e-03,  1.3141e-03,  3.0619e-03,\n",
       "                        4.8788e-04,  6.1460e-03,  8.7750e-03,  1.0119e-02, -4.4561e-03,\n",
       "                       -6.4592e-03, -4.3151e-03, -6.8851e-04, -2.3112e-04,  4.5700e-03,\n",
       "                        6.7689e-03,  7.8907e-03,  5.8471e-04,  1.3685e-02, -1.6741e-03,\n",
       "                       -6.2715e-03,  1.7133e-03,  6.2414e-03,  8.4122e-03,  1.3543e-02,\n",
       "                        8.1699e-03,  1.7829e-03, -7.6351e-03, -3.0429e-03, -1.3621e-02,\n",
       "                       -1.2631e-03, -4.4651e-03, -4.2802e-03, -1.1216e-02,  2.1136e-03,\n",
       "                        2.4936e-03, -4.6018e-03, -5.0527e-03, -7.7210e-04,  1.6026e-03,\n",
       "                       -3.6350e-03,  6.0595e-03, -3.0196e-03, -1.3064e-03,  2.5584e-03,\n",
       "                        8.5591e-03, -4.5598e-03,  9.4821e-03, -1.7386e-03, -1.4363e-03,\n",
       "                       -8.3007e-03,  5.5758e-03,  4.7252e-04,  4.9185e-05,  8.6509e-03,\n",
       "                        6.3804e-03, -2.2302e-03,  2.9550e-04,  6.5662e-03, -7.2140e-03,\n",
       "                       -4.4791e-03,  8.5944e-04, -1.3573e-03,  2.9237e-04,  1.4757e-03,\n",
       "                       -3.4488e-03,  6.4517e-03, -1.7226e-02, -9.2316e-03,  8.6126e-03,\n",
       "                        2.8234e-03, -1.4828e-03,  4.5836e-03,  3.0286e-03,  6.5544e-03,\n",
       "                       -1.0235e-02,  4.7707e-04, -2.9576e-03, -7.8035e-03,  8.0506e-03,\n",
       "                        9.0267e-03, -7.1641e-03,  2.7828e-03, -3.5579e-03,  1.3008e-02,\n",
       "                       -1.7031e-02,  3.1473e-03,  2.3527e-03, -6.2734e-03, -8.0642e-03,\n",
       "                       -8.0588e-03, -3.5393e-03, -1.0598e-02, -2.5730e-03,  1.4401e-02,\n",
       "                       -7.9064e-03, -6.2110e-03,  5.3188e-03,  8.2506e-03,  4.7168e-03,\n",
       "                        4.8163e-03,  5.6904e-03,  6.7725e-03,  1.7014e-03,  1.8291e-03,\n",
       "                       -4.5721e-03,  1.4260e-03, -1.5614e-03, -4.0051e-03, -1.0303e-02,\n",
       "                        1.6170e-03,  1.4807e-02, -2.6506e-03,  6.9276e-03, -8.1746e-05,\n",
       "                       -8.5076e-03,  1.7747e-04,  1.4809e-02, -1.7636e-03, -5.4595e-03,\n",
       "                       -5.8248e-03,  1.6365e-03, -2.1586e-03,  5.6918e-03,  1.6342e-03,\n",
       "                        6.2867e-03, -6.2199e-03,  9.5013e-03, -1.0327e-03,  1.1446e-02,\n",
       "                        6.6584e-03,  6.9687e-03,  2.9687e-03, -1.4226e-03, -9.5417e-04,\n",
       "                        5.5242e-03,  6.2236e-03, -1.2142e-02, -4.1838e-03,  8.1343e-04,\n",
       "                       -2.8399e-03,  3.0495e-03,  4.6543e-03, -4.1129e-03, -1.2591e-02,\n",
       "                       -1.0540e-02,  1.4107e-02, -9.0247e-03, -6.1769e-03, -1.3366e-03,\n",
       "                        1.1569e-04,  1.7264e-03,  7.2513e-04, -8.8712e-03,  1.5073e-03,\n",
       "                       -1.2178e-02,  7.2099e-03,  1.9582e-03, -6.5556e-03,  7.3809e-03,\n",
       "                        5.7151e-03, -2.1174e-03,  8.1328e-04, -1.3708e-02,  7.6555e-03,\n",
       "                       -7.7117e-03,  8.4437e-03,  5.7227e-03, -1.6095e-02, -1.0153e-02,\n",
       "                        3.1125e-03,  2.3727e-03, -1.6380e-02,  3.1249e-03, -3.9440e-03,\n",
       "                        4.0633e-03,  6.4204e-03,  3.2239e-03,  8.9003e-03,  2.6470e-04,\n",
       "                        2.5063e-03,  8.8543e-03, -1.1515e-02,  6.7280e-03, -4.4677e-03,\n",
       "                       -6.4088e-03, -3.7945e-03, -7.2958e-03,  5.1742e-03,  4.9359e-03,\n",
       "                       -1.8288e-02,  1.1008e-02, -1.6603e-02,  8.2989e-03,  8.7255e-03,\n",
       "                        1.0080e-02, -7.8268e-03, -6.4481e-03, -3.5924e-03, -3.1990e-03,\n",
       "                        4.0984e-03, -3.1302e-03, -3.7147e-03,  1.8740e-03, -1.2927e-02,\n",
       "                       -4.9615e-03, -1.2481e-02, -3.6962e-03, -3.4581e-03, -2.5387e-03,\n",
       "                        1.1496e-03,  6.2519e-03, -8.0982e-03,  5.1938e-03,  5.6557e-03,\n",
       "                       -1.1544e-03,  1.1039e-02,  4.6449e-03, -1.6382e-03,  2.6941e-03,\n",
       "                       -2.5899e-03,  4.7652e-03, -3.6347e-03,  5.3620e-03,  2.0838e-03,\n",
       "                        1.3071e-03, -9.7302e-03,  4.6304e-03,  1.6948e-02,  3.3015e-04,\n",
       "                       -1.2580e-02, -1.1837e-02, -9.5976e-04, -1.0848e-02, -6.0411e-03,\n",
       "                       -1.8018e-03,  1.8049e-03, -7.8519e-03, -9.4229e-03,  4.6992e-03,\n",
       "                        4.8506e-03,  6.2986e-03,  3.9899e-04, -6.1998e-03, -8.3310e-03,\n",
       "                       -9.9452e-03, -1.6624e-03, -3.7342e-04,  8.2013e-05, -2.7715e-03,\n",
       "                        2.9226e-03, -5.9279e-03, -6.8450e-03, -6.5494e-03,  6.6006e-03,\n",
       "                       -2.2734e-03, -5.3324e-03,  6.8643e-03,  6.0315e-04,  1.1633e-02,\n",
       "                        2.2074e-03, -2.6018e-03, -4.8888e-03, -5.3800e-03,  9.4880e-03,\n",
       "                       -5.8198e-03, -1.1963e-02, -1.2808e-02,  7.5753e-03,  2.4009e-03,\n",
       "                       -8.1876e-03,  3.1409e-03,  5.2725e-03, -1.8371e-03, -2.4649e-03,\n",
       "                        1.2096e-03, -4.4688e-03,  9.0216e-03,  2.8125e-04, -5.8199e-03,\n",
       "                        1.3574e-02, -5.1831e-03, -2.2277e-03,  2.8088e-03,  1.0247e-02,\n",
       "                        2.2152e-03, -6.1489e-04,  2.0178e-03, -3.8742e-04, -7.5158e-04,\n",
       "                        9.2112e-03,  1.3662e-02, -3.7028e-03,  1.4890e-03, -1.3609e-03,\n",
       "                       -1.7116e-02, -1.3672e-02,  7.5101e-03, -1.2651e-03,  1.3651e-02,\n",
       "                        9.3384e-04, -1.8036e-02,  2.2426e-02, -1.2225e-02, -2.4561e-04,\n",
       "                        5.1482e-03, -6.2425e-04, -1.1114e-02,  5.3571e-03, -1.8152e-03,\n",
       "                       -4.8849e-03,  1.5791e-03,  5.5240e-03, -8.4978e-03, -5.5220e-03,\n",
       "                       -7.8278e-03, -2.3053e-03,  7.5276e-03,  8.1247e-03,  5.5251e-04,\n",
       "                        3.7366e-03,  1.2127e-02, -9.7458e-04, -1.1013e-03,  6.0494e-04,\n",
       "                       -7.5766e-03,  9.0464e-03, -4.9131e-03, -8.3426e-03, -5.9631e-03,\n",
       "                        7.2059e-03, -7.5540e-03,  8.2525e-03,  5.1366e-03, -5.3337e-03,\n",
       "                       -4.4073e-03, -9.7067e-03, -3.3469e-03,  2.9134e-03, -4.0092e-03,\n",
       "                       -5.7745e-03, -1.0928e-02,  2.5954e-03,  1.2352e-02, -6.0581e-03,\n",
       "                        1.0425e-02,  6.0625e-03,  6.5002e-03, -2.7191e-03,  9.5795e-03,\n",
       "                        1.1051e-02,  1.3250e-03,  9.8907e-03,  1.1103e-02,  1.0421e-02,\n",
       "                        3.4618e-03,  2.6793e-03,  8.3523e-04,  3.9804e-03,  4.6047e-04,\n",
       "                        5.7656e-03, -1.5805e-02,  1.1572e-03, -8.5970e-03, -6.0052e-03,\n",
       "                        6.6182e-03, -7.1578e-03,  3.6508e-03,  5.9092e-04,  9.8280e-03,\n",
       "                       -2.5990e-03, -5.6142e-03,  2.7514e-03,  1.7221e-03,  1.1249e-02,\n",
       "                       -1.7259e-03,  4.5073e-03, -1.8606e-04,  8.5852e-04])),\n",
       "              ('net.models.0.mixing.1.mu_channel_mix.weight',\n",
       "               tensor([[-0.0224, -0.0624, -0.0566,  ...,  0.0328, -0.0071, -0.0489],\n",
       "                       [ 0.1026,  0.0134,  0.0383,  ...,  0.0105,  0.0681,  0.0169],\n",
       "                       [ 0.1036,  0.0016, -0.1219,  ..., -0.0322, -0.0459,  0.0750],\n",
       "                       ...,\n",
       "                       [-0.0590, -0.0918,  0.0206,  ...,  0.0093, -0.1154,  0.0778],\n",
       "                       [-0.0347, -0.1013,  0.1213,  ...,  0.0142,  0.1132,  0.1080],\n",
       "                       [-0.0702, -0.0983, -0.0631,  ..., -0.0766,  0.0080,  0.0546]])),\n",
       "              ('net.models.0.mixing.2.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0023,  0.0593, -0.1143,  ..., -0.0221,  0.0218,  0.1099],\n",
       "                       [-0.0276, -0.0199,  0.0025,  ...,  0.0587,  0.0172, -0.1302],\n",
       "                       [ 0.1183,  0.1137,  0.0023,  ..., -0.1014, -0.0286, -0.0350],\n",
       "                       ...,\n",
       "                       [ 0.0325, -0.0283,  0.0637,  ...,  0.0695, -0.0246, -0.0845],\n",
       "                       [ 0.0026,  0.0023,  0.0905,  ..., -0.1209,  0.0732, -0.1294],\n",
       "                       [ 0.0315,  0.0339, -0.0675,  ...,  0.0828,  0.1144,  0.0620]])),\n",
       "              ('net.models.0.mixing.2.intraatomic_context_net.0.bias',\n",
       "               tensor([-9.7401e-03, -9.6045e-03, -9.6307e-04, -8.1431e-03,  3.1496e-03,\n",
       "                       -5.3287e-04, -2.0610e-03, -4.3309e-03,  3.4582e-03, -9.6006e-03,\n",
       "                       -1.6097e-03, -1.0745e-03, -1.4303e-03, -2.7400e-03, -3.1138e-03,\n",
       "                        1.7807e-04, -2.8731e-03, -8.2361e-03, -5.0235e-03, -1.0981e-03,\n",
       "                        5.5509e-03, -8.5285e-03,  1.6192e-04,  7.6121e-04, -8.1869e-03,\n",
       "                       -9.3029e-03, -2.3415e-03, -5.0888e-03, -2.3681e-03,  4.1335e-03,\n",
       "                       -1.8527e-02, -6.4679e-03, -2.2673e-03, -6.7256e-03, -6.4744e-03,\n",
       "                       -9.4690e-03, -2.0185e-03, -6.5454e-04, -4.7889e-03,  2.5613e-03,\n",
       "                       -7.9784e-03, -1.3171e-04,  4.8046e-03,  6.6723e-03,  4.0905e-04,\n",
       "                       -4.6511e-03,  2.8664e-03,  1.3190e-02,  3.0264e-03, -2.0794e-03,\n",
       "                       -1.7815e-03,  1.0151e-02, -3.4471e-03, -4.6355e-03, -9.1111e-03,\n",
       "                       -3.7905e-04, -1.4990e-02, -2.9985e-03, -2.4233e-03,  2.6959e-03,\n",
       "                       -5.2051e-03,  3.5252e-04,  3.1451e-03, -1.4246e-03, -1.8104e-03,\n",
       "                        5.0901e-03, -6.7669e-04,  1.6917e-03, -2.6407e-03,  4.5512e-03,\n",
       "                       -2.9205e-03,  3.9333e-03, -8.1991e-03, -7.3100e-03,  3.1666e-03,\n",
       "                        1.3382e-02,  5.5412e-04, -6.5393e-03, -7.4291e-03, -3.5235e-03,\n",
       "                       -3.5065e-04, -7.7722e-03,  8.4773e-03, -2.4329e-03, -1.2392e-02,\n",
       "                        4.6667e-03, -6.6935e-03,  7.0683e-03,  1.0412e-02, -5.3728e-03,\n",
       "                       -6.6991e-03, -3.9284e-03, -9.0023e-03,  1.7669e-03,  3.1149e-03,\n",
       "                        3.2799e-03, -2.3510e-03,  5.5054e-03, -2.8735e-03, -8.4977e-03,\n",
       "                        8.9004e-03, -3.2006e-03, -2.7956e-03, -1.1191e-02, -8.0716e-03,\n",
       "                       -5.5276e-03, -6.1449e-04,  1.3555e-02, -3.3983e-03,  6.7840e-05,\n",
       "                       -7.8754e-03,  1.2860e-02, -1.1429e-03,  6.0733e-03, -2.9015e-03,\n",
       "                        3.9970e-04, -1.9337e-03, -1.8245e-03, -1.7909e-03,  2.6976e-03,\n",
       "                       -4.7783e-03, -3.6140e-03, -3.4980e-03,  1.2004e-03, -2.7471e-03,\n",
       "                        3.2630e-03, -3.5662e-03, -7.2791e-04])),\n",
       "              ('net.models.0.mixing.2.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0839, -0.0279, -0.0534,  ...,  0.0026, -0.0833, -0.1068],\n",
       "                       [-0.0332,  0.0276,  0.0279,  ..., -0.0159, -0.0671, -0.0006],\n",
       "                       [-0.0997,  0.0202, -0.0450,  ..., -0.0186,  0.0204,  0.1052],\n",
       "                       ...,\n",
       "                       [ 0.0823,  0.0446, -0.0095,  ...,  0.0715, -0.1125, -0.0070],\n",
       "                       [-0.0568,  0.0354,  0.0383,  ...,  0.0360,  0.0746, -0.0118],\n",
       "                       [ 0.0635,  0.0426,  0.0713,  ..., -0.0321, -0.0129, -0.0970]])),\n",
       "              ('net.models.0.mixing.2.intraatomic_context_net.1.bias',\n",
       "               tensor([-1.9414e-03, -9.8348e-03, -2.9670e-03,  2.1775e-03, -9.2591e-03,\n",
       "                       -1.6770e-03,  1.1538e-02,  4.4709e-03,  1.9889e-03,  3.2397e-03,\n",
       "                        2.0612e-03,  4.5197e-03,  1.2477e-02,  8.6159e-03, -2.4980e-03,\n",
       "                       -3.2264e-03, -4.9812e-03, -5.8281e-04, -1.8351e-03,  4.0737e-03,\n",
       "                        6.2450e-03,  4.0389e-03,  2.0306e-03,  8.3510e-03,  4.6911e-03,\n",
       "                       -3.9237e-03, -3.9506e-03,  2.5157e-03,  6.7015e-03,  6.7205e-03,\n",
       "                        9.7469e-03, -1.0213e-04, -2.8622e-03,  8.4104e-04, -8.3431e-03,\n",
       "                       -2.4314e-03, -1.8098e-03, -2.2240e-03, -9.8360e-03,  2.3011e-03,\n",
       "                        8.4709e-04, -3.7853e-03, -3.5298e-03,  1.5257e-03, -2.1153e-03,\n",
       "                       -5.8244e-03,  8.8331e-03, -5.0194e-03, -2.5494e-03,  1.3500e-03,\n",
       "                        4.1201e-03, -4.2086e-03,  5.3700e-03, -1.9702e-03,  5.0299e-05,\n",
       "                       -4.2610e-03,  7.6169e-03,  1.0351e-03, -1.4728e-03,  6.3241e-03,\n",
       "                        6.0879e-03,  5.6285e-04,  1.4781e-03,  9.9728e-03, -8.2522e-03,\n",
       "                       -4.3717e-03,  5.2857e-04, -7.3994e-04, -1.2983e-03,  9.9694e-04,\n",
       "                       -4.1896e-03,  4.0727e-03, -7.6568e-03, -7.5529e-03,  3.7334e-03,\n",
       "                        2.1149e-03,  1.1835e-03,  6.6824e-03,  3.3062e-03,  5.2700e-03,\n",
       "                       -9.5810e-03,  2.0524e-04, -7.0465e-03, -7.6770e-03,  1.7576e-03,\n",
       "                        1.9366e-03, -3.3459e-03,  2.7983e-03, -6.2347e-03,  5.8479e-03,\n",
       "                       -7.5262e-03,  1.6168e-03,  1.3428e-03, -5.2606e-03, -1.9088e-03,\n",
       "                       -4.3659e-03, -4.1773e-03, -1.2546e-02, -1.0300e-03,  7.7884e-03,\n",
       "                       -5.0322e-03, -4.2764e-03,  4.5783e-03,  5.2245e-03,  5.1640e-03,\n",
       "                       -1.6203e-03,  3.5095e-03,  4.4252e-03, -9.5080e-04,  1.8618e-03,\n",
       "                       -4.5466e-03,  7.4181e-04,  4.4768e-04, -1.1467e-03, -6.6625e-03,\n",
       "                        4.0030e-03,  1.2359e-02, -4.7909e-03,  1.9469e-03, -1.0107e-02,\n",
       "                       -6.2526e-03,  1.6914e-04,  9.8231e-03,  1.0339e-03, -6.8248e-03,\n",
       "                       -3.5894e-03,  3.7280e-03, -1.6319e-03, -9.4533e-03,  1.3623e-03,\n",
       "                        3.1440e-03, -2.6913e-03,  1.8610e-02, -2.8690e-03, -7.4159e-03,\n",
       "                       -7.6665e-03, -1.1148e-02,  2.6843e-03, -7.0731e-04,  3.5153e-03,\n",
       "                        5.9214e-03, -4.1010e-03, -7.0829e-04, -5.3434e-03,  3.7324e-03,\n",
       "                        9.0435e-04,  2.5030e-03, -3.6897e-03,  4.5620e-04, -8.1893e-03,\n",
       "                       -5.9902e-05, -7.3182e-04, -1.3437e-02, -2.6689e-03,  5.4876e-03,\n",
       "                       -7.6014e-04, -1.0051e-03,  2.5250e-03,  6.2575e-03, -6.2606e-03,\n",
       "                       -3.0066e-04,  2.1364e-03,  5.4116e-03, -4.9789e-03, -2.8657e-03,\n",
       "                       -5.2363e-03,  7.2153e-03, -3.1603e-03, -3.2196e-03,  2.7746e-03,\n",
       "                        7.6119e-03, -2.3943e-03,  1.1686e-02, -1.1882e-03, -3.0000e-03,\n",
       "                       -1.0444e-03,  9.0989e-03, -6.5463e-03, -1.4542e-04,  2.6509e-03,\n",
       "                       -2.9172e-03,  1.4184e-03, -3.8020e-03,  1.1497e-03,  1.4246e-02,\n",
       "                       -1.2143e-03, -2.4406e-03, -9.4939e-03,  3.1241e-03,  9.5754e-03,\n",
       "                        4.6298e-03,  2.6861e-03,  7.1073e-03, -3.0308e-03, -2.7617e-03,\n",
       "                        6.7690e-03, -1.5714e-02, -6.1803e-03,  8.1445e-04, -3.0659e-03,\n",
       "                       -7.3858e-05, -9.2190e-04,  3.8145e-03,  7.9912e-03,  7.7975e-03,\n",
       "                       -8.6011e-03,  1.2470e-02,  5.8747e-03, -3.1258e-03,  1.0068e-02,\n",
       "                       -7.4267e-03, -3.4045e-03, -9.5404e-03, -1.7639e-03, -6.9013e-03,\n",
       "                        3.3979e-03,  6.5003e-03, -7.8903e-03, -4.1389e-03,  6.1194e-03,\n",
       "                       -1.1352e-02, -8.8659e-03,  1.0790e-02, -1.6372e-03, -7.4947e-03,\n",
       "                       -1.3343e-03, -1.3843e-02, -2.1270e-03,  3.1349e-03, -5.1699e-03,\n",
       "                       -7.0760e-03, -1.8484e-04, -1.1443e-02,  4.7127e-03, -1.2667e-02,\n",
       "                       -2.4759e-03,  2.0925e-03,  3.9085e-03,  4.9939e-04,  6.1222e-03,\n",
       "                        3.9061e-03, -9.0786e-03, -4.5866e-03, -1.5327e-03,  9.2919e-03,\n",
       "                       -5.2647e-03,  5.3196e-04, -5.1783e-03,  5.4791e-03,  2.0370e-04,\n",
       "                       -3.8978e-03, -8.2964e-04,  4.5345e-03,  6.9653e-03, -5.2362e-03,\n",
       "                       -7.0120e-03, -1.0474e-02, -5.0170e-03, -3.6550e-03, -2.4624e-03,\n",
       "                        1.0901e-02, -1.1505e-02,  1.7096e-03, -4.7963e-03, -4.6004e-03,\n",
       "                        6.8152e-03, -1.0268e-03, -1.4590e-02, -9.3593e-04, -7.9330e-03,\n",
       "                       -6.1075e-03, -1.1063e-03,  9.1894e-03,  5.9053e-03,  9.9908e-03,\n",
       "                        8.8405e-04,  4.2080e-04,  5.8305e-03,  6.9998e-03, -2.1261e-02,\n",
       "                       -7.1238e-03, -9.9878e-03, -1.2043e-02,  4.7922e-03,  1.0762e-02,\n",
       "                       -2.6780e-03, -3.0618e-03, -1.4594e-03, -3.9155e-03, -2.3555e-03,\n",
       "                        1.8924e-02, -2.8355e-03, -1.6935e-03, -9.1053e-03,  3.3669e-03,\n",
       "                        1.3125e-02, -4.7625e-03,  1.6571e-03, -3.4511e-03, -3.2658e-03,\n",
       "                       -3.0625e-03, -5.4163e-03, -9.0703e-04,  3.8924e-03, -1.8913e-03,\n",
       "                        2.3053e-03, -2.8125e-03, -4.9283e-04, -4.4506e-04,  1.7928e-03,\n",
       "                       -6.0923e-04,  2.3313e-03, -5.1409e-03,  7.4897e-03, -7.2932e-03,\n",
       "                        5.6673e-03, -6.3371e-03,  1.2942e-03, -1.0328e-02, -5.8119e-03,\n",
       "                        4.7520e-03,  8.8968e-03,  5.7805e-03,  6.2861e-03,  1.4816e-02,\n",
       "                        1.3581e-02, -5.2045e-03, -8.4232e-04, -6.3490e-04, -6.3745e-03,\n",
       "                        3.0820e-03, -8.0038e-03, -2.5366e-03, -4.6156e-03,  4.9585e-03,\n",
       "                        2.6143e-03,  3.0111e-04, -2.1389e-03,  5.0882e-04, -1.2877e-03,\n",
       "                       -1.1205e-03,  6.9938e-03,  1.1356e-02,  2.7047e-03,  2.0306e-02,\n",
       "                       -1.1279e-03, -1.8405e-03,  6.5786e-03,  9.9013e-03, -5.2492e-03,\n",
       "                        4.2608e-04, -1.1181e-02, -1.0770e-02,  8.5436e-03, -2.1739e-03,\n",
       "                        1.0907e-02,  6.0464e-03, -4.0627e-04,  1.9406e-03,  7.9096e-03,\n",
       "                       -1.7160e-02, -1.3927e-02,  1.0522e-02,  6.1404e-03, -4.0431e-03,\n",
       "                       -8.0478e-04,  1.0239e-02,  1.1168e-02,  2.8860e-03,  4.5453e-03,\n",
       "                        7.4526e-03, -1.0691e-02, -1.2776e-02, -1.0624e-04, -1.9381e-03,\n",
       "                       -8.6569e-03, -6.1007e-03, -8.2660e-03, -4.2972e-04,  1.8408e-03,\n",
       "                        8.1664e-03,  1.3038e-02,  2.2648e-03,  5.2163e-03])),\n",
       "              ('net.models.0.mixing.2.mu_channel_mix.weight',\n",
       "               tensor([[ 0.0475, -0.0531,  0.0878,  ..., -0.0870, -0.1229,  0.0986],\n",
       "                       [-0.1198, -0.0499,  0.1063,  ..., -0.0543,  0.0758, -0.0736],\n",
       "                       [-0.0578, -0.1037, -0.1090,  ...,  0.0206, -0.0868,  0.1132],\n",
       "                       ...,\n",
       "                       [ 0.0879,  0.0078, -0.0932,  ...,  0.0211, -0.0611,  0.0710],\n",
       "                       [-0.0178, -0.0184,  0.0548,  ..., -0.0211, -0.1230,  0.0228],\n",
       "                       [-0.0083, -0.0801,  0.0286,  ...,  0.0283, -0.0377,  0.1073]])),\n",
       "              ('net.models.0.mixing.3.intraatomic_context_net.0.weight',\n",
       "               tensor([[-0.0506, -0.0829, -0.1290,  ...,  0.0709,  0.1014, -0.0350],\n",
       "                       [-0.0613,  0.0319, -0.0214,  ..., -0.1106,  0.0728, -0.0067],\n",
       "                       [-0.0852,  0.0255,  0.0134,  ..., -0.0382, -0.0821,  0.0006],\n",
       "                       ...,\n",
       "                       [-0.0078, -0.0404,  0.0633,  ...,  0.1042, -0.0915, -0.1144],\n",
       "                       [-0.1060,  0.0701, -0.0557,  ...,  0.0963,  0.0454,  0.0692],\n",
       "                       [-0.1065,  0.0671,  0.0175,  ..., -0.0487, -0.0598,  0.0323]])),\n",
       "              ('net.models.0.mixing.3.intraatomic_context_net.0.bias',\n",
       "               tensor([-1.0260e-03, -5.2864e-03,  2.0881e-03,  3.4348e-04, -2.7114e-04,\n",
       "                       -1.0851e-02, -5.2367e-03,  2.2250e-03, -7.1504e-04,  9.3165e-05,\n",
       "                        1.6012e-03,  2.0708e-03, -1.8795e-03, -1.1627e-03, -1.8568e-03,\n",
       "                        1.3931e-03,  3.8699e-03,  3.9175e-03, -8.9408e-04, -1.1089e-03,\n",
       "                        3.7501e-03,  8.7708e-03, -7.7628e-03,  1.0271e-03,  4.4383e-03,\n",
       "                       -1.3467e-03, -3.4015e-03,  4.9687e-04, -1.1295e-02, -8.4981e-03,\n",
       "                       -5.2962e-03, -4.2118e-03, -8.9201e-05, -5.9743e-03, -4.7646e-03,\n",
       "                       -5.4222e-03, -6.7951e-03, -7.1551e-03, -4.1686e-03,  1.8133e-03,\n",
       "                       -5.5074e-03,  9.2428e-04, -9.3812e-03, -4.9318e-04, -2.5337e-03,\n",
       "                       -6.2715e-03, -7.6851e-03, -5.4807e-03, -5.3681e-03, -3.9399e-03,\n",
       "                       -1.0621e-03, -4.3817e-03, -7.3541e-04,  4.3497e-04,  2.9305e-03,\n",
       "                        9.5829e-03, -1.3757e-03, -1.9324e-03, -4.7164e-03,  5.6029e-03,\n",
       "                       -5.6497e-03, -1.0724e-03,  4.3636e-03, -4.9271e-04, -6.6860e-03,\n",
       "                       -5.7896e-03, -9.7116e-03, -8.1759e-03, -5.2842e-04, -2.3977e-03,\n",
       "                        3.8051e-03, -9.8684e-03,  6.1328e-03,  5.7888e-03, -9.7615e-04,\n",
       "                       -2.1298e-03, -8.4383e-03, -2.3503e-03,  2.8625e-04,  1.2693e-03,\n",
       "                       -3.1465e-03, -8.1076e-05,  4.3279e-03,  1.8268e-03,  6.9015e-05,\n",
       "                       -2.7151e-03, -2.7186e-03, -1.5706e-03, -1.1563e-02,  7.3240e-03,\n",
       "                       -2.8846e-03, -1.1613e-02, -1.7964e-03, -2.2694e-03, -3.2946e-03,\n",
       "                        1.8074e-03,  1.6100e-03, -2.8721e-03,  2.7888e-03, -1.2282e-02,\n",
       "                       -2.7231e-03, -3.6227e-03,  2.6761e-03, -4.5848e-03, -3.7683e-03,\n",
       "                        4.0294e-05, -4.1059e-04,  4.4641e-03,  3.9785e-03, -6.1552e-03,\n",
       "                       -1.1146e-03,  5.6645e-03,  2.5680e-03, -1.4207e-02, -4.8157e-03,\n",
       "                       -2.4522e-03, -8.6448e-04, -4.2306e-03,  3.8333e-03, -2.6938e-03,\n",
       "                       -1.4659e-02, -3.8317e-03,  5.7362e-04, -1.3079e-02, -1.1943e-03,\n",
       "                       -9.9724e-04, -1.1625e-02,  6.1745e-04])),\n",
       "              ('net.models.0.mixing.3.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0856, -0.0781,  0.0074,  ...,  0.0440,  0.0122, -0.0635],\n",
       "                       [-0.0883, -0.0878, -0.0904,  ...,  0.1065, -0.0046, -0.0444],\n",
       "                       [-0.0888,  0.0357, -0.0238,  ...,  0.0912,  0.0898,  0.0447],\n",
       "                       ...,\n",
       "                       [ 0.0400,  0.0286, -0.0038,  ..., -0.0062, -0.0281, -0.1183],\n",
       "                       [ 0.0178,  0.0473,  0.0572,  ...,  0.0573,  0.0497,  0.0533],\n",
       "                       [ 0.0140,  0.0656,  0.0684,  ..., -0.0180, -0.0423, -0.0140]])),\n",
       "              ('net.models.0.mixing.3.intraatomic_context_net.1.bias',\n",
       "               tensor([-1.3851e-03, -1.6309e-03, -1.0209e-03,  3.9952e-04, -2.7489e-03,\n",
       "                        5.9102e-04,  1.1536e-02,  2.3100e-03,  1.5034e-03,  1.6764e-03,\n",
       "                        9.8583e-04, -1.4136e-04,  7.5841e-03,  5.4709e-03, -3.0476e-03,\n",
       "                       -3.9165e-03, -1.6844e-03, -5.7992e-04,  3.8095e-05,  4.1876e-03,\n",
       "                        3.0455e-03,  3.9821e-03, -2.2342e-03,  5.1270e-03,  1.8214e-03,\n",
       "                       -2.5924e-03, -8.1464e-03,  7.2349e-04,  6.9711e-03,  2.6654e-03,\n",
       "                        2.8438e-03, -8.3229e-04, -1.8341e-03,  3.0275e-05, -6.9372e-03,\n",
       "                       -2.5539e-03, -1.0844e-03, -3.7413e-03, -4.1160e-03,  2.5216e-03,\n",
       "                        1.0684e-03, -2.9147e-03, -2.5784e-03,  3.8683e-04, -3.2562e-03,\n",
       "                       -1.1597e-03,  5.8798e-03, -4.0214e-03, -1.8938e-03,  1.5641e-03,\n",
       "                        3.4080e-03, -6.4567e-04,  3.4982e-03,  1.4170e-03, -3.2936e-03,\n",
       "                       -3.2178e-03,  4.6109e-03,  3.6425e-05, -1.5742e-03,  4.1507e-03,\n",
       "                        3.4275e-03,  4.7974e-06,  4.2754e-04,  1.0572e-02, -3.9400e-03,\n",
       "                       -2.3264e-03,  1.0807e-03, -5.1261e-03, -3.5434e-04,  9.5789e-04,\n",
       "                       -1.0942e-03,  1.8982e-03, -8.5390e-03, -3.4071e-03,  2.0431e-03,\n",
       "                        3.2015e-03, -2.0961e-03,  2.7100e-03,  1.4783e-03,  1.2024e-02,\n",
       "                       -3.7034e-03, -5.5239e-04, -9.3461e-03, -1.6570e-03,  6.1809e-04,\n",
       "                       -8.2809e-05, -2.1971e-03,  2.2768e-03,  1.2031e-03,  2.6365e-03,\n",
       "                       -9.7691e-03, -1.0740e-04,  4.6419e-04, -3.7723e-03, -9.2904e-04,\n",
       "                       -7.0591e-04,  5.9968e-05, -9.8825e-03,  3.1677e-05, -2.1160e-03,\n",
       "                       -3.7154e-03, -5.1447e-04,  2.5216e-03,  2.9804e-03,  4.0198e-03,\n",
       "                       -5.1153e-03,  2.0430e-03,  2.1548e-03, -7.2189e-04,  3.5255e-04,\n",
       "                       -2.7988e-03,  2.6264e-03,  2.1390e-03, -4.4807e-03, -9.6304e-03,\n",
       "                        1.7483e-03,  9.9220e-03, -2.3587e-03,  5.8774e-03, -1.3279e-03,\n",
       "                       -2.3490e-04, -3.2325e-04,  1.2084e-02, -2.5915e-04, -5.2182e-03,\n",
       "                       -3.5066e-03,  1.5228e-05, -2.5501e-03, -1.3669e-03, -2.6152e-03,\n",
       "                        8.1891e-04, -3.7982e-03,  4.0878e-03, -1.2940e-02, -1.4456e-02,\n",
       "                        8.2756e-03, -3.9279e-03,  1.7253e-03, -7.4120e-03,  1.9939e-03,\n",
       "                       -2.2364e-03,  9.3352e-03, -3.6167e-04,  6.3170e-03, -1.0328e-02,\n",
       "                        9.2647e-03, -3.5845e-03,  7.9267e-04,  5.7386e-04, -9.4654e-04,\n",
       "                        1.7539e-03, -3.9295e-03, -4.6948e-03, -3.0700e-03, -2.1616e-03,\n",
       "                        6.1915e-03,  1.2015e-02,  9.4087e-04,  1.7905e-03, -4.1675e-03,\n",
       "                       -4.5148e-03, -2.8352e-04, -8.3303e-03, -6.5070e-03,  1.2924e-03,\n",
       "                        7.8452e-03, -6.6900e-03, -1.8738e-03, -2.2294e-04,  1.1066e-02,\n",
       "                        4.4031e-03,  9.2950e-04,  2.1625e-02, -1.2618e-02,  9.6209e-03,\n",
       "                       -5.1775e-03,  1.0785e-02,  9.3558e-03, -1.5070e-03, -8.6529e-04,\n",
       "                       -2.4778e-03,  1.1081e-03, -1.2292e-03,  9.4144e-03, -5.0781e-04,\n",
       "                       -1.5248e-03,  4.0440e-03,  3.1991e-03,  2.2172e-03, -6.5540e-03,\n",
       "                        2.0402e-02, -7.1139e-03,  1.3752e-03,  1.0422e-02, -1.0385e-03,\n",
       "                       -1.7275e-03, -1.4892e-02, -2.2691e-03, -7.1120e-03, -5.0681e-03,\n",
       "                        6.9992e-03,  3.9518e-03,  3.7011e-03,  3.0935e-03, -8.7611e-03,\n",
       "                        1.3908e-04,  1.0225e-02, -1.0568e-02,  1.2405e-03, -4.7297e-03,\n",
       "                       -5.6926e-04, -5.8613e-03,  1.3486e-03, -4.8266e-03, -4.6532e-03,\n",
       "                        9.1557e-03,  7.9341e-05,  6.4269e-03, -9.0951e-04,  5.5960e-03,\n",
       "                        7.1189e-03, -5.6929e-03,  1.6179e-03,  1.1135e-02,  2.6111e-03,\n",
       "                        6.1375e-03,  2.0748e-02,  2.4793e-03, -1.1876e-03, -9.5512e-03,\n",
       "                        1.3006e-02,  5.1103e-03,  8.4847e-03,  1.1281e-02,  7.8450e-03,\n",
       "                       -4.5172e-03,  1.1316e-02,  1.4075e-02, -5.8857e-04, -1.0469e-02,\n",
       "                       -1.0972e-03,  5.5155e-04, -4.7955e-03,  6.2548e-03,  7.6738e-03,\n",
       "                       -8.3600e-03, -3.1024e-03,  3.8200e-03, -1.1620e-03,  5.4146e-04,\n",
       "                       -7.1668e-03,  8.4391e-03,  6.5797e-03,  9.5265e-03,  8.6031e-03,\n",
       "                        6.9172e-04, -2.1730e-03, -1.2229e-02,  2.6713e-03, -2.0721e-03,\n",
       "                        4.7588e-03, -8.8604e-03, -1.2882e-02, -3.0265e-03, -5.2113e-03,\n",
       "                        1.1897e-02, -3.9987e-03,  4.6869e-03, -7.2502e-05,  1.5964e-03,\n",
       "                        4.8417e-03,  1.1641e-03,  3.2888e-03,  1.7421e-03,  4.4064e-03,\n",
       "                       -1.1412e-02, -1.1457e-02,  2.3153e-03,  7.1469e-04,  5.7424e-03,\n",
       "                       -7.4573e-03,  5.0579e-03, -9.8574e-03, -8.3999e-03, -1.3018e-02,\n",
       "                        2.8192e-03, -7.7544e-04,  5.2771e-03, -4.5162e-03, -7.3072e-03,\n",
       "                       -1.1550e-02, -5.0472e-03, -5.9481e-04,  6.1009e-03,  6.6951e-03,\n",
       "                       -6.5615e-03, -1.5623e-03,  6.8165e-03,  7.5689e-03, -9.6781e-03,\n",
       "                        3.0990e-03, -1.7638e-04,  6.8201e-03,  1.0565e-02,  6.0999e-04,\n",
       "                       -8.0879e-03, -3.6040e-04,  6.0839e-03,  4.2875e-05,  7.0335e-03,\n",
       "                        8.8457e-03, -2.2620e-02, -8.6910e-03,  1.8021e-04,  7.3542e-03,\n",
       "                        5.9923e-03,  3.0702e-03,  5.7498e-03, -1.3802e-02, -4.0748e-03,\n",
       "                       -9.2423e-03,  8.1906e-03,  4.1955e-03, -3.2675e-03,  6.7728e-04,\n",
       "                        2.7441e-03, -8.6990e-03,  1.0971e-02, -1.3269e-03,  8.3601e-05,\n",
       "                        4.3840e-03,  4.6133e-03, -7.1551e-04, -1.3486e-03, -4.4091e-03,\n",
       "                       -2.7977e-02,  1.3381e-02,  8.3836e-03, -3.6174e-03, -4.1725e-03,\n",
       "                        5.7260e-03, -9.5717e-04,  3.1104e-03,  5.6084e-03, -7.1041e-03,\n",
       "                       -2.9744e-04,  1.8432e-02, -2.1641e-03,  4.6747e-04,  5.5992e-03,\n",
       "                       -6.7716e-03,  4.0326e-03,  5.2254e-03,  1.7345e-02, -4.5397e-03,\n",
       "                        3.3856e-03,  2.2177e-03,  4.7014e-03,  2.0482e-03,  1.0133e-02,\n",
       "                        2.5025e-04, -6.3880e-03,  4.8400e-03,  9.5095e-03,  2.5851e-03,\n",
       "                       -2.5182e-03, -1.1378e-03, -1.5844e-02,  4.3432e-03,  7.6141e-03,\n",
       "                       -1.9209e-03,  1.1392e-03, -2.1376e-04,  1.3118e-03,  1.5632e-03,\n",
       "                        7.7075e-03, -4.5751e-03,  1.0159e-02, -9.6704e-03, -5.2145e-03,\n",
       "                        4.4330e-03,  2.2770e-02, -1.9304e-03,  5.4565e-03])),\n",
       "              ('net.models.0.mixing.3.mu_channel_mix.weight',\n",
       "               tensor([[-0.0615,  0.1111,  0.0779,  ...,  0.1037, -0.0219, -0.0656],\n",
       "                       [ 0.0448,  0.0378, -0.0131,  ..., -0.0493, -0.0257, -0.0486],\n",
       "                       [-0.0493,  0.0873,  0.0920,  ...,  0.1072, -0.0550, -0.0033],\n",
       "                       ...,\n",
       "                       [ 0.0967, -0.0437,  0.0912,  ...,  0.0435, -0.1046,  0.0492],\n",
       "                       [-0.0473, -0.0517, -0.0157,  ..., -0.0238,  0.0625,  0.0800],\n",
       "                       [ 0.0339,  0.0487,  0.1147,  ..., -0.0644, -0.0409,  0.0349]])),\n",
       "              ('net.models.0.mixing.4.intraatomic_context_net.0.weight',\n",
       "               tensor([[-0.1162, -0.0210,  0.0638,  ...,  0.0556, -0.0653,  0.0604],\n",
       "                       [ 0.0988, -0.0555,  0.0860,  ..., -0.1120, -0.1173, -0.1229],\n",
       "                       [ 0.0881,  0.0324,  0.0609,  ...,  0.0194,  0.0402,  0.1212],\n",
       "                       ...,\n",
       "                       [-0.0950,  0.0580,  0.0970,  ...,  0.0701,  0.0472, -0.0870],\n",
       "                       [-0.0102, -0.0443,  0.0539,  ..., -0.0689, -0.0681, -0.1115],\n",
       "                       [ 0.1173,  0.0459,  0.0715,  ...,  0.1054,  0.0122,  0.0119]])),\n",
       "              ('net.models.0.mixing.4.intraatomic_context_net.0.bias',\n",
       "               tensor([-9.6387e-03,  1.5986e-03,  5.5975e-04,  4.5266e-03,  5.5345e-03,\n",
       "                       -8.0831e-04, -1.9251e-03,  4.7907e-05,  6.3039e-03, -4.0782e-04,\n",
       "                       -8.7987e-03, -2.3156e-03, -2.7548e-03,  2.3419e-03,  7.6388e-04,\n",
       "                       -3.7382e-03, -7.1560e-04,  9.1524e-04, -2.2053e-03, -1.8401e-03,\n",
       "                        3.7087e-03, -6.4742e-03, -2.8490e-03, -4.6146e-03, -2.3541e-03,\n",
       "                       -6.2714e-03, -1.0198e-02,  9.3342e-04,  3.7773e-03, -9.8946e-03,\n",
       "                        3.7200e-03,  2.5946e-03, -1.2407e-02,  4.2196e-04, -2.2151e-03,\n",
       "                       -2.2358e-03,  2.9051e-03, -6.7339e-03,  4.3345e-03, -2.8992e-04,\n",
       "                       -3.8529e-03, -6.6561e-03, -1.6492e-03, -7.9752e-04, -3.4915e-03,\n",
       "                       -6.7278e-04, -2.3265e-03, -5.1881e-03, -1.3382e-03,  3.9719e-03,\n",
       "                        2.5716e-03, -4.1312e-03,  2.1944e-03, -3.3177e-03,  2.2309e-03,\n",
       "                       -6.2070e-03, -4.8910e-03,  5.8091e-03, -9.8025e-04, -1.5281e-03,\n",
       "                       -6.4073e-03, -7.1604e-03, -4.9294e-03, -1.7098e-02,  3.5077e-03,\n",
       "                       -5.7666e-03,  1.4814e-03, -1.5901e-03,  5.3907e-04,  2.1428e-03,\n",
       "                        3.9829e-03,  7.4606e-04, -3.6249e-04,  3.8131e-03,  3.0712e-03,\n",
       "                       -6.3702e-04,  1.6116e-03, -8.2614e-03, -3.9686e-03, -8.7794e-05,\n",
       "                        1.0285e-03, -3.4705e-03, -3.7028e-03, -2.9741e-03, -8.6721e-04,\n",
       "                        3.2800e-03, -2.1092e-03,  7.1873e-05,  4.1295e-03, -2.5936e-03,\n",
       "                       -2.0494e-03, -1.0158e-03, -7.4760e-03, -8.6425e-03, -3.8728e-03,\n",
       "                        1.7325e-04, -1.1980e-02, -1.0510e-03, -3.9887e-04, -1.3188e-02,\n",
       "                       -1.3997e-04, -5.0038e-03,  2.9065e-03, -1.4803e-03,  6.8369e-03,\n",
       "                        8.9568e-04,  2.8197e-03,  1.8428e-03, -1.1680e-02,  1.4897e-03,\n",
       "                       -6.4898e-03, -3.7031e-03, -6.3215e-03, -6.4247e-03, -4.6362e-03,\n",
       "                       -2.9200e-03, -1.1129e-03, -7.8630e-04, -1.4486e-04,  1.1110e-03,\n",
       "                        4.8459e-03, -1.6063e-03, -2.4394e-04,  4.2972e-04, -5.9916e-03,\n",
       "                       -3.3333e-03, -8.0869e-03,  4.3897e-04])),\n",
       "              ('net.models.0.mixing.4.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0342, -0.0324,  0.0799,  ..., -0.0168, -0.0054,  0.0899],\n",
       "                       [-0.0103, -0.0768,  0.0263,  ..., -0.0184, -0.0652,  0.0069],\n",
       "                       [ 0.0785,  0.0278, -0.0684,  ...,  0.0787,  0.0018, -0.0545],\n",
       "                       ...,\n",
       "                       [ 0.0873, -0.0104, -0.0705,  ...,  0.0818,  0.0529, -0.0550],\n",
       "                       [-0.0955,  0.0426, -0.0724,  ...,  0.0153, -0.0352, -0.1015],\n",
       "                       [-0.0557, -0.0870, -0.0857,  ...,  0.0663, -0.0441,  0.0649]])),\n",
       "              ('net.models.0.mixing.4.intraatomic_context_net.1.bias',\n",
       "               tensor([-9.6184e-04, -9.9627e-03,  5.5950e-04,  2.3658e-03, -1.7230e-03,\n",
       "                       -1.3201e-03,  5.1398e-03,  8.0108e-04,  6.9982e-04, -4.5244e-04,\n",
       "                        4.5463e-04, -5.1896e-03,  7.6533e-03,  8.7050e-03,  2.2347e-03,\n",
       "                       -1.8827e-03, -1.5970e-03,  5.0064e-05,  4.0736e-04,  7.6964e-04,\n",
       "                        1.0253e-03,  1.1540e-03, -8.3612e-04,  3.4933e-03,  1.2443e-03,\n",
       "                       -1.0334e-03, -8.3908e-03,  1.6866e-03,  2.8481e-03,  1.1581e-03,\n",
       "                        1.4077e-03, -1.4496e-03, -1.6778e-04, -3.9930e-04, -3.0196e-03,\n",
       "                       -1.7488e-03, -9.8209e-04, -1.1806e-03, -1.3893e-03, -5.2133e-04,\n",
       "                        4.0045e-04, -1.1171e-03, -1.6036e-03, -9.5566e-04, -8.3749e-04,\n",
       "                       -1.5031e-04,  3.3235e-03, -2.8217e-03, -2.9418e-03,  1.0475e-03,\n",
       "                        4.0732e-04, -1.4437e-03,  1.0412e-03, -1.0062e-03, -2.9524e-03,\n",
       "                       -2.0142e-03,  3.1360e-03,  1.9522e-03, -2.0936e-03,  2.3981e-03,\n",
       "                        8.1215e-04, -8.3037e-04, -1.8457e-03,  6.6127e-03, -2.1429e-03,\n",
       "                       -1.4576e-03,  5.4855e-04, -5.4834e-03,  3.3661e-04,  7.2170e-04,\n",
       "                       -2.9058e-03,  7.4770e-04, -3.9595e-03, -1.1566e-03, -4.8677e-04,\n",
       "                        1.2484e-03,  2.6390e-03,  9.8027e-04,  9.0631e-04,  7.0536e-03,\n",
       "                       -2.2778e-03,  6.3910e-04, -9.1997e-03, -9.2973e-04,  8.1035e-05,\n",
       "                       -4.3771e-04, -1.4963e-03,  1.4092e-03,  8.3761e-05,  1.4024e-03,\n",
       "                       -2.8042e-03, -8.9293e-04,  6.0065e-04, -2.6783e-03,  1.4633e-03,\n",
       "                       -2.9025e-03, -5.2253e-03, -5.0857e-03, -1.7192e-03, -2.2304e-03,\n",
       "                       -2.5266e-03, -3.0573e-03,  2.4753e-03,  1.2659e-03,  2.4256e-03,\n",
       "                       -2.6960e-03,  1.3401e-03,  1.2240e-03, -5.2943e-05, -2.9118e-04,\n",
       "                       -1.9482e-03, -5.8738e-03,  9.7561e-04, -2.8319e-03, -9.4202e-03,\n",
       "                        1.8222e-03,  6.7295e-03, -1.2160e-03,  1.6892e-03, -4.2738e-03,\n",
       "                       -6.0185e-03, -1.6277e-03,  6.2203e-03, -2.0337e-04, -2.3017e-03,\n",
       "                       -4.0596e-04, -2.9276e-03, -5.6636e-03, -1.6763e-03,  5.3974e-03,\n",
       "                       -4.8530e-03, -2.7512e-03,  2.7273e-03, -1.0153e-03,  8.7474e-04,\n",
       "                       -8.2737e-03,  8.6137e-03, -1.6814e-02, -1.3061e-03, -1.0094e-03,\n",
       "                       -7.6936e-04,  5.1239e-03, -6.5742e-03,  7.9864e-03,  3.5812e-03,\n",
       "                       -1.1097e-02, -6.9404e-03,  5.8720e-03, -1.8559e-03,  1.7604e-02,\n",
       "                        3.6336e-03, -4.6702e-03, -7.7638e-03,  5.4926e-03,  8.9055e-03,\n",
       "                       -1.0131e-02,  1.2567e-03, -4.5525e-04,  1.7722e-04, -6.9606e-03,\n",
       "                        6.4988e-03, -1.3442e-02,  5.4142e-03, -8.0404e-03,  1.1926e-02,\n",
       "                       -1.2436e-03,  5.1601e-03, -8.4675e-04,  6.9694e-03,  5.2769e-03,\n",
       "                        5.1341e-03, -1.0821e-02, -5.8543e-03,  1.0022e-02,  9.3761e-04,\n",
       "                       -7.0174e-03, -9.7801e-03, -4.2878e-03, -3.4847e-03, -2.9454e-03,\n",
       "                        7.3268e-04, -8.9195e-03, -6.0784e-03, -1.4797e-02,  1.0161e-02,\n",
       "                        6.7440e-03, -6.3779e-03, -2.0961e-03,  6.7283e-03,  6.7348e-04,\n",
       "                        1.2099e-02, -5.2409e-03, -1.1418e-02,  3.7357e-03,  4.2167e-04,\n",
       "                       -3.8557e-03,  4.2724e-03, -1.5337e-02,  6.0239e-03,  1.4677e-02,\n",
       "                        3.9211e-03, -1.8156e-03, -5.8234e-04, -3.5731e-03,  5.2998e-03,\n",
       "                       -1.3918e-03,  1.7910e-03,  1.7765e-03,  7.2113e-03,  5.5857e-03,\n",
       "                       -8.0938e-03,  1.7659e-03,  1.1723e-02, -1.2426e-03, -7.0299e-03,\n",
       "                       -8.5144e-03, -2.7477e-03,  8.7945e-03, -1.1015e-02,  7.3410e-03,\n",
       "                        1.2303e-02, -2.6610e-03, -2.1091e-03, -1.2869e-02, -5.3737e-03,\n",
       "                       -1.1824e-04, -1.6363e-03, -4.3039e-03,  3.3497e-03, -5.3139e-03,\n",
       "                        1.5500e-02,  4.9665e-03,  3.1063e-03, -1.0485e-02,  2.0479e-04,\n",
       "                        8.2258e-03, -6.2092e-03, -3.0622e-04,  6.4380e-03,  3.6860e-03,\n",
       "                       -1.4138e-02, -9.5445e-03, -9.8005e-03,  2.2787e-03,  7.5808e-03,\n",
       "                        3.3363e-03, -9.9858e-04,  5.2930e-04,  9.2371e-03,  4.8716e-03,\n",
       "                       -5.6489e-03, -2.2375e-03, -9.8576e-03,  3.5074e-03, -3.5748e-03,\n",
       "                       -7.6680e-03, -7.0258e-03,  1.4942e-02, -1.5316e-02,  1.7260e-03,\n",
       "                        4.6392e-03, -9.8266e-03, -3.2855e-04,  7.6841e-03, -5.5999e-03,\n",
       "                        2.5521e-03, -1.2766e-02,  1.1248e-02, -6.4474e-03,  7.1705e-03,\n",
       "                       -6.9810e-03, -4.6343e-04,  5.9081e-03,  3.8315e-03, -7.2890e-03,\n",
       "                        1.5829e-03, -1.1884e-03, -2.1770e-03, -3.5457e-03, -6.0565e-03,\n",
       "                       -1.4390e-02, -1.1130e-02,  3.3719e-03, -1.0508e-02,  8.5695e-03,\n",
       "                        2.1190e-03, -3.4689e-03, -6.8331e-03,  9.9286e-03, -5.2909e-04,\n",
       "                       -2.0233e-03,  4.2291e-03, -1.0399e-02,  1.4254e-03,  1.1552e-02,\n",
       "                       -9.7740e-03,  7.5646e-03,  7.3122e-04, -8.7377e-03, -1.0828e-02,\n",
       "                       -4.9906e-03, -1.6291e-02, -4.5042e-04, -3.7824e-03,  3.7640e-03,\n",
       "                       -6.4425e-03,  1.7134e-02, -9.0794e-03, -8.0692e-03,  1.4589e-02,\n",
       "                       -1.0048e-03, -1.5906e-02, -8.1281e-03,  7.8460e-04,  2.7251e-03,\n",
       "                       -5.5445e-03,  9.4898e-03,  4.7107e-03, -1.6275e-02, -5.4529e-04,\n",
       "                       -2.5108e-03, -1.2185e-02,  1.1324e-03, -1.2001e-02,  3.7235e-03,\n",
       "                       -1.9433e-03,  1.4211e-02, -3.8541e-03, -8.3548e-04,  6.2801e-04,\n",
       "                       -4.2596e-03,  4.5755e-03,  2.2503e-03, -3.0370e-03,  6.2592e-03,\n",
       "                       -1.3551e-02, -4.4004e-03,  8.4241e-03,  1.9914e-03,  1.4947e-03,\n",
       "                       -3.4286e-03,  1.2463e-04,  3.9760e-03,  5.7299e-03, -1.1719e-02,\n",
       "                       -1.8104e-03, -2.5871e-03, -1.2133e-02, -6.6920e-03,  8.6962e-04,\n",
       "                        5.5264e-03,  1.7364e-03,  5.9942e-03, -3.5738e-03, -6.0245e-03,\n",
       "                        1.8303e-04, -1.2070e-02, -6.4418e-03, -1.1642e-03, -2.6438e-03,\n",
       "                       -4.2151e-03,  8.2657e-03, -4.9634e-03, -1.2355e-04, -1.0914e-02,\n",
       "                       -1.5210e-02,  9.5481e-03, -1.0752e-02,  2.6070e-03, -7.5409e-03,\n",
       "                       -3.0315e-03, -4.6125e-04,  2.9982e-03, -2.7806e-03, -4.4432e-03,\n",
       "                        1.3202e-02,  1.1482e-03,  8.6367e-04, -4.2004e-04, -1.0228e-03,\n",
       "                        1.3575e-03, -6.7131e-03,  1.8812e-03,  9.9052e-03])),\n",
       "              ('net.models.0.mixing.4.mu_channel_mix.weight',\n",
       "               tensor([[ 0.0724,  0.0041,  0.1258,  ...,  0.0286,  0.0760,  0.0197],\n",
       "                       [ 0.0652,  0.0580,  0.1233,  ...,  0.0876,  0.1003, -0.0507],\n",
       "                       [ 0.0058,  0.1250, -0.0332,  ...,  0.0272, -0.0387, -0.0902],\n",
       "                       ...,\n",
       "                       [-0.1000,  0.1100,  0.0484,  ...,  0.0813, -0.0671,  0.0640],\n",
       "                       [-0.0475,  0.0058,  0.1079,  ...,  0.0472,  0.0007,  0.0966],\n",
       "                       [ 0.1041,  0.0312,  0.0743,  ...,  0.0949, -0.1120,  0.0232]])),\n",
       "              ('net.models.0.mixing.5.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0773, -0.1013, -0.1239,  ...,  0.0849,  0.0745, -0.0429],\n",
       "                       [-0.0782,  0.0867,  0.0243,  ...,  0.0413, -0.0419, -0.0885],\n",
       "                       [ 0.0515, -0.1203,  0.0494,  ...,  0.1034,  0.1193,  0.1103],\n",
       "                       ...,\n",
       "                       [ 0.0127,  0.0803,  0.0086,  ..., -0.0656,  0.0002, -0.0994],\n",
       "                       [-0.1028, -0.0772,  0.0358,  ...,  0.0245, -0.0748, -0.0105],\n",
       "                       [-0.0829, -0.1052,  0.0012,  ..., -0.0019, -0.0333, -0.1074]])),\n",
       "              ('net.models.0.mixing.5.intraatomic_context_net.0.bias',\n",
       "               tensor([ 4.2362e-03,  1.0244e-03,  3.3966e-03,  3.7035e-03, -1.1471e-03,\n",
       "                        2.0768e-03, -4.0748e-03, -1.9392e-03, -3.3519e-03,  2.3073e-03,\n",
       "                        1.5993e-03, -1.1165e-02, -9.3735e-03,  7.4290e-04, -2.4548e-03,\n",
       "                       -4.5679e-03, -8.9312e-05,  4.2490e-03, -5.9091e-03,  1.2853e-03,\n",
       "                       -5.6389e-03,  6.3757e-03,  7.0261e-04,  2.7028e-03, -2.5776e-04,\n",
       "                       -1.3185e-03, -5.7318e-03, -4.4887e-03, -1.3961e-03,  1.4264e-03,\n",
       "                       -1.5363e-03,  3.3192e-03,  3.3357e-03, -7.9135e-03, -2.5759e-04,\n",
       "                        2.1863e-03, -2.1617e-03,  1.3574e-03,  2.0430e-03, -1.3288e-02,\n",
       "                       -6.6825e-03, -3.8934e-03,  2.8271e-03, -1.0488e-02, -2.6865e-03,\n",
       "                       -9.5816e-04,  2.5591e-04, -1.5291e-03, -2.0556e-03, -4.5920e-03,\n",
       "                       -3.6036e-03,  2.6593e-03,  6.0086e-03, -1.0496e-03, -3.6193e-03,\n",
       "                       -6.6844e-03, -4.3879e-03,  7.6102e-04, -1.8303e-03, -1.4305e-03,\n",
       "                       -1.3386e-03, -1.0676e-03, -1.0253e-02, -3.9629e-04,  1.7828e-03,\n",
       "                       -3.4116e-03, -1.5842e-03, -2.5118e-03, -1.3667e-03, -1.0778e-03,\n",
       "                        2.8555e-03,  2.5452e-03, -2.0982e-03, -5.8045e-03, -6.6859e-03,\n",
       "                       -9.3501e-04,  1.5557e-03,  2.5060e-04,  3.5147e-03, -1.2091e-03,\n",
       "                       -1.4987e-03, -2.0326e-03,  2.3929e-03, -8.4504e-03, -3.8864e-03,\n",
       "                       -4.9118e-03, -9.2190e-03, -3.2535e-03, -7.6422e-04, -1.3025e-05,\n",
       "                       -2.6545e-03,  3.3588e-03,  4.2090e-03,  6.7742e-05, -3.0334e-03,\n",
       "                       -2.9674e-03, -1.2177e-03, -7.8725e-03, -2.5364e-03, -4.8984e-03,\n",
       "                        2.1024e-03, -1.2473e-03, -5.0908e-03, -1.3152e-04, -1.1908e-03,\n",
       "                        6.4158e-03,  1.2043e-03,  6.1357e-04,  8.2782e-04, -2.6535e-03,\n",
       "                        7.3197e-04, -4.1567e-03,  1.9165e-04, -1.1421e-03, -1.1624e-02,\n",
       "                       -3.3825e-03, -1.6232e-03, -2.3923e-03, -2.1333e-03, -1.5511e-04,\n",
       "                       -8.8699e-03, -3.2448e-03, -7.3029e-03, -5.3316e-03,  4.7214e-03,\n",
       "                        2.3926e-03, -1.1231e-03, -3.3056e-04])),\n",
       "              ('net.models.0.mixing.5.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0269,  0.0932,  0.0428,  ..., -0.0242, -0.0404,  0.0412],\n",
       "                       [-0.0908, -0.0997,  0.0455,  ...,  0.0045,  0.0524, -0.0745],\n",
       "                       [ 0.0028,  0.0500, -0.1068,  ..., -0.0754,  0.0687,  0.0934],\n",
       "                       ...,\n",
       "                       [-0.0185, -0.0954, -0.0611,  ..., -0.0763,  0.0643,  0.0450],\n",
       "                       [ 0.0145,  0.0225, -0.0766,  ..., -0.1075, -0.0286,  0.0087],\n",
       "                       [ 0.0157, -0.0098,  0.0354,  ..., -0.0596, -0.0177, -0.0881]])),\n",
       "              ('net.models.0.mixing.5.intraatomic_context_net.1.bias',\n",
       "               tensor([-2.1066e-04, -6.7277e-04,  1.2767e-04,  1.1042e-04, -3.5449e-04,\n",
       "                       -2.1826e-04,  3.5394e-03,  2.7694e-04,  1.5893e-04,  1.2656e-04,\n",
       "                        1.5559e-05,  2.2344e-04,  1.8767e-03,  1.9267e-04, -5.7760e-04,\n",
       "                       -2.9740e-04,  1.0935e-05, -2.6798e-04, -6.0908e-05, -1.1930e-03,\n",
       "                        3.8646e-04,  5.9537e-05, -2.0496e-04,  8.1353e-04, -6.4361e-04,\n",
       "                       -4.3500e-04, -1.1728e-04,  2.6384e-04, -4.0122e-05,  2.8260e-04,\n",
       "                        7.0415e-03,  1.2402e-04, -2.7975e-04, -1.3588e-04, -1.4862e-04,\n",
       "                        2.8202e-04,  2.3286e-05, -1.8495e-04, -1.9683e-04, -1.1730e-03,\n",
       "                        2.4336e-04, -3.4028e-04, -2.2981e-04,  1.0985e-05,  5.7837e-05,\n",
       "                       -3.7627e-05,  5.0726e-03, -3.6553e-04, -1.2555e-04, -7.8867e-05,\n",
       "                       -7.8930e-05,  2.2249e-05,  1.4704e-04, -3.7748e-04, -1.7368e-04,\n",
       "                       -3.4188e-04,  8.2559e-04,  1.5253e-03,  1.9637e-05,  2.7693e-04,\n",
       "                        4.6309e-04,  1.2358e-04,  7.5813e-04,  7.5438e-04, -4.3544e-04,\n",
       "                       -2.2584e-04,  1.3157e-04, -4.2034e-04, -1.5534e-04,  3.2909e-04,\n",
       "                       -3.7257e-04,  1.9774e-04, -1.1326e-02, -3.7330e-04, -2.2662e-04,\n",
       "                        6.5844e-05,  1.8834e-03,  2.2749e-04,  1.7687e-04,  1.2238e-04,\n",
       "                       -2.7215e-04,  2.6562e-04, -2.6634e-04, -3.2557e-04,  6.8364e-05,\n",
       "                       -5.7719e-05, -1.7141e-04,  2.9872e-04,  9.0574e-05,  2.3472e-04,\n",
       "                       -9.6357e-04, -1.3851e-04, -1.2034e-04, -3.5460e-04, -5.2824e-04,\n",
       "                       -1.4639e-04,  1.3062e-03, -1.6904e-03, -3.5201e-04, -1.2409e-04,\n",
       "                       -3.3526e-04, -1.2216e-04,  3.1135e-04,  3.1810e-04,  2.2161e-04,\n",
       "                       -2.0679e-05,  2.6023e-04,  2.3466e-04,  7.5674e-05,  1.2394e-04,\n",
       "                       -8.7877e-05,  9.9956e-04,  6.5181e-06, -2.1096e-04, -2.1237e-04,\n",
       "                        1.8291e-04,  5.3603e-03,  8.4489e-06,  1.4359e-04,  3.7518e-04,\n",
       "                       -6.0592e-03,  2.6430e-05,  7.0358e-04, -1.1025e-04, -2.3315e-03,\n",
       "                       -1.4276e-04,  1.9981e-04, -4.0604e-04,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00, -4.8194e-03, -5.3698e-04, -2.7461e-03, -2.0437e-03,\n",
       "                        6.5266e-03,  1.0094e-03, -6.4005e-05, -1.0292e-02,  4.1845e-04,\n",
       "                        1.4905e-03,  2.2474e-03,  2.3675e-03, -1.9504e-03, -8.9059e-03,\n",
       "                       -2.5528e-03,  4.6332e-03, -8.4910e-03,  3.4873e-03, -2.3164e-03,\n",
       "                        8.4868e-03, -3.1210e-03, -3.8654e-03,  1.0364e-02,  2.7283e-03,\n",
       "                        3.0494e-03, -8.1007e-03, -4.5810e-03, -1.9710e-03,  6.1027e-03,\n",
       "                       -2.5701e-03,  6.4471e-03,  5.9613e-03, -1.9274e-03,  7.4868e-04,\n",
       "                       -1.1643e-02,  1.2335e-02,  9.6769e-05,  1.8635e-03,  1.5897e-04,\n",
       "                       -1.8017e-02,  1.4953e-02,  2.1117e-03,  1.8669e-03, -4.5045e-03,\n",
       "                        4.7313e-03, -1.6096e-03, -9.0270e-03,  8.1256e-03, -8.3943e-03,\n",
       "                        5.7087e-03, -5.4525e-03,  1.2242e-02,  2.0667e-03, -3.9462e-03,\n",
       "                        8.9282e-04, -2.5014e-03,  3.0826e-03, -1.3488e-03, -7.4294e-04,\n",
       "                        4.7993e-03, -3.5158e-03, -1.3584e-02, -5.0347e-03, -2.3612e-03,\n",
       "                        1.1852e-03, -2.7115e-03,  3.5875e-03, -3.2005e-03, -4.5261e-03,\n",
       "                       -4.4550e-04,  1.6031e-03, -9.7039e-03, -8.9050e-03, -1.5080e-03,\n",
       "                        8.8316e-03, -1.6003e-03, -4.2316e-03, -7.7569e-03,  5.0958e-03,\n",
       "                        3.7331e-04,  6.5612e-03,  5.2660e-03,  3.4388e-03, -7.2177e-03,\n",
       "                       -6.1844e-03,  3.0905e-04,  7.9291e-03,  1.9242e-02,  6.0332e-03,\n",
       "                        6.2871e-03, -1.3408e-03, -6.8897e-04, -5.1819e-03, -2.4742e-03,\n",
       "                       -6.1387e-03,  5.3900e-03,  3.5954e-03,  3.7803e-03, -7.3286e-03,\n",
       "                       -4.4082e-03,  3.4388e-03,  6.0578e-03, -1.4961e-03,  7.9164e-04,\n",
       "                       -3.4071e-03,  1.0567e-03, -3.2129e-03,  3.9478e-03, -1.9284e-04,\n",
       "                       -3.4656e-03,  1.0090e-03, -5.3192e-03,  3.5142e-03,  1.1797e-02,\n",
       "                       -2.5320e-03, -1.1683e-02,  4.4028e-03,  8.0969e-03,  1.4056e-03,\n",
       "                       -6.9744e-03, -1.0394e-02,  2.1875e-03, -3.9022e-03, -3.0410e-03,\n",
       "                        4.9161e-03,  1.0198e-02, -1.1577e-02, -7.6948e-03])),\n",
       "              ('net.models.0.mixing.5.mu_channel_mix.weight',\n",
       "               tensor([[-0.0012,  0.0523,  0.0510,  ...,  0.0668, -0.0165, -0.0828],\n",
       "                       [-0.1145, -0.0663,  0.0212,  ...,  0.0533,  0.0856, -0.0203],\n",
       "                       [-0.1075, -0.1055,  0.1198,  ..., -0.0978, -0.0683, -0.0878],\n",
       "                       ...,\n",
       "                       [ 0.0903, -0.0502, -0.1231,  ...,  0.0021, -0.1216, -0.0641],\n",
       "                       [-0.1027, -0.0362,  0.1162,  ...,  0.0050, -0.0215,  0.1393],\n",
       "                       [ 0.0072,  0.0595, -0.0751,  ...,  0.0418,  0.0111,  0.1145]])),\n",
       "              ('net.models.1.cutoff_fn.cutoff', tensor([12.])),\n",
       "              ('net.models.1.radial_basis.widths',\n",
       "               tensor([0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n",
       "                       0.1905])),\n",
       "              ('net.models.1.radial_basis.offsets',\n",
       "               tensor([ 0.0000,  0.1905,  0.3810,  0.5714,  0.7619,  0.9524,  1.1429,  1.3333,\n",
       "                        1.5238,  1.7143,  1.9048,  2.0952,  2.2857,  2.4762,  2.6667,  2.8571,\n",
       "                        3.0476,  3.2381,  3.4286,  3.6190,  3.8095,  4.0000,  4.1905,  4.3810,\n",
       "                        4.5714,  4.7619,  4.9524,  5.1429,  5.3333,  5.5238,  5.7143,  5.9048,\n",
       "                        6.0952,  6.2857,  6.4762,  6.6667,  6.8571,  7.0476,  7.2381,  7.4286,\n",
       "                        7.6190,  7.8095,  8.0000,  8.1905,  8.3810,  8.5714,  8.7619,  8.9524,\n",
       "                        9.1429,  9.3333,  9.5238,  9.7143,  9.9048, 10.0952, 10.2857, 10.4762,\n",
       "                       10.6667, 10.8571, 11.0476, 11.2381, 11.4286, 11.6190, 11.8095, 12.0000])),\n",
       "              ('net.models.1.embedding.weight',\n",
       "               tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                       [-1.2432, -2.5113, -0.2417,  ...,  0.3587, -0.9538, -0.1779],\n",
       "                       [ 0.7063, -0.3008, -0.8739,  ..., -0.8130,  0.7503, -1.1326],\n",
       "                       ...,\n",
       "                       [-0.9675,  0.2792,  1.4635,  ..., -0.6444, -0.7772,  0.2633],\n",
       "                       [ 0.4420,  0.3902,  0.0582,  ...,  0.9740,  2.1346,  0.0568],\n",
       "                       [-0.3681,  1.2346, -0.7139,  ..., -0.0727,  0.6064,  0.3135]])),\n",
       "              ('net.models.1.filter_net.weight',\n",
       "               tensor([[ 0.0432, -0.0171, -0.0015,  ..., -0.0061, -0.0031, -0.0097],\n",
       "                       [-0.0166,  0.0101, -0.0265,  ...,  0.0401,  0.0122,  0.0460],\n",
       "                       [ 0.0319, -0.0222, -0.0265,  ..., -0.0039, -0.0119,  0.0207],\n",
       "                       ...,\n",
       "                       [-0.0438,  0.0056,  0.0185,  ..., -0.0394,  0.0151,  0.0128],\n",
       "                       [ 0.0380,  0.0387,  0.0034,  ..., -0.0274, -0.0060,  0.0181],\n",
       "                       [-0.0134, -0.0292,  0.0321,  ...,  0.0133,  0.0006,  0.0034]])),\n",
       "              ('net.models.1.filter_net.bias',\n",
       "               tensor([ 0.0029, -0.0045,  0.0026,  ..., -0.0054,  0.0097, -0.0076])),\n",
       "              ('net.models.1.interactions.0.interatomic_context_net.0.weight',\n",
       "               tensor([[ 0.1134,  0.1006,  0.0440,  ...,  0.1069, -0.0966,  0.1577],\n",
       "                       [-0.0788,  0.0207,  0.1030,  ..., -0.0730, -0.0461,  0.1050],\n",
       "                       [ 0.1088, -0.0502,  0.0265,  ..., -0.0383, -0.1419,  0.0926],\n",
       "                       ...,\n",
       "                       [-0.1139, -0.1176, -0.0160,  ..., -0.1251,  0.0522,  0.0573],\n",
       "                       [-0.0006, -0.0064, -0.0112,  ...,  0.1453,  0.0395,  0.1581],\n",
       "                       [-0.0402, -0.0266,  0.1462,  ..., -0.1300, -0.0456, -0.0664]])),\n",
       "              ('net.models.1.interactions.0.interatomic_context_net.0.bias',\n",
       "               tensor([-0.0182,  0.0019, -0.0098, -0.0108, -0.0054, -0.0006, -0.0040, -0.0024,\n",
       "                       -0.0010, -0.0016, -0.0079,  0.0086,  0.0015, -0.0076,  0.0004, -0.0095,\n",
       "                       -0.0057, -0.0006,  0.0076,  0.0004, -0.0066, -0.0093, -0.0042, -0.0081,\n",
       "                        0.0072, -0.0052,  0.0093,  0.0024,  0.0004,  0.0017, -0.0093, -0.0018,\n",
       "                        0.0047, -0.0022, -0.0074, -0.0039, -0.0068, -0.0074,  0.0099,  0.0013,\n",
       "                       -0.0083, -0.0039, -0.0060,  0.0007, -0.0088, -0.0006, -0.0050, -0.0128,\n",
       "                        0.0039,  0.0012,  0.0014,  0.0006,  0.0063, -0.0090,  0.0040, -0.0014,\n",
       "                       -0.0027, -0.0025,  0.0045,  0.0006, -0.0012,  0.0016, -0.0015, -0.0026,\n",
       "                       -0.0031, -0.0112,  0.0033, -0.0086, -0.0027, -0.0094, -0.0058,  0.0066,\n",
       "                       -0.0060,  0.0022, -0.0079, -0.0147, -0.0064, -0.0019,  0.0068, -0.0171,\n",
       "                        0.0007, -0.0117, -0.0014, -0.0041, -0.0013, -0.0031,  0.0035, -0.0038,\n",
       "                       -0.0104,  0.0015, -0.0072, -0.0067, -0.0018, -0.0109, -0.0091, -0.0077,\n",
       "                       -0.0064, -0.0015, -0.0038,  0.0045, -0.0041,  0.0003,  0.0022,  0.0040,\n",
       "                       -0.0101, -0.0092,  0.0074,  0.0090,  0.0109,  0.0002, -0.0006,  0.0049,\n",
       "                       -0.0067,  0.0024, -0.0036, -0.0041, -0.0110,  0.0041, -0.0106, -0.0005,\n",
       "                        0.0039, -0.0018, -0.0054, -0.0065, -0.0013,  0.0027, -0.0066, -0.0068])),\n",
       "              ('net.models.1.interactions.0.interatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0685, -0.0066, -0.0397,  ...,  0.0060, -0.0358, -0.0205],\n",
       "                       [ 0.0396, -0.0097, -0.0474,  ...,  0.0554,  0.0815,  0.0294],\n",
       "                       [-0.0256, -0.0106, -0.0863,  ..., -0.0697, -0.0051,  0.0570],\n",
       "                       ...,\n",
       "                       [ 0.0121,  0.0580, -0.0723,  ...,  0.0037,  0.0256, -0.0527],\n",
       "                       [ 0.0351, -0.0755, -0.0554,  ..., -0.0504,  0.0471,  0.0215],\n",
       "                       [ 0.0250,  0.0617,  0.0055,  ...,  0.0243,  0.0631, -0.1002]])),\n",
       "              ('net.models.1.interactions.0.interatomic_context_net.1.bias',\n",
       "               tensor([ 7.8290e-04,  4.3113e-03, -6.7418e-04, -9.1156e-03,  4.1886e-03,\n",
       "                        1.4699e-03,  1.6450e-02,  3.7291e-03,  1.3175e-02,  4.5605e-03,\n",
       "                       -1.1909e-02, -9.3148e-03,  3.0575e-03,  4.7241e-03, -8.3171e-03,\n",
       "                        7.8069e-03,  2.2837e-03, -3.1973e-04,  1.1055e-02, -6.2254e-03,\n",
       "                        4.1007e-04,  7.3520e-04,  2.2988e-03,  1.4266e-02,  1.7356e-03,\n",
       "                       -4.9771e-03,  7.2633e-05,  3.2115e-03,  1.4255e-02, -1.0273e-03,\n",
       "                        1.1123e-03,  2.2009e-03,  4.0568e-03, -4.1935e-03,  4.3280e-03,\n",
       "                        2.6678e-03,  3.2242e-03, -8.9782e-04,  8.0014e-03, -6.3572e-03,\n",
       "                       -4.9976e-03, -3.3818e-03,  3.6983e-04, -2.3956e-03,  3.0525e-03,\n",
       "                        9.8962e-03, -3.2738e-03, -8.0827e-04,  3.7088e-03, -1.0372e-02,\n",
       "                       -2.6039e-03,  5.0243e-03, -2.0290e-03,  1.9116e-03, -4.7767e-03,\n",
       "                        1.1730e-02, -2.9977e-03, -1.5099e-03,  3.6768e-03, -7.2128e-03,\n",
       "                        1.4369e-03, -5.7802e-03, -3.3707e-03, -8.4349e-04, -1.2230e-02,\n",
       "                       -3.6364e-03,  6.8747e-03,  1.5181e-03,  4.0931e-03,  3.9349e-03,\n",
       "                        3.6254e-03, -4.4609e-03,  4.5535e-03,  3.0821e-03, -9.3026e-03,\n",
       "                        1.0851e-02, -7.0455e-04, -5.4572e-04, -3.9793e-03,  1.7928e-03,\n",
       "                        1.0243e-02,  1.5049e-03, -4.5828e-03,  4.5529e-03, -6.9145e-03,\n",
       "                        5.0398e-03,  9.6241e-03,  4.6302e-03, -1.1915e-03, -1.6432e-03,\n",
       "                       -1.0299e-03,  5.9016e-03,  4.5957e-04,  3.0185e-03,  4.4650e-03,\n",
       "                        2.0303e-03, -2.0767e-03, -1.1335e-03,  7.7392e-03, -3.7219e-04,\n",
       "                        1.1764e-04,  1.2041e-03, -4.3097e-03, -3.6713e-03, -2.6057e-03,\n",
       "                        3.7843e-03,  2.5853e-04,  5.5671e-03,  2.9410e-03, -1.6647e-03,\n",
       "                       -2.5907e-03, -3.2772e-03,  4.2103e-03, -1.0772e-03,  1.1538e-02,\n",
       "                        6.0744e-03, -5.3406e-04, -2.1010e-03,  4.7047e-04,  6.6119e-03,\n",
       "                       -8.4900e-03, -1.4405e-02, -1.0926e-03,  3.2786e-03,  9.1406e-03,\n",
       "                        3.2286e-03,  4.1413e-03,  3.9980e-03, -1.9979e-05,  1.4129e-02,\n",
       "                        1.0564e-02,  5.8957e-03,  5.9544e-03, -1.0176e-03,  3.0860e-03,\n",
       "                        1.4061e-02, -4.6384e-03,  5.9353e-03,  1.4568e-02, -5.9752e-03,\n",
       "                       -8.7023e-03,  1.2522e-02, -1.9263e-03, -1.4759e-02,  3.6076e-03,\n",
       "                        5.3626e-04,  7.2679e-03,  1.7987e-02, -4.1531e-03,  3.9796e-03,\n",
       "                        3.1592e-03, -7.4970e-03,  4.6652e-04, -1.3035e-02,  8.6629e-04,\n",
       "                       -4.6617e-03, -4.1221e-03,  3.8652e-03,  1.7649e-02,  1.2205e-02,\n",
       "                       -1.2016e-03,  9.0934e-03, -7.1215e-03,  1.4976e-04, -4.3376e-03,\n",
       "                       -1.0778e-02,  4.6655e-03,  1.1601e-02,  1.9393e-04, -7.9036e-03,\n",
       "                        9.3469e-03,  3.9243e-03, -2.9221e-03, -2.5283e-04,  7.3597e-03,\n",
       "                       -1.0233e-02,  1.7194e-03,  1.2517e-02,  4.9910e-03,  2.0335e-03,\n",
       "                       -1.7099e-03, -1.8831e-03,  3.6314e-03, -1.3513e-05,  3.2562e-03,\n",
       "                        5.8500e-04, -1.6550e-03,  6.3897e-03, -2.0332e-03, -1.2912e-02,\n",
       "                       -6.8720e-03,  7.6277e-04, -8.1551e-03, -1.3340e-02, -9.0443e-03,\n",
       "                        2.4587e-03, -1.8139e-03,  6.1463e-03,  1.2529e-03, -7.2281e-03,\n",
       "                       -1.1980e-04, -7.4870e-03,  4.3287e-04, -1.6418e-02,  7.2147e-04,\n",
       "                       -9.5493e-03, -5.3039e-03, -2.4423e-03, -1.0523e-02, -1.8376e-02,\n",
       "                        1.5666e-02, -6.5273e-03, -3.8655e-03, -4.1905e-03, -1.2367e-02,\n",
       "                       -4.2128e-03,  5.9343e-03,  1.1964e-03,  3.1062e-03,  7.3228e-03,\n",
       "                       -4.0570e-03, -8.9983e-04,  5.4394e-03, -4.2747e-03, -9.4738e-03,\n",
       "                        7.4504e-03,  1.0489e-02, -5.0602e-03, -3.1199e-03, -6.3277e-03,\n",
       "                       -5.1929e-03,  1.4236e-02, -2.2361e-02,  4.0624e-03,  5.1848e-03,\n",
       "                        1.1061e-02,  6.8364e-03, -5.2442e-03,  7.0609e-03,  2.8160e-03,\n",
       "                        7.1009e-03,  5.9377e-03,  6.2437e-03, -3.1878e-03,  4.5276e-03,\n",
       "                        7.9146e-03, -6.3903e-03,  1.0205e-02, -7.9835e-03, -6.2122e-03,\n",
       "                       -7.0576e-03,  1.0305e-02,  8.4283e-04,  1.0270e-02,  7.9852e-03,\n",
       "                       -3.8537e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])),\n",
       "              ('net.models.1.interactions.1.interatomic_context_net.0.weight',\n",
       "               tensor([[ 0.1146,  0.1188, -0.0116,  ...,  0.0159, -0.0680,  0.0465],\n",
       "                       [-0.0815, -0.1308, -0.0557,  ...,  0.0592, -0.0552, -0.0478],\n",
       "                       [-0.0221, -0.1181,  0.1401,  ..., -0.0680,  0.1161,  0.0743],\n",
       "                       ...,\n",
       "                       [ 0.0956, -0.0856, -0.0080,  ..., -0.1159,  0.0224,  0.0372],\n",
       "                       [-0.1532,  0.0634,  0.0653,  ..., -0.1522,  0.0069,  0.0974],\n",
       "                       [-0.0213, -0.1409,  0.1110,  ...,  0.0792,  0.1121, -0.0488]])),\n",
       "              ('net.models.1.interactions.1.interatomic_context_net.0.bias',\n",
       "               tensor([ 2.8768e-03,  2.2264e-04, -4.8913e-03,  7.9123e-03, -4.5467e-03,\n",
       "                       -3.0447e-03, -5.0731e-03,  1.2035e-03, -3.0754e-03, -3.9723e-03,\n",
       "                        1.9220e-03, -2.0681e-04, -5.8279e-03, -9.7536e-03, -4.4500e-03,\n",
       "                        3.3830e-04,  3.2596e-04,  7.0955e-03,  1.3369e-03, -7.4222e-03,\n",
       "                       -1.0404e-03, -9.6312e-03, -2.7521e-03, -1.0367e-02,  3.3035e-03,\n",
       "                        1.0386e-03,  3.8943e-03, -5.5837e-03,  1.3099e-03,  1.1524e-03,\n",
       "                        6.1495e-03,  4.4716e-03,  2.6785e-03, -6.0478e-03, -3.6418e-03,\n",
       "                        7.0267e-04, -1.0722e-02,  3.9143e-03, -7.0865e-03,  5.2847e-04,\n",
       "                       -5.5198e-04, -3.0789e-03,  1.0995e-03,  4.7928e-03, -2.8401e-03,\n",
       "                       -1.5520e-03, -7.1333e-03,  2.8642e-03, -6.1099e-04, -1.6380e-03,\n",
       "                       -7.8828e-03, -3.4811e-03,  8.2059e-05, -5.0999e-03,  9.8397e-03,\n",
       "                        1.1420e-02,  4.9899e-03, -5.5703e-03, -1.0848e-03, -2.4199e-03,\n",
       "                       -1.3713e-02,  1.4162e-03, -3.9195e-03, -1.6806e-03, -1.1067e-03,\n",
       "                       -1.0159e-02, -8.5751e-06, -5.6307e-03, -1.1042e-02,  4.9849e-03,\n",
       "                       -4.2083e-03, -1.0721e-03,  6.8541e-03, -4.6180e-03, -7.5460e-06,\n",
       "                       -6.9135e-04, -8.0491e-03, -1.3453e-02, -1.4976e-02, -9.4721e-03,\n",
       "                       -1.9590e-03,  4.9439e-03, -1.3006e-02, -1.1249e-02, -5.1780e-03,\n",
       "                        5.6555e-03, -2.2704e-03,  2.6794e-03,  6.3408e-03, -1.6905e-04,\n",
       "                        5.4825e-03, -4.2325e-03, -7.7966e-04, -3.5259e-03, -2.3034e-04,\n",
       "                       -4.4978e-04, -4.3480e-03, -1.2617e-02,  3.5584e-03, -6.0033e-03,\n",
       "                       -1.4332e-02,  3.5739e-03,  6.9290e-03, -6.6137e-03, -7.8842e-03,\n",
       "                        6.0123e-03, -1.2130e-02,  7.0012e-03, -5.3043e-03,  2.4732e-03,\n",
       "                       -5.1939e-03, -9.4764e-03, -6.0558e-03, -3.4753e-03, -7.5690e-03,\n",
       "                       -6.6905e-03, -3.2328e-03, -1.1145e-02,  4.5443e-03,  8.3455e-03,\n",
       "                       -4.4190e-03, -4.7964e-03,  1.3764e-03,  1.0400e-02, -8.0957e-03,\n",
       "                        1.0848e-03, -5.7156e-04,  4.3084e-03])),\n",
       "              ('net.models.1.interactions.1.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0383, -0.1055, -0.0476,  ..., -0.0192,  0.0020, -0.0649],\n",
       "                       [-0.0932,  0.1069,  0.0559,  ..., -0.0227,  0.0809, -0.0607],\n",
       "                       [ 0.0559,  0.0397,  0.0821,  ..., -0.0630, -0.0398, -0.0543],\n",
       "                       ...,\n",
       "                       [-0.0242,  0.0783, -0.0943,  ...,  0.0488, -0.0738, -0.0753],\n",
       "                       [ 0.0332,  0.0427, -0.0566,  ..., -0.0498, -0.0063,  0.1084],\n",
       "                       [ 0.0511, -0.0198, -0.0598,  ...,  0.0488, -0.0892,  0.0026]])),\n",
       "              ('net.models.1.interactions.1.interatomic_context_net.1.bias',\n",
       "               tensor([-1.5015e-03,  3.9955e-04, -2.2905e-03, -5.9293e-03, -1.4643e-03,\n",
       "                        5.9098e-03, -9.9795e-03,  1.1026e-04,  3.7812e-04,  6.5003e-03,\n",
       "                        7.9701e-03, -6.1537e-03, -5.4789e-03, -1.3646e-03, -3.6773e-03,\n",
       "                       -5.8213e-03, -5.0903e-04,  6.9377e-03, -1.3747e-02, -9.2925e-03,\n",
       "                        1.8994e-03, -8.1192e-03,  1.2776e-03, -1.6303e-02, -8.9438e-04,\n",
       "                        8.2840e-04,  1.3215e-03, -7.3481e-03,  7.0210e-03,  1.2675e-03,\n",
       "                        5.9219e-03, -4.6823e-03, -2.5358e-03,  3.2844e-03, -4.9115e-03,\n",
       "                        4.3195e-03,  8.7425e-03,  3.6907e-03,  4.8427e-04, -3.7454e-03,\n",
       "                        6.9182e-03,  1.1014e-02,  4.1683e-04, -9.9051e-03, -4.0011e-03,\n",
       "                        2.9299e-03,  5.5183e-04,  4.7165e-03, -8.6273e-03, -1.2429e-02,\n",
       "                        2.2547e-03, -5.4535e-03, -6.2840e-03,  2.6452e-03,  1.1267e-05,\n",
       "                        4.5128e-03, -1.4333e-03, -6.0322e-03, -8.9287e-03,  3.1385e-04,\n",
       "                        1.4879e-04, -5.8122e-03,  6.6028e-03, -2.8567e-03, -7.7275e-03,\n",
       "                       -4.1437e-03, -8.4717e-03,  6.8506e-04,  8.1078e-03,  2.4434e-03,\n",
       "                        8.9780e-04, -5.3778e-03,  4.9594e-03, -5.8370e-03,  4.6876e-03,\n",
       "                       -3.6848e-05,  2.8687e-03,  5.2913e-04,  3.1408e-03,  2.1709e-03,\n",
       "                        5.1988e-03, -3.9003e-03,  2.4952e-03, -6.3329e-03,  2.9132e-03,\n",
       "                       -5.7485e-05,  4.5913e-03,  3.5251e-04, -8.5935e-03,  9.4008e-04,\n",
       "                       -3.2096e-03,  5.8612e-03, -4.3674e-03,  3.3143e-03, -7.1412e-03,\n",
       "                        1.1976e-03, -4.9766e-03,  3.7418e-03, -9.7506e-03, -1.6643e-02,\n",
       "                        2.5294e-03, -4.7756e-04,  3.4064e-04,  1.4630e-03, -5.5295e-03,\n",
       "                        3.9445e-03,  2.3679e-04, -1.1428e-02, -9.3615e-03,  3.4839e-03,\n",
       "                        6.3897e-03,  9.2857e-03,  1.0753e-03,  5.8347e-03,  3.9237e-03,\n",
       "                        9.9018e-04, -3.9031e-03, -1.4685e-04,  7.3656e-03,  3.2807e-03,\n",
       "                       -5.8366e-04,  6.9381e-04,  4.6807e-03,  2.4103e-03,  2.4265e-03,\n",
       "                        1.0685e-02, -1.1788e-02, -8.0670e-03, -2.2350e-03, -6.5953e-03,\n",
       "                       -8.8316e-03, -7.5523e-03,  3.1191e-03, -5.4896e-03,  2.0619e-03,\n",
       "                       -5.0355e-04, -9.1182e-04,  2.5058e-03,  3.4240e-04,  1.5084e-02,\n",
       "                       -3.2920e-03,  1.3419e-02,  5.1487e-03,  1.0819e-02, -5.0960e-03,\n",
       "                       -1.9496e-03,  2.4932e-03,  3.5625e-04, -1.5715e-03,  7.2519e-03,\n",
       "                        1.0454e-04,  6.4189e-03,  2.6829e-04,  8.4604e-04, -5.6692e-03,\n",
       "                        6.6055e-03,  1.6689e-02, -4.0255e-03,  5.6253e-03, -3.5919e-04,\n",
       "                       -1.0782e-02, -4.5217e-03, -8.1492e-04,  1.0229e-02, -6.1519e-03,\n",
       "                       -5.4146e-03, -4.3827e-03,  7.6997e-03, -1.7791e-02,  7.0189e-03,\n",
       "                        9.7175e-03,  1.5808e-02, -4.6830e-04,  4.4769e-03,  3.6830e-03,\n",
       "                       -1.4399e-02, -1.0762e-02,  4.1255e-03,  9.5543e-05,  8.4012e-03,\n",
       "                        2.5971e-03,  4.2537e-03,  1.0068e-04, -1.9761e-02, -1.8560e-03,\n",
       "                        5.1946e-03,  2.0124e-02,  2.3093e-03, -3.8306e-03, -1.1002e-02,\n",
       "                       -7.2810e-03,  8.1606e-03,  1.0289e-03, -4.6739e-03,  5.8371e-03,\n",
       "                        1.9069e-03,  4.3430e-03,  6.7990e-03,  6.8786e-03, -9.9801e-03,\n",
       "                       -6.9987e-03, -5.6091e-03, -4.7607e-03, -5.4612e-03,  5.0241e-03,\n",
       "                        1.3819e-03,  1.5596e-03,  3.5989e-03,  3.4596e-03, -8.1018e-03,\n",
       "                       -1.1664e-02,  1.6174e-02,  2.3980e-04, -1.6359e-03,  3.1205e-03,\n",
       "                        3.2370e-03,  9.7964e-03,  8.5847e-03,  1.0293e-02,  1.1142e-02,\n",
       "                       -1.0780e-06, -1.1847e-02, -2.8513e-03, -5.2764e-03,  5.6347e-03,\n",
       "                       -5.1296e-03, -4.4919e-04,  1.4283e-02,  1.9723e-03,  3.7060e-03,\n",
       "                        1.5856e-04,  7.6709e-03, -6.2603e-03, -3.7017e-03,  7.7250e-03,\n",
       "                        3.8683e-03, -7.3676e-03,  8.4562e-03,  9.3237e-03, -4.6015e-03,\n",
       "                        7.5607e-03,  1.5935e-03, -9.7355e-03, -2.7222e-03, -4.4125e-03,\n",
       "                        7.1827e-03,  6.7370e-03,  3.4229e-03,  1.2880e-02,  5.8871e-03,\n",
       "                        4.5232e-03, -5.1872e-03,  3.7915e-03,  1.9958e-03,  6.1236e-03,\n",
       "                        6.3957e-03,  2.4710e-03,  1.9772e-02,  1.5203e-03,  8.1226e-03,\n",
       "                        5.4796e-03, -2.6581e-03, -2.2154e-04,  1.0299e-02,  2.5859e-03,\n",
       "                       -1.1342e-02,  5.4219e-03,  1.8892e-03, -6.9827e-03,  1.3615e-02,\n",
       "                        6.5689e-03, -1.1790e-02,  4.2579e-03,  7.3179e-03,  9.2737e-03,\n",
       "                        1.7026e-02,  1.4744e-03, -6.5765e-03,  1.6724e-02,  9.6946e-03,\n",
       "                        5.1614e-03,  3.4944e-03,  1.5409e-03,  2.1684e-03,  1.2022e-02,\n",
       "                       -1.5223e-04, -1.8032e-02,  6.1177e-03, -5.1412e-03,  1.7683e-02,\n",
       "                       -1.3080e-02,  1.1337e-02,  1.8497e-03,  4.1190e-03,  2.7536e-03,\n",
       "                        1.2455e-02,  1.3023e-02,  1.3637e-02, -6.7835e-04,  7.6295e-03,\n",
       "                        8.4369e-03,  1.5550e-03, -2.5703e-03,  2.9189e-03,  1.2014e-02,\n",
       "                        5.1486e-03,  8.5809e-03,  1.2497e-02,  1.5498e-03,  9.2718e-04,\n",
       "                       -1.1585e-02,  6.3830e-03,  1.1064e-02,  7.8096e-03,  1.4555e-03,\n",
       "                       -2.0935e-03, -1.0730e-03, -1.0899e-02, -4.3892e-03, -8.7028e-03,\n",
       "                        1.5014e-02, -9.1594e-03,  1.1992e-03, -1.6388e-03,  5.8199e-03,\n",
       "                        6.1752e-05, -4.4493e-03,  1.2718e-02,  8.5893e-03,  2.0832e-03,\n",
       "                       -5.2682e-03, -1.5709e-02, -5.2411e-03, -9.2918e-03, -9.3529e-03,\n",
       "                        1.1699e-03,  6.2811e-03,  7.0702e-03, -1.4515e-03, -7.8958e-03,\n",
       "                       -2.4871e-03,  3.2342e-03, -6.6738e-03, -1.4486e-02,  1.6719e-03,\n",
       "                       -7.6952e-04, -3.1341e-03,  8.6850e-03,  1.2865e-02,  1.2822e-02,\n",
       "                       -4.8211e-03,  1.4251e-02,  4.5379e-04, -9.4462e-03, -1.3819e-02,\n",
       "                        8.4448e-03, -5.6746e-03, -1.2981e-03,  5.9908e-03,  1.7742e-02,\n",
       "                        1.0607e-02,  5.0281e-04, -1.0525e-02, -1.4329e-02,  3.2747e-03,\n",
       "                       -6.8055e-03,  5.8332e-03, -6.0533e-04, -1.9372e-02, -9.5013e-03,\n",
       "                       -4.8957e-03, -1.0640e-02, -2.8912e-03, -1.6115e-02, -7.9027e-03,\n",
       "                       -8.6625e-03, -7.6174e-03,  1.0297e-02,  1.8866e-03, -6.5996e-03,\n",
       "                        8.2132e-03, -5.8527e-03, -5.5280e-03, -1.4624e-02])),\n",
       "              ('net.models.1.interactions.2.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.0932,  0.0476,  0.1095,  ...,  0.1470,  0.0724,  0.0621],\n",
       "                       [ 0.0456, -0.0540, -0.0209,  ...,  0.0262,  0.1137,  0.0262],\n",
       "                       [ 0.1224, -0.0070,  0.0900,  ...,  0.1239, -0.1444, -0.1207],\n",
       "                       ...,\n",
       "                       [ 0.0840,  0.0504, -0.1411,  ...,  0.0532, -0.0883, -0.0973],\n",
       "                       [-0.1035, -0.0793, -0.0574,  ...,  0.0500, -0.0689, -0.0074],\n",
       "                       [-0.1633,  0.1459,  0.1018,  ..., -0.1388, -0.0793,  0.0373]])),\n",
       "              ('net.models.1.interactions.2.interatomic_context_net.0.bias',\n",
       "               tensor([-9.0201e-03,  1.3140e-03, -5.7553e-03, -5.5954e-03, -3.3058e-03,\n",
       "                        4.8741e-04,  6.8989e-03,  3.4363e-03,  6.7377e-03,  6.6362e-03,\n",
       "                        2.5102e-03,  7.6902e-03, -6.3832e-03,  7.0261e-04, -5.7687e-04,\n",
       "                        2.7459e-04, -6.6311e-03,  7.4332e-03, -3.4303e-03, -7.2540e-03,\n",
       "                       -5.8376e-03, -6.6079e-03,  5.3397e-05, -4.9189e-03, -6.8137e-03,\n",
       "                        8.5581e-03, -1.0181e-03, -9.5133e-03, -1.3741e-02, -1.5951e-02,\n",
       "                       -3.2044e-03,  3.7665e-03, -2.9374e-03, -7.1302e-03, -3.0031e-04,\n",
       "                        1.8097e-03, -5.9527e-03,  7.5076e-03, -8.5310e-03, -3.6674e-03,\n",
       "                        4.3599e-03,  9.1900e-04, -5.3375e-03,  6.6906e-04, -4.2271e-03,\n",
       "                       -3.1091e-03, -2.0779e-03, -1.4184e-03, -1.0512e-02, -1.0411e-02,\n",
       "                       -1.5724e-03, -8.4317e-04, -2.3031e-04,  4.8296e-04,  5.5254e-03,\n",
       "                       -1.5646e-02, -1.1296e-02, -7.8949e-04, -1.8694e-03, -5.9381e-03,\n",
       "                        8.8451e-03, -2.4684e-03, -1.3774e-03, -2.7386e-03,  5.4386e-03,\n",
       "                       -1.1288e-02, -1.8199e-03, -2.9481e-04,  4.7339e-03, -6.2881e-03,\n",
       "                       -7.3298e-04, -4.0656e-03, -8.0186e-03,  3.9952e-03, -4.0321e-03,\n",
       "                       -7.0736e-03, -2.8620e-03,  7.5739e-05, -7.5759e-03, -8.9759e-03,\n",
       "                       -7.0741e-03, -3.9846e-03,  3.1231e-03, -9.9315e-03, -4.9012e-03,\n",
       "                       -1.3602e-02, -4.2326e-03, -2.3522e-03, -6.2610e-03,  7.6042e-03,\n",
       "                       -9.5628e-03,  9.8807e-04,  2.5736e-03, -3.3007e-03,  1.8739e-03,\n",
       "                        1.0138e-02,  1.5923e-03, -1.0213e-03, -1.3813e-03, -1.1433e-02,\n",
       "                       -7.4094e-03, -3.1833e-03, -5.2541e-03, -8.9743e-03, -8.1767e-03,\n",
       "                       -3.4355e-03, -6.7575e-03, -2.6598e-03, -2.1611e-03, -1.8193e-05,\n",
       "                       -4.5680e-03, -4.1183e-03, -3.9902e-03, -2.9145e-03,  3.2729e-04,\n",
       "                       -3.4266e-03,  9.6303e-03, -1.1683e-02, -5.8931e-03, -5.6175e-03,\n",
       "                        9.1066e-03, -9.7462e-04,  5.2352e-03, -6.0356e-03,  1.0122e-03,\n",
       "                       -4.9337e-03, -1.8290e-03, -1.0330e-02])),\n",
       "              ('net.models.1.interactions.2.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0135,  0.0511,  0.0099,  ...,  0.0108,  0.1055, -0.0634],\n",
       "                       [-0.1036, -0.0811,  0.0307,  ...,  0.0705, -0.0856,  0.0278],\n",
       "                       [ 0.0618,  0.0428, -0.0615,  ..., -0.0150,  0.0821,  0.0548],\n",
       "                       ...,\n",
       "                       [-0.0334, -0.0040,  0.0282,  ..., -0.0112, -0.0088,  0.0283],\n",
       "                       [ 0.0009,  0.1064,  0.0230,  ..., -0.0112,  0.0070, -0.0295],\n",
       "                       [ 0.0958,  0.0932, -0.0703,  ..., -0.0010, -0.0143, -0.0115]])),\n",
       "              ('net.models.1.interactions.2.interatomic_context_net.1.bias',\n",
       "               tensor([-1.4214e-03,  3.2616e-03, -8.3073e-03, -1.4526e-02,  4.1189e-03,\n",
       "                        4.0523e-04,  5.4685e-03, -3.6344e-03,  4.1318e-03,  5.2526e-03,\n",
       "                       -1.7077e-04,  3.2375e-03,  9.4242e-03, -1.4729e-03, -5.2328e-03,\n",
       "                        6.5723e-03, -4.3910e-03,  5.8697e-03, -5.8415e-03, -3.9160e-03,\n",
       "                        3.1999e-03,  3.2687e-03, -6.9706e-03, -9.6370e-03,  3.2504e-03,\n",
       "                        2.1936e-03,  1.2550e-03,  1.0024e-03,  1.3591e-03, -1.0454e-02,\n",
       "                        9.3892e-03, -4.1897e-03, -4.8071e-03, -1.0158e-02,  7.8157e-03,\n",
       "                       -3.6608e-03, -5.3223e-03,  3.2224e-03, -2.0757e-03, -7.3176e-03,\n",
       "                        6.0075e-03,  1.5786e-03, -1.9388e-03, -8.3746e-03, -2.3712e-03,\n",
       "                       -2.9050e-03, -6.0559e-03, -9.9567e-04, -2.5541e-03, -1.1668e-02,\n",
       "                        5.6507e-03, -9.2046e-03,  9.0879e-03, -1.1092e-03,  1.2300e-02,\n",
       "                       -5.4114e-03,  3.1493e-03,  3.3205e-03,  9.3082e-03,  6.9442e-03,\n",
       "                        1.4262e-03,  2.0845e-03,  4.0626e-03,  4.8245e-03, -3.8749e-03,\n",
       "                       -2.6402e-03,  8.2714e-03,  2.0550e-03, -6.6744e-03, -3.0249e-03,\n",
       "                       -8.3698e-04, -7.8386e-03,  4.6718e-03,  1.9629e-04, -1.5309e-04,\n",
       "                       -4.4680e-04,  2.5707e-03, -3.7996e-03,  6.0577e-03,  3.8932e-03,\n",
       "                       -7.3467e-03, -4.8464e-03,  2.8468e-03, -2.6390e-03,  2.3660e-03,\n",
       "                       -6.4012e-03,  6.4639e-03,  3.7513e-04,  2.8664e-03,  1.1514e-03,\n",
       "                       -1.7777e-03,  4.1999e-03,  3.6371e-03, -5.5032e-03,  9.3560e-03,\n",
       "                        4.8719e-04,  1.4427e-03, -1.4097e-03, -6.8760e-03, -9.4087e-03,\n",
       "                       -3.5335e-03,  5.0883e-03, -7.4109e-03, -9.6808e-03,  1.2734e-03,\n",
       "                        1.1330e-03,  2.0125e-03,  6.8009e-04, -4.9936e-03,  1.0890e-02,\n",
       "                       -5.7667e-03, -2.6999e-03,  3.0369e-03, -2.6772e-03,  1.0084e-02,\n",
       "                       -1.9804e-03,  3.8232e-03, -6.3374e-03,  4.4555e-03, -9.6463e-04,\n",
       "                       -1.1852e-04, -6.2958e-03, -5.9923e-03, -1.0249e-03, -5.6010e-04,\n",
       "                        3.9235e-03,  6.2203e-03,  7.9388e-03,  4.9804e-03, -3.4614e-03,\n",
       "                       -1.6379e-02, -7.2737e-03,  9.0355e-03, -7.1822e-03, -2.9050e-03,\n",
       "                       -5.1114e-03,  4.8861e-03,  1.0762e-04,  1.6248e-03,  3.3370e-03,\n",
       "                       -1.3143e-02,  9.4226e-03, -2.6884e-03, -1.7637e-03,  2.0069e-02,\n",
       "                       -1.3840e-02, -2.8133e-03, -5.0615e-03, -5.4209e-03,  1.2247e-02,\n",
       "                       -1.1314e-02,  1.0615e-02, -7.3031e-04,  5.1878e-03, -3.9742e-03,\n",
       "                       -3.2041e-03, -3.9590e-03, -5.5740e-03,  1.5708e-03, -1.5167e-03,\n",
       "                        1.4335e-04, -6.5610e-04,  1.0088e-02,  2.1460e-03, -1.3596e-02,\n",
       "                       -1.8793e-02,  2.8725e-03, -1.9548e-03,  3.0209e-03, -4.0999e-04,\n",
       "                       -3.4059e-03,  2.6275e-03,  4.4659e-03, -8.6882e-03, -4.6109e-03,\n",
       "                       -2.9469e-03,  4.9042e-03,  4.3368e-03, -7.3973e-03, -8.6668e-03,\n",
       "                       -2.3785e-03,  2.2828e-03, -1.3210e-02, -4.2543e-03,  4.1676e-03,\n",
       "                       -2.8031e-03, -9.0888e-03, -1.2668e-02, -3.1996e-05,  2.4329e-03,\n",
       "                        9.3736e-04, -8.4492e-03, -1.9148e-02,  2.1252e-03, -2.2977e-04,\n",
       "                        1.0571e-02,  3.9200e-03, -1.0967e-02, -3.7190e-03, -7.3234e-03,\n",
       "                       -5.3607e-03, -4.8966e-03,  1.1474e-02,  8.5653e-03, -5.2664e-03,\n",
       "                        8.2102e-04,  1.9807e-03,  8.0117e-03,  7.7168e-03, -1.8198e-03,\n",
       "                        2.1717e-03, -5.3160e-03,  3.4724e-03,  5.8073e-03, -4.8002e-03,\n",
       "                        1.0742e-02,  6.3962e-03,  7.6225e-03, -4.8358e-03, -1.4466e-03,\n",
       "                        2.9598e-03, -2.2973e-03,  8.6909e-03, -6.5936e-03,  4.3728e-03,\n",
       "                       -4.6894e-04, -5.0268e-03,  8.7971e-03,  4.4103e-03,  5.5971e-04,\n",
       "                        3.3614e-03, -6.6182e-03,  5.3835e-03, -1.2910e-02,  2.8800e-03,\n",
       "                        1.5768e-03, -7.6081e-03, -5.7565e-03, -1.8143e-04,  4.3255e-03,\n",
       "                        3.2858e-03, -1.4522e-03, -2.8136e-03, -6.5562e-03,  7.6434e-03,\n",
       "                        6.9203e-03,  8.4286e-03,  1.4340e-03, -2.7040e-03, -5.8075e-03,\n",
       "                       -3.0127e-03, -1.6482e-03,  1.7591e-03, -4.7020e-04,  1.1327e-02,\n",
       "                       -3.1505e-03,  1.4736e-03, -3.2229e-03,  3.4997e-03,  6.7070e-03,\n",
       "                       -1.5209e-02, -9.3417e-03,  9.9822e-03,  8.4998e-03, -4.3041e-03,\n",
       "                        8.8332e-03, -1.0731e-03, -1.1543e-02, -5.6505e-03, -1.4913e-02,\n",
       "                        3.3116e-03, -7.0068e-03,  2.0117e-02, -1.5404e-02,  9.2015e-03,\n",
       "                       -6.8781e-03, -1.4401e-02,  1.5672e-03, -6.9299e-03, -6.6258e-04,\n",
       "                        3.1893e-03,  3.3689e-03,  1.0249e-02, -8.0947e-03,  1.2180e-02,\n",
       "                        1.1512e-02, -1.2771e-03, -6.6260e-03, -1.6897e-04, -1.9802e-03,\n",
       "                       -1.7862e-02,  3.2753e-03,  1.5390e-02, -3.7376e-03,  8.7127e-03,\n",
       "                        4.8356e-03, -1.9038e-02,  8.0342e-03, -3.5825e-03, -7.7456e-03,\n",
       "                        8.2283e-03, -1.2030e-02, -4.4720e-03,  1.4077e-03, -1.1798e-02,\n",
       "                       -2.5193e-03, -9.0376e-03,  1.1417e-02,  1.0157e-03, -5.0426e-03,\n",
       "                        1.5437e-02,  8.5106e-03,  5.4230e-03,  7.6928e-03, -1.0160e-02,\n",
       "                       -6.6417e-03, -1.3594e-02,  4.6343e-03, -8.8358e-04,  5.4867e-03,\n",
       "                       -5.4537e-03, -1.7835e-02, -5.4023e-03, -2.2716e-03,  2.4387e-03,\n",
       "                       -9.6235e-03,  6.0549e-03, -6.9602e-03, -1.8349e-03, -9.8856e-04,\n",
       "                        1.9970e-05, -6.3980e-04,  9.0692e-03,  7.7976e-03,  9.1091e-03,\n",
       "                        1.1003e-02,  1.5568e-02,  1.8630e-02, -1.7079e-03, -6.1700e-03,\n",
       "                        5.9487e-03, -2.0309e-03,  4.6348e-03, -1.9691e-02,  4.8539e-03,\n",
       "                        6.2958e-03, -1.9828e-02,  2.2123e-03, -9.3476e-03, -1.3489e-02,\n",
       "                       -2.7834e-03, -4.3430e-03,  6.5021e-03,  1.4464e-02,  1.3470e-03,\n",
       "                        1.1597e-02, -7.5458e-03, -1.3890e-02,  7.8772e-03, -6.8920e-03,\n",
       "                        1.4139e-02,  1.5174e-02, -9.3098e-03,  1.0199e-02,  1.3816e-02,\n",
       "                       -5.2456e-04, -2.1969e-02, -4.6082e-03,  5.9003e-03, -5.6814e-03,\n",
       "                        1.7155e-02, -8.1412e-03,  3.7492e-03, -1.1912e-02,  3.8816e-03,\n",
       "                        1.0437e-02, -6.8918e-03,  9.8665e-03, -1.1446e-04,  3.0063e-03,\n",
       "                        7.3998e-04, -2.6740e-03, -1.3483e-02,  1.5181e-02])),\n",
       "              ('net.models.1.interactions.3.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.0505,  0.0152,  0.1261,  ...,  0.0917,  0.1199, -0.0442],\n",
       "                       [ 0.0669,  0.0999, -0.1002,  ...,  0.0014, -0.1400, -0.0802],\n",
       "                       [-0.1066, -0.0903,  0.0542,  ...,  0.0979, -0.1081,  0.0214],\n",
       "                       ...,\n",
       "                       [-0.1267,  0.0726,  0.1017,  ...,  0.1469,  0.1364, -0.1275],\n",
       "                       [-0.1133,  0.1111,  0.1575,  ..., -0.1392, -0.1172,  0.1416],\n",
       "                       [ 0.0711, -0.0275, -0.0936,  ..., -0.1352, -0.0565,  0.0777]])),\n",
       "              ('net.models.1.interactions.3.interatomic_context_net.0.bias',\n",
       "               tensor([ 6.2846e-03, -9.7411e-04, -1.5997e-03,  1.7961e-05, -5.7046e-03,\n",
       "                       -5.7005e-03,  1.5240e-03,  3.2142e-03, -1.4955e-02, -4.2968e-03,\n",
       "                       -1.3120e-02,  4.2403e-03, -7.5550e-03,  8.7520e-04, -1.4571e-04,\n",
       "                       -5.2549e-03,  8.7347e-03, -1.2223e-02, -3.1276e-03,  4.5720e-04,\n",
       "                       -1.7653e-03, -1.6313e-03, -1.9747e-02, -3.8131e-03,  5.7361e-03,\n",
       "                       -1.2808e-02,  7.4524e-04, -6.7591e-03, -3.9395e-04,  3.1937e-03,\n",
       "                        3.0849e-03, -5.3290e-03,  9.1037e-03, -9.0130e-03, -2.7079e-03,\n",
       "                       -6.3518e-03, -3.5586e-03, -1.6622e-03, -8.8862e-03,  7.9929e-04,\n",
       "                        1.2776e-02,  4.9534e-03,  1.9559e-03, -5.3253e-03, -1.8431e-02,\n",
       "                       -6.1945e-03, -1.1248e-02, -6.9933e-04, -1.2551e-02,  2.6396e-03,\n",
       "                       -1.5165e-02, -6.3957e-03,  1.2309e-03, -5.7956e-03,  3.4451e-03,\n",
       "                       -5.8395e-03, -2.7602e-03,  6.0869e-03, -3.3224e-03, -5.0786e-03,\n",
       "                       -6.7781e-03, -3.3220e-04,  5.6410e-03, -1.3679e-02, -4.9568e-03,\n",
       "                       -1.4163e-03, -5.4008e-03, -1.7775e-03, -5.6926e-03,  1.8911e-03,\n",
       "                       -9.2560e-03, -7.3195e-04, -1.1716e-03,  5.6226e-04, -5.8500e-03,\n",
       "                       -1.6108e-03, -1.7376e-03, -3.9567e-03,  1.4886e-03, -5.5551e-03,\n",
       "                       -5.3527e-03, -8.6325e-04, -4.8511e-03, -4.1344e-03, -9.2659e-03,\n",
       "                       -1.1902e-02,  5.1147e-03, -1.7439e-03, -7.8398e-03, -1.0813e-02,\n",
       "                        4.3565e-03,  6.2826e-03, -7.2220e-03, -5.0486e-03,  1.8631e-03,\n",
       "                       -1.5122e-03,  1.0082e-02,  5.4951e-04, -3.5290e-03,  7.1471e-04,\n",
       "                       -8.8957e-03, -9.8621e-03, -2.0038e-03, -3.8261e-03,  3.7558e-03,\n",
       "                        5.0488e-03, -5.4749e-03,  2.1747e-03,  3.0535e-03, -2.9998e-03,\n",
       "                       -5.1165e-03, -8.9511e-03, -6.5679e-03, -3.2315e-03, -8.9399e-03,\n",
       "                        4.1810e-05, -7.8809e-03, -6.4775e-04,  6.7103e-03, -7.2770e-03,\n",
       "                       -1.7115e-03, -4.4113e-03, -3.6683e-03, -1.1543e-02, -2.7725e-03,\n",
       "                       -6.5634e-03, -6.8312e-03, -9.5541e-03])),\n",
       "              ('net.models.1.interactions.3.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0447,  0.0782,  0.0913,  ...,  0.0411, -0.0958, -0.0970],\n",
       "                       [ 0.0422,  0.0815,  0.0930,  ..., -0.0420, -0.0180,  0.0686],\n",
       "                       [-0.0366,  0.0593, -0.1041,  ..., -0.0792,  0.0617, -0.0645],\n",
       "                       ...,\n",
       "                       [ 0.0254,  0.0244,  0.0509,  ...,  0.0614, -0.0563, -0.0587],\n",
       "                       [-0.0044,  0.0390, -0.0009,  ..., -0.0339, -0.0040, -0.0579],\n",
       "                       [ 0.0494, -0.0054, -0.0221,  ..., -0.0686,  0.0525,  0.0625]])),\n",
       "              ('net.models.1.interactions.3.interatomic_context_net.1.bias',\n",
       "               tensor([-2.6381e-03, -7.5360e-03, -6.6494e-03, -5.6980e-03,  2.5520e-03,\n",
       "                        4.8013e-03, -7.2162e-03, -1.0505e-03, -1.7909e-03, -2.2782e-03,\n",
       "                        2.4196e-03, -3.7227e-03, -1.1019e-03,  6.5635e-03,  6.3675e-03,\n",
       "                       -6.5865e-04,  8.9290e-03,  3.8233e-03,  6.9250e-03, -2.9661e-03,\n",
       "                       -8.2642e-04,  7.1239e-03,  1.0118e-02, -6.6805e-03, -4.9657e-03,\n",
       "                        9.0520e-03, -2.0482e-03,  1.6777e-03, -6.0561e-03,  2.3710e-03,\n",
       "                       -9.1734e-03,  5.1474e-03, -2.7135e-03, -3.9563e-03,  1.9931e-03,\n",
       "                       -3.7277e-03,  4.7924e-03,  3.5726e-03,  4.8679e-03, -4.6890e-04,\n",
       "                        1.3446e-04, -7.9834e-04, -2.2328e-03, -2.7714e-03, -9.3911e-03,\n",
       "                        3.2862e-03, -1.8123e-03,  6.0983e-03,  2.4929e-03,  6.5400e-03,\n",
       "                       -2.8792e-03,  1.1013e-03, -8.0704e-03, -8.8473e-03, -8.7031e-03,\n",
       "                        5.4219e-03, -1.0550e-03,  5.7751e-03,  6.8187e-03,  9.2058e-04,\n",
       "                        3.1555e-03,  2.5891e-03, -1.2111e-04,  3.0984e-03,  8.2244e-03,\n",
       "                        8.7845e-03, -8.3889e-03,  6.1248e-03,  1.6726e-03,  1.3460e-03,\n",
       "                       -3.5214e-03, -1.4676e-03,  1.8741e-04,  2.1979e-03,  8.1429e-03,\n",
       "                       -2.7129e-03,  1.0737e-03,  1.7138e-05,  4.6038e-03,  5.7473e-03,\n",
       "                       -2.6518e-03, -3.8560e-03,  3.6387e-03,  5.4575e-03,  1.5329e-03,\n",
       "                       -8.1858e-03,  4.2652e-03,  1.7184e-03,  9.4377e-03, -5.4965e-05,\n",
       "                       -1.1141e-02,  2.3906e-03, -4.2136e-03, -1.3536e-03, -3.9861e-03,\n",
       "                        1.5024e-03, -5.3288e-03, -5.8269e-03,  4.4200e-03, -6.0037e-03,\n",
       "                        1.9812e-03,  9.4941e-03,  1.0724e-03, -6.1510e-03, -5.2593e-03,\n",
       "                        3.8572e-04, -6.4937e-03,  1.8431e-04,  1.4005e-02, -5.4236e-04,\n",
       "                        6.3069e-03,  6.7697e-03,  1.2131e-03, -4.0667e-04,  3.4881e-03,\n",
       "                        5.7810e-04, -9.2345e-03, -2.5112e-03, -3.4232e-03, -9.0044e-04,\n",
       "                        1.1346e-03, -5.8061e-03,  1.8854e-03, -3.0214e-03,  2.1003e-03,\n",
       "                        2.6851e-03, -5.8481e-03,  1.2290e-02,  6.0638e-03, -4.4384e-03,\n",
       "                        5.2136e-03,  3.6217e-03, -2.8357e-03, -4.5176e-03, -7.2952e-03,\n",
       "                       -9.8220e-03,  8.0527e-04, -7.4541e-03,  1.7164e-02, -9.0492e-03,\n",
       "                        1.8430e-03, -3.8259e-03,  3.9408e-03, -6.9797e-04,  1.6255e-03,\n",
       "                       -2.5722e-03,  2.6924e-03, -3.3786e-03, -1.4511e-02, -4.1958e-03,\n",
       "                        8.9369e-03,  1.3897e-03,  5.6764e-03, -3.8686e-03, -4.3492e-04,\n",
       "                       -5.0928e-03, -1.6578e-02, -2.6044e-03, -4.4725e-03, -2.6300e-04,\n",
       "                        7.5786e-03,  6.0671e-03, -1.0857e-02,  7.5316e-03, -1.1794e-03,\n",
       "                        1.7770e-03, -1.8880e-03,  1.0610e-02, -1.4926e-02,  2.4567e-03,\n",
       "                       -2.2236e-03, -9.8485e-03,  4.9302e-03,  2.9676e-03, -6.5083e-03,\n",
       "                       -2.1675e-03, -1.6328e-03, -1.1912e-02, -3.6353e-04, -1.4006e-03,\n",
       "                        2.8171e-03,  1.2063e-02,  1.0393e-02, -6.4858e-03, -1.0107e-02,\n",
       "                        1.1600e-02, -8.4700e-03,  9.9945e-03,  1.0769e-02,  6.5440e-03,\n",
       "                       -1.6714e-03,  1.0165e-02,  8.4023e-03, -1.1026e-02, -2.4616e-03,\n",
       "                        1.9566e-03,  2.7352e-03,  1.2378e-03, -1.0456e-03,  6.0221e-03,\n",
       "                       -8.5298e-03, -2.9540e-03,  7.3972e-03, -9.5139e-04,  1.7265e-03,\n",
       "                        2.0629e-04,  4.8360e-03,  7.2088e-04,  2.3923e-04,  1.8051e-03,\n",
       "                       -2.5098e-03,  8.0889e-03,  3.9062e-03, -3.0900e-03, -3.0505e-03,\n",
       "                        4.9702e-03, -4.2360e-03,  4.4679e-04,  1.0592e-02, -5.0780e-03,\n",
       "                       -9.7532e-03,  3.2617e-03,  4.1979e-03,  6.8207e-03, -5.5359e-03,\n",
       "                       -8.7953e-03,  6.8118e-03, -3.3229e-03,  1.0776e-02,  3.9363e-04,\n",
       "                       -3.9983e-04,  2.9141e-03, -6.0684e-03,  4.7882e-03, -8.2418e-03,\n",
       "                       -6.4124e-03, -8.6927e-03, -2.4049e-03,  1.0882e-02,  3.0928e-03,\n",
       "                       -6.9488e-03, -3.3043e-03, -4.8817e-03, -5.1821e-03,  1.7485e-03,\n",
       "                       -2.4976e-03,  6.8332e-03, -8.8323e-03, -5.7146e-03, -4.0909e-03,\n",
       "                        2.0573e-03, -1.4175e-03,  3.7372e-03, -1.1788e-02,  1.2180e-03,\n",
       "                       -9.2530e-03,  1.3043e-03,  9.4135e-03, -6.5269e-03,  1.6155e-02,\n",
       "                       -8.4668e-03, -1.4963e-02,  5.9514e-03,  1.3675e-02,  3.4680e-04,\n",
       "                        1.3285e-02, -7.8217e-05, -1.2295e-02,  1.8443e-03, -1.2090e-03,\n",
       "                       -1.1775e-03, -8.6743e-03,  1.4184e-02,  1.2294e-02, -1.7776e-02,\n",
       "                       -9.3618e-03, -1.2413e-02, -1.0594e-02,  1.0631e-02,  9.6108e-04,\n",
       "                       -4.8722e-03, -2.0004e-03,  4.2782e-03,  6.1318e-03, -3.0887e-03,\n",
       "                        1.3342e-04, -4.4276e-04,  3.4728e-03,  9.4459e-03,  9.9157e-03,\n",
       "                       -5.3094e-03,  3.8907e-03,  3.1301e-03, -5.9910e-03,  5.1029e-03,\n",
       "                       -1.7250e-03, -6.3643e-03, -1.5830e-03, -9.0983e-03, -8.4536e-03,\n",
       "                       -3.7122e-03,  7.5592e-03,  8.6898e-03,  8.9781e-03, -3.4366e-03,\n",
       "                        1.7400e-03,  1.4857e-02,  1.3594e-02, -5.3808e-03,  1.9472e-03,\n",
       "                        6.6694e-04, -4.4657e-03, -6.1308e-03,  1.0330e-02, -1.5789e-02,\n",
       "                       -5.9667e-03, -6.6530e-03,  9.3801e-03,  3.8679e-04, -1.4698e-02,\n",
       "                       -6.2718e-03,  1.7019e-02,  1.3917e-02, -5.8165e-03,  8.2279e-04,\n",
       "                        7.5590e-04, -1.3711e-02, -1.2526e-02, -8.7377e-04,  1.6757e-02,\n",
       "                        6.8383e-03,  4.8922e-03, -9.3938e-03,  1.7010e-02,  5.1438e-03,\n",
       "                       -8.5416e-03,  1.7903e-02, -1.3299e-02, -1.2612e-02, -1.9764e-02,\n",
       "                        1.3258e-02,  6.1887e-03,  3.6705e-03, -1.1906e-02,  1.0686e-02,\n",
       "                        1.1112e-02,  1.2811e-02, -3.3324e-03,  1.1375e-02, -9.2099e-04,\n",
       "                        4.8349e-03,  4.2456e-03, -5.6150e-03,  1.2401e-02, -1.7244e-02,\n",
       "                        9.8611e-03,  5.1475e-03,  5.0944e-03,  6.5431e-03, -5.7138e-03,\n",
       "                       -2.1485e-02, -1.7555e-02, -1.4373e-03,  8.3476e-03,  5.0464e-03,\n",
       "                       -6.2868e-03,  1.8473e-02,  1.1613e-02, -1.2161e-02, -2.3104e-02,\n",
       "                        6.0105e-03, -8.6735e-03,  2.0784e-03,  1.6177e-02, -1.3775e-02,\n",
       "                       -8.8181e-03, -1.1349e-02,  1.2703e-02, -1.6783e-02, -9.6771e-03,\n",
       "                        1.2549e-02,  1.1466e-02,  1.3809e-02,  8.8785e-04])),\n",
       "              ('net.models.1.interactions.4.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.0563,  0.1263,  0.1444,  ..., -0.0566,  0.0366, -0.1249],\n",
       "                       [ 0.0740,  0.0558, -0.1021,  ..., -0.0903,  0.0381, -0.0853],\n",
       "                       [ 0.0187,  0.0434,  0.1142,  ..., -0.0428, -0.0889, -0.0163],\n",
       "                       ...,\n",
       "                       [ 0.1410, -0.0982,  0.0531,  ...,  0.0778,  0.1283,  0.0346],\n",
       "                       [-0.0765,  0.0145, -0.0444,  ...,  0.0785,  0.0905, -0.1407],\n",
       "                       [ 0.0431, -0.0133, -0.1151,  ...,  0.0585,  0.1234, -0.0289]])),\n",
       "              ('net.models.1.interactions.4.interatomic_context_net.0.bias',\n",
       "               tensor([-1.0241e-02, -3.7858e-03, -2.6381e-03,  5.3184e-03,  5.8317e-03,\n",
       "                       -8.4036e-04, -1.6016e-03, -4.9069e-03, -4.9226e-03,  4.4437e-03,\n",
       "                       -6.7735e-03, -2.5408e-03,  4.6011e-03, -1.1731e-03, -4.2534e-03,\n",
       "                       -1.3342e-03, -4.2979e-03, -7.6619e-03, -8.9416e-03, -2.7762e-03,\n",
       "                       -3.9038e-03,  4.2637e-03,  5.0615e-05, -2.3985e-03, -7.5236e-03,\n",
       "                       -9.0338e-03,  1.4925e-04,  2.8588e-03, -9.1173e-03, -7.8308e-03,\n",
       "                       -2.6023e-03,  1.0449e-02, -6.6527e-03,  1.9130e-03, -8.5912e-03,\n",
       "                       -3.0920e-03,  8.5677e-03, -4.3589e-03,  6.3220e-03, -2.3242e-03,\n",
       "                        3.9999e-03,  3.7786e-04,  1.7080e-03, -3.9757e-04,  3.1774e-04,\n",
       "                       -9.5317e-03,  3.9521e-03,  3.6514e-04, -4.9417e-03, -2.4114e-03,\n",
       "                        8.4628e-04,  8.0509e-03, -1.0882e-02, -4.7379e-04, -1.0884e-02,\n",
       "                       -6.9186e-03, -4.5036e-03,  1.8530e-03,  3.9796e-03, -9.7397e-03,\n",
       "                       -8.2135e-03, -3.8248e-03, -8.6218e-03, -6.1513e-03, -4.1983e-04,\n",
       "                       -4.9901e-03, -9.5312e-03, -8.6499e-03, -4.5759e-03, -3.7209e-03,\n",
       "                        2.4630e-03,  7.2450e-03, -1.0205e-02, -1.1397e-03, -1.0795e-03,\n",
       "                        1.4893e-04, -3.0827e-03, -5.7636e-04, -8.0590e-05,  7.1751e-04,\n",
       "                        5.4742e-03, -1.1728e-02,  1.3078e-02,  6.8158e-04, -4.7767e-03,\n",
       "                       -2.9638e-03, -5.2537e-03, -1.0968e-03, -1.2755e-04, -1.2869e-04,\n",
       "                       -1.1829e-02, -7.8497e-03, -1.2634e-02, -2.2019e-04,  2.1374e-04,\n",
       "                       -7.9650e-04, -2.7257e-03, -1.0120e-02, -7.7469e-03, -6.4554e-03,\n",
       "                       -4.8570e-03, -2.0217e-03, -1.5480e-03, -4.6634e-03,  2.8187e-03,\n",
       "                       -6.5488e-04,  1.8852e-03,  1.6862e-03,  1.2553e-03, -1.3763e-02,\n",
       "                       -5.1173e-03,  3.8513e-03, -1.1424e-02, -6.9354e-03, -3.5855e-03,\n",
       "                       -9.5258e-03, -5.2138e-03,  2.0480e-03, -3.9727e-03, -2.5926e-03,\n",
       "                        3.3018e-03, -6.6615e-03,  4.9793e-03, -2.4467e-03, -3.1496e-03,\n",
       "                       -3.5028e-03, -1.2207e-02,  2.1881e-03])),\n",
       "              ('net.models.1.interactions.4.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0948,  0.0462, -0.0258,  ..., -0.0978, -0.0303, -0.0602],\n",
       "                       [ 0.0945,  0.0146, -0.0128,  ..., -0.0480, -0.0011,  0.0175],\n",
       "                       [ 0.0183,  0.0174, -0.0206,  ..., -0.0336,  0.0682,  0.0531],\n",
       "                       ...,\n",
       "                       [ 0.0853,  0.1047, -0.1060,  ...,  0.0513, -0.0627,  0.0900],\n",
       "                       [-0.0947, -0.0090,  0.0927,  ...,  0.0164, -0.0242,  0.0059],\n",
       "                       [ 0.0158, -0.0794, -0.0062,  ...,  0.1050,  0.0519,  0.0939]])),\n",
       "              ('net.models.1.interactions.4.interatomic_context_net.1.bias',\n",
       "               tensor([-1.6469e-03, -3.8927e-03,  4.6755e-03,  2.6447e-03,  2.3971e-03,\n",
       "                       -1.7711e-03, -1.9930e-03, -2.7519e-03, -9.8070e-03,  8.9865e-04,\n",
       "                       -1.8325e-03,  2.4749e-03, -7.6151e-03,  2.8878e-03,  3.7758e-03,\n",
       "                       -2.5541e-03, -1.7861e-03,  2.6408e-03, -6.4507e-03, -4.9112e-03,\n",
       "                       -5.2030e-03,  1.6767e-03,  2.2649e-03, -4.2355e-03,  1.2325e-03,\n",
       "                       -7.3167e-04, -6.8560e-03, -8.3858e-04, -6.0426e-03, -1.0321e-02,\n",
       "                       -9.5872e-03,  3.1244e-03,  2.5138e-03, -5.7210e-03,  4.5361e-03,\n",
       "                        2.3197e-03, -9.4636e-03,  9.0584e-03,  2.8855e-03,  1.9668e-03,\n",
       "                        7.4540e-04, -8.1556e-04,  5.5620e-03,  3.4409e-03,  5.0040e-03,\n",
       "                        2.1168e-03, -2.0827e-03,  3.5449e-03,  6.8317e-03, -2.3962e-04,\n",
       "                        2.1612e-03, -1.7012e-03, -1.3529e-03,  5.3431e-04,  1.6067e-02,\n",
       "                       -9.4240e-03,  4.1097e-03, -1.2470e-04, -1.9357e-03, -6.8083e-03,\n",
       "                       -2.3390e-03,  6.8149e-03, -7.5753e-03,  2.0530e-03, -1.5587e-03,\n",
       "                        7.6366e-03,  3.3159e-04,  2.2737e-03, -7.2796e-04,  2.3383e-03,\n",
       "                        2.9710e-03,  3.2259e-03, -2.6860e-03,  6.6973e-03,  1.3544e-03,\n",
       "                        9.3300e-04,  3.5881e-03, -3.0959e-03, -2.9878e-03, -2.1025e-03,\n",
       "                        1.2055e-03, -3.5236e-04,  5.1555e-03,  7.8529e-03,  7.1506e-04,\n",
       "                       -3.9235e-03,  7.6157e-03,  1.3752e-03,  2.1681e-03,  1.1121e-02,\n",
       "                       -5.9832e-03, -1.8757e-03,  1.4072e-03,  9.5683e-04, -4.4668e-04,\n",
       "                        2.7514e-04,  2.0078e-03, -9.9652e-03, -5.8585e-03, -7.0653e-04,\n",
       "                       -8.4902e-04, -9.9595e-03,  2.0156e-03,  9.3358e-04, -3.9060e-03,\n",
       "                        7.7206e-03, -2.8913e-03,  8.4928e-04,  2.3638e-03,  7.5988e-03,\n",
       "                       -6.3682e-03,  7.5612e-03,  4.1544e-03,  9.2287e-03,  6.5381e-04,\n",
       "                        9.9380e-04,  1.3222e-03,  6.6796e-03, -4.6254e-04, -4.8872e-03,\n",
       "                       -7.0143e-03, -4.4022e-03, -1.2657e-03, -6.3372e-03,  3.8607e-03,\n",
       "                        1.1186e-02, -2.5368e-03, -1.9700e-03,  3.8946e-03,  1.2470e-03,\n",
       "                       -9.9015e-04,  1.9315e-03, -1.0634e-03,  7.4478e-04,  3.2439e-03,\n",
       "                        8.8119e-03,  8.1036e-03, -1.0967e-04,  2.5916e-03,  1.7596e-03,\n",
       "                       -1.3679e-04,  1.3824e-02, -5.8212e-03, -9.6620e-03,  4.2263e-03,\n",
       "                       -1.1879e-02, -6.3389e-04,  3.6726e-03, -4.1981e-03, -5.8793e-03,\n",
       "                        1.1326e-02,  9.9308e-03, -1.6617e-04, -4.8374e-03, -1.2257e-02,\n",
       "                        2.5781e-04,  5.3209e-04,  6.7046e-03,  1.5836e-02, -7.1964e-03,\n",
       "                       -3.5818e-03, -3.9704e-03, -9.9113e-03,  9.7949e-03, -1.3626e-03,\n",
       "                       -8.5943e-03, -7.5695e-03,  1.0489e-02, -3.6452e-03,  4.1096e-03,\n",
       "                        4.2750e-03, -8.6990e-03, -4.1592e-03,  3.7734e-03,  4.1457e-03,\n",
       "                        1.1652e-02,  1.4227e-02,  1.3889e-02,  6.9166e-03, -9.7092e-03,\n",
       "                        1.1556e-03,  8.2060e-03, -6.9860e-04,  2.9605e-04,  2.4126e-03,\n",
       "                       -1.2607e-02, -5.7014e-03,  4.7486e-03, -3.9963e-03,  6.5910e-03,\n",
       "                       -1.1607e-02,  1.2322e-02,  1.4683e-02, -1.7255e-03,  3.5384e-03,\n",
       "                       -3.3416e-03,  2.4633e-03, -6.2664e-03,  1.9460e-03,  1.4878e-02,\n",
       "                       -2.2585e-05,  6.2450e-03, -9.1837e-03,  4.4619e-04,  2.1523e-02,\n",
       "                        1.4914e-03, -1.7839e-02,  8.4478e-03, -9.2885e-04,  5.0135e-03,\n",
       "                       -3.1707e-04, -5.1788e-03, -6.9182e-03,  7.5752e-04,  4.9057e-03,\n",
       "                       -6.5502e-03, -4.8577e-03, -8.4753e-03,  4.3702e-03, -3.6050e-03,\n",
       "                        8.6319e-04, -1.5573e-03,  3.4303e-03,  9.2326e-03,  8.7805e-03,\n",
       "                        5.7813e-03,  5.7091e-03,  5.2993e-03,  7.9645e-03,  2.4717e-03,\n",
       "                       -6.0006e-03, -7.0935e-03,  1.0845e-03, -1.4421e-02, -8.9486e-03,\n",
       "                       -1.3560e-02, -3.5392e-05, -1.1871e-03, -1.2589e-03,  5.2867e-03,\n",
       "                        1.0651e-02,  3.0651e-03, -1.3361e-02, -1.6384e-04,  8.9300e-03,\n",
       "                       -1.1479e-02, -9.0189e-03,  6.6767e-03,  8.2720e-03,  4.3210e-03,\n",
       "                       -5.4724e-03,  7.7015e-03, -6.1312e-03,  1.0052e-02,  1.4432e-02,\n",
       "                       -9.6508e-04, -7.3680e-03, -7.1556e-03,  7.4237e-03, -1.5654e-02,\n",
       "                       -6.1466e-03,  4.0499e-03,  2.4665e-02,  7.1965e-03,  2.8692e-03,\n",
       "                       -2.5356e-03,  6.9395e-03, -1.5613e-02,  5.4479e-03, -7.1528e-04,\n",
       "                        1.3228e-03, -1.7781e-03,  9.8486e-03,  1.2714e-02,  1.4754e-02,\n",
       "                        1.9750e-02, -1.4602e-02, -6.3869e-03,  2.2433e-03, -2.0966e-04,\n",
       "                        2.2333e-03, -1.6273e-02, -7.5586e-03,  1.8011e-02, -2.8290e-03,\n",
       "                       -2.7820e-03, -9.1349e-03, -9.3524e-03,  1.5011e-03,  1.2973e-02,\n",
       "                       -6.4693e-03,  2.9304e-03, -1.3272e-02, -3.8219e-03, -8.1454e-03,\n",
       "                       -3.3391e-03,  6.2451e-03, -9.8160e-04, -9.8788e-03,  3.0718e-03,\n",
       "                        9.2691e-03, -1.1389e-02, -7.2407e-03, -1.9077e-02, -5.8865e-03,\n",
       "                        1.8692e-02, -7.5648e-03, -1.1100e-02,  1.8199e-03,  1.0497e-02,\n",
       "                       -1.1606e-02,  4.9907e-03,  1.0986e-02,  1.2113e-02,  9.4093e-03,\n",
       "                        1.1371e-02, -6.7655e-03,  7.7619e-03,  2.3947e-03, -8.4728e-03,\n",
       "                       -4.9529e-03, -9.4978e-03,  4.4565e-04,  8.1296e-05, -2.9987e-03,\n",
       "                        9.0828e-03, -1.0738e-02,  7.1844e-03, -3.4612e-03, -1.2216e-02,\n",
       "                        2.1867e-02,  4.9720e-03,  3.3034e-04,  7.3230e-03, -3.8982e-03,\n",
       "                        1.4091e-03,  5.3736e-03,  6.1578e-03, -7.5757e-03, -1.3655e-02,\n",
       "                        7.0759e-03,  1.3300e-02,  7.0806e-03,  1.5275e-03, -1.0656e-02,\n",
       "                       -6.0037e-03,  1.6279e-02,  4.0725e-03,  7.1259e-03, -3.7905e-03,\n",
       "                        6.3891e-03,  6.4845e-03, -9.5286e-03, -8.4995e-03,  3.8379e-03,\n",
       "                        1.5589e-02, -5.3408e-03,  8.9202e-03,  1.1021e-02, -1.5899e-02,\n",
       "                       -1.6512e-02,  7.6159e-03,  8.9971e-03, -8.3832e-03,  8.6490e-03,\n",
       "                        1.6685e-02, -6.4043e-03,  3.3731e-03, -1.2638e-02, -2.5142e-02,\n",
       "                        2.7018e-03, -7.7597e-03,  1.9912e-03,  1.5650e-02,  1.4506e-02,\n",
       "                       -2.6467e-03, -4.2636e-04, -3.9830e-03,  1.4717e-02, -1.8170e-03,\n",
       "                        9.0811e-04,  6.6985e-03, -9.8350e-03,  1.3582e-02])),\n",
       "              ('net.models.1.interactions.5.interatomic_context_net.0.weight',\n",
       "               tensor([[-0.0965,  0.0863, -0.0215,  ..., -0.0773,  0.0264,  0.1070],\n",
       "                       [-0.1233, -0.0134,  0.0730,  ..., -0.0723,  0.1263,  0.0543],\n",
       "                       [ 0.1497,  0.1218,  0.0897,  ..., -0.0469, -0.0647, -0.1413],\n",
       "                       ...,\n",
       "                       [ 0.1194, -0.0703,  0.0245,  ...,  0.0628,  0.1220, -0.0727],\n",
       "                       [-0.0870,  0.0644,  0.1161,  ...,  0.0450, -0.0243,  0.0143],\n",
       "                       [ 0.0489,  0.0966,  0.1164,  ..., -0.1297,  0.0807, -0.1420]])),\n",
       "              ('net.models.1.interactions.5.interatomic_context_net.0.bias',\n",
       "               tensor([ 6.8922e-04, -3.5721e-03,  2.4967e-03, -1.9601e-03, -3.7040e-03,\n",
       "                       -2.3152e-03, -5.4039e-03, -3.1890e-03, -3.3493e-03,  6.7445e-04,\n",
       "                       -1.4973e-03,  4.3115e-04, -6.9197e-03, -1.0936e-03, -8.6487e-03,\n",
       "                       -1.1201e-03,  5.2521e-03, -2.2227e-03, -3.5208e-04, -3.9570e-03,\n",
       "                        9.2852e-04, -8.7580e-03, -4.4474e-03, -5.1070e-03, -3.2047e-03,\n",
       "                       -5.2213e-04,  6.4312e-03, -1.8668e-03,  3.8183e-03, -4.1011e-03,\n",
       "                        4.3948e-03,  1.8911e-03, -2.8098e-03, -1.0902e-02, -1.3468e-02,\n",
       "                       -1.8600e-04, -1.3399e-02,  1.1166e-03, -3.2921e-03, -2.3865e-03,\n",
       "                       -5.2371e-03, -2.6837e-03, -3.6525e-03, -2.3272e-03, -2.3177e-03,\n",
       "                       -4.8751e-03,  1.2965e-03,  1.9459e-03, -2.0824e-03, -1.3826e-02,\n",
       "                       -8.6223e-04,  3.1913e-03, -1.5250e-02, -8.4779e-03, -9.7999e-03,\n",
       "                       -8.3248e-03, -4.3907e-03, -2.2139e-03, -1.4071e-03, -2.8228e-03,\n",
       "                       -6.9501e-03, -1.8799e-03, -9.4597e-03,  1.5772e-03, -6.9953e-03,\n",
       "                        3.3755e-03, -3.3822e-03, -9.0918e-03,  4.1231e-03, -8.2549e-03,\n",
       "                        3.4349e-03,  1.2685e-03, -4.2227e-03,  7.6565e-04,  1.8164e-03,\n",
       "                       -4.4161e-03, -1.2061e-02, -5.4701e-03, -3.4274e-03,  2.8332e-03,\n",
       "                       -7.0721e-03, -1.4475e-03, -6.6239e-05,  4.9018e-04, -5.4403e-03,\n",
       "                       -3.0875e-03, -5.6167e-03, -2.8195e-03, -3.0711e-03, -1.0169e-02,\n",
       "                       -2.1381e-03,  3.5535e-03,  4.5858e-04, -6.5095e-03, -7.9230e-03,\n",
       "                       -1.3073e-03,  4.5972e-03, -1.0266e-03, -4.6766e-03, -4.4147e-03,\n",
       "                       -9.5501e-03,  2.2231e-03, -1.5913e-03,  6.9375e-03,  3.1100e-03,\n",
       "                        1.2210e-03,  2.2762e-03,  1.2309e-03, -8.2788e-03,  7.6107e-03,\n",
       "                       -7.8178e-03,  1.1162e-02, -7.6808e-03,  6.0172e-03, -1.4780e-03,\n",
       "                       -3.2789e-03, -7.0102e-03, -5.2828e-03, -1.8701e-03, -1.0337e-03,\n",
       "                        1.1918e-03,  4.6976e-04,  2.1689e-03, -3.1782e-03, -1.9208e-03,\n",
       "                        4.0610e-03, -5.9896e-04,  7.7669e-04])),\n",
       "              ('net.models.1.interactions.5.interatomic_context_net.1.weight',\n",
       "               tensor([[-0.0976,  0.0225, -0.0280,  ...,  0.0741,  0.0667, -0.0847],\n",
       "                       [ 0.0829,  0.0486,  0.0762,  ..., -0.0616,  0.0209, -0.0979],\n",
       "                       [-0.0972, -0.0007, -0.0062,  ..., -0.0960, -0.0952,  0.0680],\n",
       "                       ...,\n",
       "                       [ 0.0048,  0.0912,  0.0725,  ..., -0.0603, -0.0753,  0.1113],\n",
       "                       [-0.0320,  0.0432, -0.0365,  ..., -0.1093, -0.0823, -0.0081],\n",
       "                       [ 0.0072,  0.0425,  0.0461,  ...,  0.0500, -0.1049,  0.0504]])),\n",
       "              ('net.models.1.interactions.5.interatomic_context_net.1.bias',\n",
       "               tensor([-4.5293e-03,  5.7566e-03,  1.3374e-03,  4.1489e-04,  1.7360e-03,\n",
       "                       -6.4568e-03, -4.9165e-03, -9.0749e-04, -4.2447e-03, -2.1039e-03,\n",
       "                       -6.5836e-04, -1.9911e-04,  1.3791e-05, -6.0644e-03, -1.2871e-03,\n",
       "                        3.8981e-03, -9.0290e-04,  1.1362e-03, -3.7024e-03, -3.1652e-03,\n",
       "                       -3.6485e-03,  2.3847e-03,  8.7383e-04, -5.4660e-03, -1.9074e-03,\n",
       "                        1.3002e-02,  1.1378e-03, -9.9876e-04,  2.6122e-03, -4.9938e-04,\n",
       "                        6.0325e-04,  1.0494e-04,  8.4141e-04,  2.6798e-03, -3.9725e-03,\n",
       "                       -8.3149e-03,  1.6915e-03, -8.1639e-03,  3.2224e-04, -4.8712e-03,\n",
       "                        7.6963e-04, -1.3724e-03, -1.3263e-02,  4.4437e-04, -9.0181e-05,\n",
       "                        2.1236e-03, -2.2340e-03, -6.4491e-03,  2.5217e-03, -3.4020e-03,\n",
       "                       -4.9619e-03,  1.8755e-03, -3.0399e-03, -6.2689e-03,  1.1768e-03,\n",
       "                        2.3291e-03,  1.4441e-03, -5.8365e-03,  1.7304e-03, -1.2026e-03,\n",
       "                       -2.1759e-03, -2.5372e-03,  3.0209e-04, -1.0160e-03,  3.3434e-03,\n",
       "                       -3.2136e-03,  4.9101e-03, -4.7571e-03, -1.6696e-03,  1.6443e-03,\n",
       "                        3.8906e-04,  1.3387e-03,  6.5417e-04,  2.5717e-04,  1.1122e-03,\n",
       "                        1.1931e-02,  5.4854e-03, -8.9997e-03,  2.3756e-04,  3.8388e-03,\n",
       "                        5.8294e-04,  1.9851e-03, -1.0893e-03,  1.6471e-02,  1.0534e-03,\n",
       "                        1.0115e-03, -1.1399e-02,  7.7624e-03, -1.4535e-03,  7.1994e-04,\n",
       "                        2.9859e-03,  9.5810e-03,  3.0900e-05,  6.4550e-03,  8.1680e-04,\n",
       "                        1.2059e-03, -1.4272e-03,  5.0945e-03, -3.7530e-03, -3.1491e-03,\n",
       "                        8.2209e-03,  1.7819e-02,  3.3244e-03,  9.3010e-04, -6.0305e-03,\n",
       "                        2.0362e-03,  3.4139e-03, -2.2438e-03, -3.5009e-04, -2.9444e-03,\n",
       "                       -2.5363e-03, -2.4702e-04,  4.8346e-03, -3.7554e-03, -4.8491e-03,\n",
       "                       -4.5114e-03, -3.5478e-03, -1.8328e-03, -4.6486e-03,  2.6207e-03,\n",
       "                       -6.8948e-03,  2.2444e-03,  6.7777e-03,  1.6106e-03,  5.8194e-03,\n",
       "                       -1.9220e-03,  3.2553e-03, -5.5632e-03,  4.7003e-03,  8.8285e-03,\n",
       "                       -6.2429e-03,  4.4505e-03, -7.0648e-04, -1.1376e-02,  6.2520e-03,\n",
       "                        4.4457e-03, -3.9524e-03, -7.5565e-03,  1.8398e-03, -2.9253e-03,\n",
       "                       -1.5500e-03, -3.8454e-04, -4.7603e-03,  6.2571e-03, -2.8795e-03,\n",
       "                        1.0365e-03,  4.5626e-03,  7.1372e-03, -3.0390e-03, -8.3176e-03,\n",
       "                       -9.5712e-03, -2.8680e-03, -4.7127e-03,  2.1079e-03, -5.6565e-03,\n",
       "                        2.1897e-03, -5.0046e-03, -4.8038e-03,  4.3684e-03, -9.6821e-03,\n",
       "                       -2.7562e-03,  6.4439e-03, -9.5240e-03,  5.8954e-03, -8.1431e-03,\n",
       "                        3.8445e-03, -1.9503e-03, -5.1506e-04,  1.2687e-02,  4.8630e-03,\n",
       "                       -7.4751e-03,  3.2974e-03, -2.0444e-03, -5.4372e-03,  1.3918e-03,\n",
       "                       -4.8137e-03,  5.9327e-03, -5.8019e-03,  2.8267e-03,  6.5568e-03,\n",
       "                        3.7888e-03,  1.7092e-03, -5.1919e-03, -9.7739e-03, -1.1923e-03,\n",
       "                        3.7328e-03, -4.3112e-03, -4.4868e-03, -6.7687e-03, -6.9080e-03,\n",
       "                        6.5919e-03,  2.4726e-03,  3.8796e-03,  8.2772e-03, -7.2060e-03,\n",
       "                       -5.2721e-04, -1.0782e-02,  4.1857e-03,  3.1139e-03, -1.3935e-02,\n",
       "                        4.4598e-03,  2.0408e-03,  3.8746e-03, -6.3937e-03, -3.4496e-03,\n",
       "                        4.7228e-03,  2.7838e-03,  2.6126e-03,  5.8501e-03, -3.8665e-04,\n",
       "                        7.9563e-03,  6.2481e-03, -6.5882e-03, -8.3111e-03, -9.0054e-03,\n",
       "                       -8.6712e-03,  5.0977e-03, -3.5087e-03, -3.2782e-04,  2.5028e-03,\n",
       "                       -1.3857e-02,  9.0193e-04, -1.2175e-02,  3.1343e-03, -1.7623e-03,\n",
       "                       -8.0411e-03,  1.2549e-03,  1.0169e-03, -2.6748e-03, -2.7214e-03,\n",
       "                       -4.3818e-04, -5.3153e-03,  4.5020e-03, -5.9684e-03, -3.3007e-03,\n",
       "                        4.0379e-03,  2.2413e-03,  8.4011e-04,  2.7509e-03, -7.5227e-03,\n",
       "                       -1.4662e-02, -3.8393e-03, -1.1466e-02, -4.9554e-03, -3.0180e-04,\n",
       "                       -6.6598e-04, -7.0753e-03, -4.5495e-04,  5.3766e-03,  1.2284e-02,\n",
       "                       -3.8878e-03, -1.2991e-02, -6.0308e-03,  1.6227e-03,  4.2034e-03,\n",
       "                        3.6170e-04, -2.3439e-03, -3.1637e-03,  1.2897e-02, -7.9088e-03,\n",
       "                        9.0892e-03, -9.7307e-03, -7.4666e-04, -7.6899e-03, -9.6098e-03,\n",
       "                       -8.5862e-03,  6.7993e-03,  2.1086e-03, -2.3440e-04,  9.4174e-03,\n",
       "                       -8.5284e-03,  1.2190e-02,  2.0547e-03,  2.4517e-03,  5.3705e-03,\n",
       "                       -5.8970e-03, -1.3214e-02, -1.7060e-03,  9.1467e-03, -2.8282e-03,\n",
       "                       -1.3637e-03, -1.2524e-03, -4.9516e-03,  9.2288e-03,  1.4686e-02,\n",
       "                        3.9815e-03,  1.2960e-02,  3.4903e-03,  7.3504e-03,  5.3023e-03,\n",
       "                        9.9528e-03, -5.4497e-03, -1.5424e-03,  2.2060e-03, -2.1758e-03,\n",
       "                        6.9511e-03,  6.7429e-04, -1.1205e-03,  4.0790e-03, -1.9026e-03,\n",
       "                        4.9792e-03, -2.1366e-02, -4.1371e-03, -6.0565e-03, -7.7652e-03,\n",
       "                       -3.0713e-03,  2.4943e-03,  1.4374e-03, -8.1428e-04,  3.1839e-07,\n",
       "                        1.9793e-02,  1.4720e-02, -1.1623e-02,  4.0145e-03,  5.5947e-03,\n",
       "                        1.0951e-02,  4.4841e-03, -1.0472e-02, -7.1459e-03,  1.5560e-02,\n",
       "                       -3.3747e-03,  1.1457e-02,  1.1218e-02,  2.4662e-04,  1.4638e-02,\n",
       "                       -1.2009e-02, -9.3806e-03, -7.8708e-03,  8.6018e-03, -9.4457e-03,\n",
       "                        1.2919e-02,  3.0303e-03, -6.4998e-03, -6.2563e-03,  9.8490e-03,\n",
       "                       -1.5522e-03, -1.2699e-02,  8.0971e-03, -1.3452e-02,  7.7927e-03,\n",
       "                        4.2267e-03,  1.5290e-02,  1.8990e-03, -2.8857e-03,  1.2034e-02,\n",
       "                        1.0878e-03, -6.4690e-03,  3.9851e-03, -1.5293e-02, -1.2580e-02,\n",
       "                       -1.5109e-02,  6.6699e-03,  9.0772e-03,  1.6975e-03,  1.4386e-02,\n",
       "                       -9.8680e-03, -5.9164e-03,  3.3192e-04,  1.4805e-02, -4.7405e-03,\n",
       "                        5.7413e-03,  6.8399e-04, -5.8970e-03, -1.0236e-02, -1.1509e-02,\n",
       "                       -1.8497e-02, -2.9833e-02,  1.6053e-03, -1.0708e-02, -6.2142e-05,\n",
       "                        5.4748e-03, -6.4435e-03, -1.5338e-02, -7.8631e-03,  5.4991e-03,\n",
       "                       -1.6718e-02, -5.9639e-04, -9.5185e-03,  4.3717e-04, -2.5362e-03,\n",
       "                        5.5192e-03,  3.4252e-04, -4.3567e-03, -3.9124e-03])),\n",
       "              ('net.models.1.mixing.0.intraatomic_context_net.0.weight',\n",
       "               tensor([[-0.0805,  0.0697, -0.0944,  ..., -0.0968,  0.0779,  0.0540],\n",
       "                       [ 0.1183, -0.1068, -0.0562,  ...,  0.0461,  0.0261, -0.0219],\n",
       "                       [ 0.0497, -0.0651,  0.0030,  ...,  0.1100,  0.0327, -0.0513],\n",
       "                       ...,\n",
       "                       [-0.1101,  0.0057, -0.1288,  ..., -0.0023, -0.0386, -0.0396],\n",
       "                       [ 0.0530,  0.1173,  0.0980,  ..., -0.0382,  0.1189, -0.1218],\n",
       "                       [ 0.0020,  0.0905,  0.1262,  ..., -0.0182,  0.0448,  0.0481]])),\n",
       "              ('net.models.1.mixing.0.intraatomic_context_net.0.bias',\n",
       "               tensor([ 3.2047e-03, -4.4908e-03, -8.0403e-04, -1.9299e-02, -6.7223e-03,\n",
       "                        4.2253e-04,  3.4650e-05, -7.5428e-03,  5.1087e-04,  3.5111e-03,\n",
       "                       -6.3943e-03, -5.6725e-03,  2.7259e-03, -2.6347e-03,  1.0927e-03,\n",
       "                       -1.3564e-02, -1.1478e-02, -3.1352e-03, -1.3876e-02,  6.3139e-03,\n",
       "                       -1.5533e-03, -1.1544e-02, -7.8486e-05,  2.3579e-03, -9.6860e-03,\n",
       "                       -4.2183e-03, -2.2984e-03,  5.5230e-03, -2.0157e-02, -2.0247e-03,\n",
       "                       -5.7817e-03,  1.3308e-03,  1.5777e-03,  1.8014e-03,  7.5619e-03,\n",
       "                       -1.1202e-02,  8.2529e-04, -8.7191e-04, -2.6738e-03, -1.7191e-02,\n",
       "                       -5.2808e-04,  1.0951e-03,  5.6451e-03, -6.9793e-03, -4.6224e-03,\n",
       "                       -4.8071e-03,  6.2093e-03,  1.3021e-02,  5.3770e-03, -5.4545e-03,\n",
       "                        4.9723e-04, -7.3607e-03, -7.1144e-03, -1.1591e-02, -5.0470e-03,\n",
       "                        1.4230e-03, -6.5608e-03,  3.0114e-03, -3.5351e-03,  9.7963e-03,\n",
       "                       -3.4041e-03, -8.7901e-03, -4.0585e-03, -2.9679e-03,  1.1461e-03,\n",
       "                       -2.9488e-03, -9.1774e-04, -1.1955e-02,  1.5418e-02,  4.2398e-03,\n",
       "                        3.8426e-03,  5.8859e-03, -4.4903e-03,  1.4501e-02, -1.1882e-02,\n",
       "                       -1.3253e-02,  8.9874e-04,  4.2878e-03,  5.9208e-03, -7.2879e-03,\n",
       "                       -9.4709e-03, -2.7482e-03,  6.4658e-03, -6.2666e-03,  6.6891e-03,\n",
       "                       -3.5152e-03, -1.9340e-02, -9.3158e-07, -8.9148e-03, -1.0410e-02,\n",
       "                        6.2136e-03, -1.0351e-02,  1.7318e-03, -2.8334e-03,  4.9089e-03,\n",
       "                       -1.5286e-03, -9.4438e-03, -7.8368e-03,  7.8649e-03, -9.8175e-04,\n",
       "                       -2.4301e-03, -1.1162e-02,  4.9483e-03, -7.0018e-03,  6.7375e-04,\n",
       "                        3.7301e-03, -1.0693e-02,  1.0173e-02,  5.5894e-03, -2.4508e-03,\n",
       "                       -3.6449e-03,  1.6680e-03, -4.9683e-04,  8.0457e-04, -7.6134e-03,\n",
       "                        4.6884e-03,  1.9744e-04, -2.2791e-02,  7.4835e-03,  8.9893e-03,\n",
       "                       -5.6126e-03,  7.1112e-04, -3.0879e-03, -1.0374e-02, -3.9378e-03,\n",
       "                        1.0370e-02, -5.2970e-03, -5.6891e-03])),\n",
       "              ('net.models.1.mixing.0.intraatomic_context_net.1.weight',\n",
       "               tensor([[-0.0624, -0.0156,  0.0753,  ..., -0.0489, -0.0721, -0.0144],\n",
       "                       [-0.0761,  0.0131,  0.0122,  ..., -0.0101, -0.0984,  0.1048],\n",
       "                       [-0.0631,  0.0363,  0.0442,  ...,  0.0707, -0.0326,  0.0550],\n",
       "                       ...,\n",
       "                       [-0.0790,  0.0064, -0.0899,  ..., -0.0002,  0.0857,  0.0872],\n",
       "                       [ 0.0655,  0.0759,  0.0640,  ...,  0.0935, -0.0210,  0.0688],\n",
       "                       [ 0.0542,  0.0092, -0.0716,  ...,  0.0169,  0.0921,  0.0638]])),\n",
       "              ('net.models.1.mixing.0.intraatomic_context_net.1.bias',\n",
       "               tensor([-8.0013e-03,  2.0392e-03,  4.8956e-03, -1.4985e-03,  6.4705e-04,\n",
       "                        3.5882e-03, -1.2951e-02,  3.3136e-03, -5.5976e-03,  4.4423e-03,\n",
       "                        1.4490e-02, -7.2612e-03,  1.5174e-02,  1.6441e-03, -8.6392e-03,\n",
       "                        6.2513e-03, -1.0239e-02,  2.9313e-03,  2.5117e-03, -3.7948e-03,\n",
       "                        2.2855e-03, -5.2407e-03,  9.1691e-03,  1.5775e-02,  5.0696e-03,\n",
       "                        4.4167e-03, -5.9548e-03, -1.0521e-02, -1.0458e-02, -9.1018e-03,\n",
       "                        1.3461e-02,  5.6573e-03,  6.6652e-03,  1.3594e-02,  5.1662e-03,\n",
       "                       -9.7797e-03, -1.8731e-03,  4.6585e-03,  1.2405e-02, -4.5532e-03,\n",
       "                       -1.2876e-03, -1.3419e-03,  4.2255e-03, -4.8928e-03, -6.2929e-03,\n",
       "                       -5.3289e-03, -6.5658e-03, -7.7675e-03, -8.4154e-03,  1.4989e-02,\n",
       "                        5.2293e-03, -9.0031e-03,  2.0068e-03,  4.7876e-03, -7.4131e-03,\n",
       "                       -4.4090e-03, -4.5481e-03, -2.7976e-03, -1.0305e-02,  1.5341e-02,\n",
       "                        6.8427e-03, -8.2236e-03,  9.5139e-04, -1.0869e-02,  1.0306e-02,\n",
       "                        3.5915e-03,  1.6004e-02,  1.2826e-02, -6.1550e-03, -3.2838e-03,\n",
       "                       -1.3096e-03,  3.6270e-03,  4.2554e-03, -1.2238e-02,  2.3010e-03,\n",
       "                       -3.3392e-03, -2.1173e-03,  3.7508e-03,  1.4471e-02, -4.4852e-03,\n",
       "                        7.1163e-03,  2.9940e-03, -1.0754e-02,  1.0317e-02,  5.3554e-03,\n",
       "                        1.0171e-02, -1.1046e-02,  3.3149e-03,  1.8985e-04,  4.3701e-03,\n",
       "                       -3.3813e-03, -1.3744e-03,  9.0398e-03,  5.3085e-03, -2.2402e-03,\n",
       "                       -2.5590e-03,  2.0015e-05,  2.0431e-03, -6.3917e-03,  1.7901e-03,\n",
       "                        1.1776e-03, -1.8589e-03, -5.9852e-03, -1.1282e-02, -3.2172e-03,\n",
       "                       -4.9292e-04, -5.1608e-03, -5.4705e-04,  3.4479e-03, -9.1998e-05,\n",
       "                        3.8465e-03,  2.9645e-03, -2.4180e-03,  5.8883e-03, -6.1349e-03,\n",
       "                       -1.0577e-02,  7.8333e-03, -3.1786e-03, -2.7418e-03,  4.0419e-03,\n",
       "                        5.0406e-03, -1.2947e-02, -8.0445e-03,  4.0482e-03, -4.3101e-03,\n",
       "                        1.2731e-02,  7.4541e-03, -5.1590e-04,  1.7935e-03,  1.4586e-02,\n",
       "                        8.9007e-03, -3.3967e-03, -1.1255e-03,  7.4295e-04,  9.6096e-03,\n",
       "                        1.0293e-03, -8.0532e-03, -4.7479e-04, -5.8493e-03, -3.7983e-03,\n",
       "                       -1.0040e-02,  1.0082e-03, -1.0644e-02,  4.5633e-03, -9.5639e-04,\n",
       "                        2.9369e-03, -7.7393e-04,  6.5043e-03,  6.1080e-03, -9.0654e-03,\n",
       "                       -6.7473e-04,  1.1346e-02, -4.1524e-03, -2.7009e-03,  5.0262e-03,\n",
       "                        5.0840e-03, -5.4609e-03,  1.0487e-03, -1.2564e-03,  7.0948e-03,\n",
       "                       -2.0268e-03, -3.1565e-03,  1.0885e-02,  4.0660e-03,  6.9276e-03,\n",
       "                        1.7156e-03, -1.4896e-02,  8.2711e-03,  1.2844e-02,  1.1708e-02,\n",
       "                       -1.0271e-02, -5.5927e-03, -7.1664e-03,  3.7870e-03, -3.4040e-03,\n",
       "                       -1.1015e-02, -5.0986e-03,  7.6998e-03,  3.5816e-03,  5.6621e-04,\n",
       "                        4.0391e-03, -1.2185e-03, -8.4162e-03,  6.9944e-03,  8.7180e-03,\n",
       "                        4.2722e-03, -2.7976e-03,  1.1851e-02,  1.2264e-02,  8.0763e-03,\n",
       "                        7.9834e-03,  6.6614e-03, -1.1298e-02,  2.9524e-03,  4.8208e-04,\n",
       "                        1.3680e-03,  4.0949e-03, -7.9171e-04,  5.7018e-03,  8.9653e-03,\n",
       "                       -2.0197e-03,  5.2645e-03,  2.5590e-04, -1.2882e-03, -5.9294e-03,\n",
       "                       -3.3113e-04, -2.3733e-03, -5.7979e-03, -1.7171e-03,  4.5142e-03,\n",
       "                       -5.2949e-03,  8.9962e-03,  2.2787e-03, -2.6802e-03, -1.6551e-03,\n",
       "                       -3.7225e-03,  3.1171e-03,  9.0206e-03, -6.1773e-03,  1.0073e-03,\n",
       "                        3.2616e-03, -6.2308e-03,  3.3570e-03, -4.3438e-03,  1.5956e-03,\n",
       "                        8.6312e-03,  2.4677e-04, -2.2939e-04,  6.5857e-03,  2.3649e-03,\n",
       "                       -7.4859e-03, -3.8956e-03,  7.1216e-03, -6.4375e-05,  7.1693e-04,\n",
       "                       -3.9726e-04,  2.0671e-02,  3.3151e-03,  4.4440e-03, -4.9357e-05,\n",
       "                       -5.7505e-04,  7.2243e-03, -7.9936e-03, -6.3228e-04,  1.1275e-04,\n",
       "                        5.2313e-03, -9.9358e-03,  2.7080e-03,  2.2948e-03, -2.7699e-03,\n",
       "                        1.1534e-03,  2.7405e-03, -1.0353e-02, -8.2805e-03, -1.2811e-03,\n",
       "                        8.2632e-03, -2.8856e-03, -5.0115e-03, -2.9041e-03,  7.2318e-03,\n",
       "                       -6.5791e-03, -5.2548e-03, -1.8538e-03, -9.4830e-03,  8.0835e-03,\n",
       "                       -6.6144e-03, -1.6254e-02, -9.1875e-03,  9.7743e-03,  1.0678e-02,\n",
       "                        3.3316e-03, -9.4316e-03, -1.1695e-03,  5.1399e-03, -7.7981e-04,\n",
       "                        4.9347e-03, -2.5048e-03,  2.7281e-03, -8.6662e-03,  8.8064e-03,\n",
       "                       -6.2676e-04,  3.0462e-04,  5.0706e-03,  1.0347e-02,  2.2328e-02,\n",
       "                       -1.8036e-03,  7.2070e-04, -3.3298e-03,  2.9031e-03,  1.0576e-02,\n",
       "                        1.6161e-03, -1.4083e-02, -4.8606e-03, -3.0305e-03,  2.2899e-03,\n",
       "                       -5.6126e-03,  3.1748e-04, -2.5529e-03, -4.8239e-04,  4.4497e-03,\n",
       "                       -1.4449e-03,  3.9174e-03, -3.0371e-03, -4.3213e-03, -1.0449e-02,\n",
       "                       -2.8985e-03, -4.3701e-03,  1.3596e-02,  4.3000e-03, -2.6186e-03,\n",
       "                       -3.3636e-03, -9.7500e-03, -3.6346e-03, -1.2205e-04, -3.3948e-03,\n",
       "                       -1.5482e-02,  2.6051e-04,  5.4979e-03,  2.6752e-03, -9.2109e-04,\n",
       "                        5.8324e-03, -3.7838e-03,  3.7328e-03, -2.1060e-02,  1.7704e-03,\n",
       "                        3.2107e-03,  5.7526e-03, -3.1338e-03,  1.0353e-02,  1.1582e-02,\n",
       "                       -1.2675e-02, -2.9570e-03, -2.0722e-03,  8.3537e-03,  1.4682e-02,\n",
       "                        1.4005e-02, -5.0051e-03,  7.2671e-03,  8.5058e-03, -6.3960e-03,\n",
       "                        3.4827e-03,  9.2207e-03, -1.1824e-02,  5.1514e-03,  8.0816e-04,\n",
       "                       -5.9805e-03,  6.5112e-03,  3.0296e-03, -3.3991e-03,  1.1485e-02,\n",
       "                       -1.0093e-02, -6.6501e-03, -7.4176e-03, -1.0314e-02, -6.8511e-03,\n",
       "                       -2.1796e-03,  5.9456e-03, -1.0219e-02, -5.3377e-04, -1.0465e-02,\n",
       "                        8.6201e-03,  9.3521e-04,  5.1839e-03, -5.2170e-03, -7.2289e-03,\n",
       "                        3.6437e-03,  1.7168e-03,  2.6594e-03,  6.7027e-04,  7.4536e-04,\n",
       "                        3.4918e-03,  9.4670e-03,  1.5441e-03,  3.3354e-03, -5.3563e-03,\n",
       "                        4.1207e-03,  7.7860e-03,  4.6458e-03, -3.9113e-03, -1.0318e-02,\n",
       "                       -9.6613e-03,  3.5445e-03,  7.8492e-03,  6.5217e-03])),\n",
       "              ('net.models.1.mixing.0.mu_channel_mix.weight',\n",
       "               tensor([[-0.0292, -0.0705,  0.0998,  ..., -0.1242,  0.0265,  0.1131],\n",
       "                       [ 0.0454, -0.0089, -0.0684,  ..., -0.0759, -0.0939,  0.0090],\n",
       "                       [ 0.0108, -0.0383, -0.0739,  ..., -0.0265, -0.1195, -0.0403],\n",
       "                       ...,\n",
       "                       [ 0.0385, -0.0462,  0.0647,  ..., -0.0822, -0.0040,  0.1073],\n",
       "                       [ 0.0812, -0.0714,  0.1120,  ...,  0.0812, -0.1503,  0.0978],\n",
       "                       [-0.0893, -0.0353,  0.1108,  ..., -0.0353,  0.0524,  0.0764]])),\n",
       "              ('net.models.1.mixing.1.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0799,  0.0159,  0.0070,  ...,  0.0936,  0.0324,  0.1039],\n",
       "                       [-0.1263,  0.0434, -0.0967,  ..., -0.1235, -0.0278, -0.0090],\n",
       "                       [ 0.0887, -0.0393, -0.1195,  ..., -0.0340, -0.0089, -0.0669],\n",
       "                       ...,\n",
       "                       [ 0.0366,  0.0567,  0.0942,  ..., -0.1041, -0.0170,  0.0042],\n",
       "                       [-0.0526,  0.1085,  0.0017,  ..., -0.1214,  0.0175, -0.1195],\n",
       "                       [ 0.1145,  0.0471,  0.0475,  ..., -0.0807, -0.0898, -0.1175]])),\n",
       "              ('net.models.1.mixing.1.intraatomic_context_net.0.bias',\n",
       "               tensor([-6.7043e-05, -1.2425e-02, -1.5307e-03, -3.6803e-03,  3.1475e-03,\n",
       "                       -9.9252e-03,  2.2033e-03, -4.3591e-03, -3.5538e-03,  5.2028e-03,\n",
       "                        1.1611e-03, -3.2671e-03,  1.5813e-03, -2.8406e-03,  2.3772e-03,\n",
       "                        1.8672e-03,  1.8838e-03, -5.3095e-03,  7.4749e-04, -8.7097e-03,\n",
       "                       -5.2657e-03, -5.2194e-03, -7.0127e-03,  8.9404e-03,  6.6607e-03,\n",
       "                        9.0690e-04, -3.9543e-03,  1.8456e-03,  1.6684e-03, -1.5209e-02,\n",
       "                        7.7599e-03, -1.1400e-02, -2.2722e-04, -3.9638e-03, -1.2021e-03,\n",
       "                        2.2787e-03, -5.4104e-04, -5.7124e-03,  5.6205e-03, -1.1007e-02,\n",
       "                       -5.6239e-03, -6.2984e-03, -6.0343e-03,  5.4111e-03, -1.1212e-02,\n",
       "                       -1.2176e-02, -3.5240e-03,  8.2222e-03, -1.0014e-02, -4.9016e-03,\n",
       "                       -7.1652e-03, -1.3728e-02,  1.8793e-03, -6.9328e-03, -6.3615e-05,\n",
       "                       -8.0123e-04, -3.0311e-03, -9.3369e-03,  2.7416e-03,  2.1807e-03,\n",
       "                        9.2715e-05, -6.9611e-04,  4.1269e-03,  3.5454e-03, -1.3666e-02,\n",
       "                       -2.0057e-03, -5.3896e-03, -2.5325e-03,  3.7300e-03, -4.0511e-03,\n",
       "                       -4.5462e-03,  3.0755e-03, -7.9790e-03,  3.7193e-04,  2.8455e-03,\n",
       "                       -6.6388e-03,  3.4398e-03, -1.0783e-03,  2.3102e-03,  3.4481e-03,\n",
       "                        3.2457e-03, -4.3565e-03,  3.0227e-04,  3.1139e-03,  2.0672e-03,\n",
       "                       -6.7200e-03,  7.7496e-04, -7.8879e-03, -5.8765e-04,  1.3877e-02,\n",
       "                       -3.0133e-03, -5.0536e-03,  1.6918e-03,  1.0331e-03,  6.6371e-03,\n",
       "                        1.1856e-03, -6.6381e-03, -1.1874e-04, -6.0130e-03, -3.5409e-03,\n",
       "                        1.1983e-03,  1.2271e-03,  8.3603e-03,  8.7201e-03, -8.4479e-05,\n",
       "                       -2.7285e-03,  8.0234e-04, -3.2988e-03,  1.0398e-02,  4.4939e-03,\n",
       "                       -1.3131e-03, -5.0765e-03, -9.9484e-03,  1.4285e-03, -2.6850e-03,\n",
       "                       -3.1789e-03,  7.0783e-03, -9.9792e-03,  2.1048e-03,  3.9403e-03,\n",
       "                        7.6129e-04, -4.0331e-03,  5.3108e-03, -7.1835e-03, -6.1930e-03,\n",
       "                       -3.4416e-03, -3.5927e-03, -9.8165e-03])),\n",
       "              ('net.models.1.mixing.1.intraatomic_context_net.1.weight',\n",
       "               tensor([[-0.0290,  0.0528, -0.0233,  ..., -0.0242,  0.0082, -0.0521],\n",
       "                       [ 0.0932, -0.0026, -0.0690,  ...,  0.0847,  0.0792, -0.0241],\n",
       "                       [ 0.0831,  0.0385, -0.0337,  ...,  0.0793, -0.0523,  0.0648],\n",
       "                       ...,\n",
       "                       [-0.0837, -0.0723, -0.0996,  ..., -0.0721, -0.0417, -0.0955],\n",
       "                       [-0.0311,  0.0122, -0.0455,  ...,  0.0930, -0.0858,  0.0726],\n",
       "                       [ 0.0250,  0.0164, -0.0235,  ...,  0.0862, -0.0509,  0.0476]])),\n",
       "              ('net.models.1.mixing.1.intraatomic_context_net.1.bias',\n",
       "               tensor([-1.1621e-02,  4.2358e-03,  4.1050e-03,  1.2934e-03,  1.3664e-03,\n",
       "                        1.5813e-03, -9.7554e-03, -4.6095e-04,  7.3273e-04,  4.6032e-03,\n",
       "                        1.1872e-02, -6.9437e-03,  1.5263e-02,  2.1254e-03, -7.0553e-03,\n",
       "                        5.5553e-03, -9.4007e-03,  1.9006e-03, -1.1843e-04, -2.1099e-03,\n",
       "                       -3.0066e-03, -4.1511e-03,  4.6576e-03,  1.4864e-02,  6.7336e-03,\n",
       "                       -1.8654e-03, -4.3830e-03, -6.1658e-03, -4.7808e-03, -7.1258e-03,\n",
       "                        8.8650e-03,  6.4851e-03,  3.3826e-03,  8.8417e-03, -5.6316e-04,\n",
       "                       -6.5116e-03, -7.3266e-04,  6.8440e-03,  7.9116e-03, -9.5495e-03,\n",
       "                       -6.2992e-03, -1.6546e-03,  3.2765e-03, -3.8772e-03, -8.1459e-03,\n",
       "                       -2.3115e-03, -5.7185e-03, -6.3214e-03, -6.9384e-03,  1.3597e-02,\n",
       "                        5.9453e-03, -6.3244e-03,  1.9414e-03,  2.6237e-03, -3.9145e-03,\n",
       "                       -3.8540e-03, -3.3296e-03, -5.9945e-05, -1.0050e-02,  9.4287e-03,\n",
       "                        5.6756e-03, -5.0894e-03,  5.7642e-04, -3.2544e-03,  1.0533e-02,\n",
       "                        4.2415e-03,  1.0117e-02,  1.0597e-02, -4.9065e-03, -4.1274e-03,\n",
       "                       -2.3677e-04,  5.8336e-03,  2.7123e-03, -9.9387e-03,  2.9578e-03,\n",
       "                       -3.9916e-03,  2.0053e-04, -3.1365e-03,  6.5423e-03, -3.4116e-03,\n",
       "                        4.2292e-03,  1.3014e-03, -9.7837e-03,  6.3696e-03,  5.7303e-03,\n",
       "                        1.0107e-02, -7.1963e-03,  2.6355e-03,  1.7043e-03,  1.8818e-03,\n",
       "                       -4.9502e-03,  7.3091e-05,  8.1586e-03,  3.9671e-03,  1.1379e-03,\n",
       "                       -1.8012e-03,  3.5307e-03,  2.6707e-03, -6.0230e-03, -1.4892e-04,\n",
       "                        1.9135e-03, -2.4858e-03, -3.3379e-03, -9.5428e-03, -2.6152e-03,\n",
       "                        9.8814e-04, -3.6455e-03,  1.6695e-04,  3.1888e-03, -4.2993e-04,\n",
       "                        5.6346e-03,  1.4890e-03, -1.9609e-04,  3.6789e-03, -3.6076e-03,\n",
       "                       -6.8548e-03,  6.9532e-03,  5.8294e-04, -1.1008e-02,  3.9691e-03,\n",
       "                        3.2700e-03, -1.4970e-02, -8.2522e-03,  2.8489e-03, -2.8616e-03,\n",
       "                        9.4971e-03,  7.7934e-03,  1.3472e-03,  3.1705e-04, -8.6397e-03,\n",
       "                       -5.7197e-04,  1.3010e-02, -2.9700e-03,  4.7073e-03,  2.9668e-03,\n",
       "                       -2.2595e-05, -5.5035e-03, -8.0371e-03, -5.8462e-03, -4.5859e-03,\n",
       "                        5.1696e-03, -2.8751e-03, -6.7313e-03, -5.7598e-03,  4.0280e-03,\n",
       "                        2.4328e-03, -1.0780e-02, -2.5949e-04, -8.9087e-04,  4.3614e-03,\n",
       "                       -4.1044e-04,  2.5784e-03, -2.4636e-03,  9.6384e-03, -4.6797e-03,\n",
       "                       -9.9770e-03,  3.4943e-03, -1.0344e-03,  2.5184e-03,  5.7972e-03,\n",
       "                        7.6529e-03, -5.6692e-03, -6.7716e-05, -4.2671e-03,  1.2237e-02,\n",
       "                       -7.6921e-03, -8.0779e-04, -6.4058e-03,  2.2470e-03, -1.0547e-02,\n",
       "                        7.4027e-03, -5.1870e-03, -1.5157e-02,  7.8553e-03,  1.5846e-03,\n",
       "                       -8.0290e-03, -1.0169e-03,  6.2836e-05, -4.6118e-03, -8.6809e-03,\n",
       "                        9.8604e-03,  6.8199e-03, -2.5639e-03,  9.2332e-03, -4.9230e-03,\n",
       "                        6.4116e-03,  1.0423e-02, -1.6653e-02,  1.0702e-02,  7.2995e-03,\n",
       "                        9.8298e-03, -4.4733e-04, -9.5643e-03, -5.2507e-03,  2.6280e-03,\n",
       "                        9.5050e-03, -3.6410e-03, -7.3026e-03,  9.0355e-03, -1.4780e-02,\n",
       "                       -3.2515e-03,  7.2440e-03, -7.1885e-03, -2.3430e-03, -9.9039e-03,\n",
       "                       -3.5319e-03, -4.2569e-03,  7.8536e-03,  2.9643e-03, -2.9081e-03,\n",
       "                        1.8214e-02, -2.5997e-03,  2.5851e-03,  1.2871e-02, -7.9495e-03,\n",
       "                        1.9440e-04, -1.0560e-02, -2.6085e-04, -3.4399e-04,  1.2345e-02,\n",
       "                       -5.9530e-03,  1.9281e-03,  3.1758e-03, -6.0600e-03,  9.2177e-03,\n",
       "                        1.0560e-03, -4.5349e-03, -4.9869e-03, -6.1060e-03,  1.7504e-03,\n",
       "                        6.0934e-04, -1.5876e-03, -1.2595e-03,  1.5582e-02,  3.1606e-03,\n",
       "                       -1.7652e-03, -1.3267e-02, -3.4260e-03, -4.4520e-03, -4.7194e-03,\n",
       "                        2.5410e-03,  3.7716e-04, -1.8246e-03, -2.8485e-03,  8.1562e-03,\n",
       "                        4.0886e-03,  4.1641e-03,  7.0149e-03, -1.7036e-03, -1.5712e-02,\n",
       "                       -3.5682e-03, -4.8867e-03,  4.1681e-03,  8.7296e-03, -5.8588e-04,\n",
       "                       -6.8664e-03,  9.3611e-03,  2.0524e-03,  6.4971e-03, -1.4095e-02,\n",
       "                        1.8503e-03, -1.6340e-03, -1.5349e-02,  1.8677e-03, -2.3852e-02,\n",
       "                        1.3759e-02,  4.8692e-03,  1.1260e-02,  1.2206e-02, -1.6202e-03,\n",
       "                        4.7752e-03,  1.4526e-02, -2.3010e-03, -2.1296e-02,  2.2092e-03,\n",
       "                        5.4821e-03,  5.6815e-03,  7.9340e-03, -1.1327e-02,  8.3581e-03,\n",
       "                       -4.3380e-03,  3.8595e-03, -1.5763e-04, -2.9626e-03,  9.8096e-03,\n",
       "                       -6.4526e-04, -8.9129e-03, -6.2357e-03, -1.6900e-03, -1.6437e-03,\n",
       "                        7.8203e-03,  4.0090e-03, -5.0172e-03,  5.4038e-03,  9.8248e-03,\n",
       "                       -2.3220e-03,  5.9834e-03, -7.9537e-03, -7.3260e-03, -8.8895e-04,\n",
       "                       -1.1350e-03,  1.7341e-05, -2.4130e-03, -5.4397e-03,  4.9466e-04,\n",
       "                       -6.4638e-03, -5.9647e-03, -2.2160e-03,  8.6775e-03, -7.4888e-03,\n",
       "                        8.1773e-03, -4.0015e-03,  7.0511e-03,  6.5048e-03,  7.1803e-04,\n",
       "                       -8.2710e-03,  6.4019e-03, -1.8863e-02, -9.0297e-03, -2.5582e-03,\n",
       "                       -6.3772e-03,  1.6145e-03,  4.8241e-03,  4.8224e-04,  8.8244e-04,\n",
       "                        4.5513e-03,  4.0010e-03, -8.3454e-03,  7.6745e-04, -2.7499e-03,\n",
       "                        4.0866e-03, -1.5062e-02,  2.5855e-03,  1.0059e-02,  8.6508e-04,\n",
       "                        5.9372e-04, -7.3553e-03, -1.2643e-03, -6.2651e-03, -5.9838e-03,\n",
       "                        7.1944e-03,  1.1929e-02,  8.2099e-03, -1.2869e-03,  1.2671e-02,\n",
       "                       -7.6175e-03, -4.5528e-03, -6.5155e-03, -4.8561e-03, -8.6460e-03,\n",
       "                       -2.8184e-03, -3.0632e-03, -8.6700e-03, -8.4240e-04, -2.7378e-03,\n",
       "                       -4.2150e-03, -2.5992e-03,  9.9179e-03, -2.0361e-04, -5.7213e-03,\n",
       "                        2.5531e-03,  3.3202e-03, -1.6565e-03,  1.1596e-02, -9.5729e-03,\n",
       "                       -8.2272e-03, -4.4249e-03, -6.4804e-03,  1.9356e-03, -2.9235e-03,\n",
       "                        1.3732e-02, -6.7319e-04,  1.7700e-02, -1.4607e-03, -5.7673e-03,\n",
       "                        3.5664e-03, -7.2817e-05,  1.7146e-02,  2.8403e-03, -1.0004e-02,\n",
       "                        1.0397e-03, -1.5088e-02,  7.2044e-03,  1.8610e-03])),\n",
       "              ('net.models.1.mixing.1.mu_channel_mix.weight',\n",
       "               tensor([[ 0.0363,  0.0992,  0.0697,  ..., -0.0874, -0.0720, -0.0074],\n",
       "                       [-0.0699, -0.0306, -0.1028,  ..., -0.0172, -0.0210, -0.0454],\n",
       "                       [-0.0577, -0.0039,  0.0659,  ..., -0.0989,  0.0526,  0.0487],\n",
       "                       ...,\n",
       "                       [-0.0661, -0.1245, -0.0627,  ..., -0.0975, -0.0254, -0.1213],\n",
       "                       [ 0.0243,  0.0804, -0.1112,  ...,  0.0377,  0.0809, -0.0378],\n",
       "                       [-0.0501,  0.1162, -0.0194,  ...,  0.0349, -0.0493, -0.1318]])),\n",
       "              ('net.models.1.mixing.2.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0512, -0.0929,  0.0301,  ..., -0.0032,  0.0957,  0.0181],\n",
       "                       [ 0.0791, -0.0025,  0.1128,  ..., -0.1214,  0.0821, -0.0838],\n",
       "                       [ 0.0291, -0.0019,  0.0161,  ..., -0.0389, -0.0398, -0.0868],\n",
       "                       ...,\n",
       "                       [ 0.0765, -0.1085, -0.0618,  ..., -0.0073, -0.0869,  0.0965],\n",
       "                       [ 0.1050, -0.0646,  0.0075,  ...,  0.0361, -0.0339, -0.0970],\n",
       "                       [-0.0318, -0.0456, -0.0794,  ..., -0.0081, -0.0549,  0.1118]])),\n",
       "              ('net.models.1.mixing.2.intraatomic_context_net.0.bias',\n",
       "               tensor([-6.0688e-03, -8.6185e-03,  3.3404e-03, -1.9040e-03, -1.7196e-03,\n",
       "                       -1.1320e-03, -7.5027e-03,  6.3505e-03, -2.0927e-03, -4.6053e-03,\n",
       "                       -1.0048e-02,  2.2792e-03, -6.6891e-03, -3.0156e-03, -3.2590e-03,\n",
       "                       -8.3813e-03,  5.0096e-03,  6.0197e-03, -6.7994e-03, -9.1145e-04,\n",
       "                       -3.0027e-03, -1.1845e-04,  4.2340e-03, -1.2003e-02, -5.9443e-04,\n",
       "                        5.9438e-05, -6.7381e-03, -5.4559e-04, -9.7182e-03,  2.9241e-03,\n",
       "                       -5.8104e-03, -2.1267e-03, -3.8779e-03,  7.8741e-03,  4.3782e-04,\n",
       "                       -3.0922e-03,  2.2374e-03,  4.8869e-03, -4.8004e-03,  1.7841e-03,\n",
       "                       -6.0147e-03, -4.6621e-03, -8.3488e-05,  5.2003e-03,  5.1634e-03,\n",
       "                        1.3232e-03, -7.9629e-03, -9.9555e-04,  4.8467e-03, -2.4454e-03,\n",
       "                       -3.6912e-03, -7.9817e-03, -1.5248e-04,  4.1048e-04, -4.4818e-05,\n",
       "                       -6.2035e-03,  1.7041e-03, -5.2819e-03, -8.4631e-03, -4.2159e-03,\n",
       "                       -3.5763e-03, -9.2630e-03, -4.9823e-03,  2.3589e-03, -7.7023e-03,\n",
       "                        2.2913e-03,  7.7863e-03, -3.1207e-03, -1.2222e-03, -1.1522e-02,\n",
       "                       -8.4446e-03, -4.6216e-03,  1.3757e-04,  6.6301e-03, -9.3706e-03,\n",
       "                       -1.8757e-04,  8.2576e-03, -1.5322e-03,  5.4157e-04,  5.1237e-03,\n",
       "                        4.7560e-03,  2.4787e-03, -2.8174e-03, -5.6938e-03,  6.0549e-03,\n",
       "                       -8.0250e-03, -2.4898e-03, -2.4652e-03, -1.0993e-03, -2.1277e-04,\n",
       "                       -4.5628e-03, -2.5904e-03,  4.5990e-03, -5.5108e-03, -1.3596e-02,\n",
       "                       -6.5414e-03, -4.6682e-03, -6.3666e-03,  7.1030e-03, -1.0336e-03,\n",
       "                        3.3985e-03,  4.2727e-03, -8.9152e-03,  8.5900e-05,  4.1330e-03,\n",
       "                       -1.7259e-02,  3.0382e-03, -8.8227e-03,  9.5404e-03, -6.6983e-03,\n",
       "                        6.7729e-03,  8.2284e-03, -7.0873e-03, -4.7577e-03, -2.8010e-03,\n",
       "                       -4.8631e-03, -9.7702e-03,  6.7846e-04,  1.8096e-04,  6.0926e-04,\n",
       "                        2.5283e-04, -3.3873e-03, -8.0216e-03, -6.1256e-03,  4.6813e-03,\n",
       "                       -7.7669e-04, -1.2814e-02,  6.2680e-03])),\n",
       "              ('net.models.1.mixing.2.intraatomic_context_net.1.weight',\n",
       "               tensor([[-0.0424,  0.0202, -0.0209,  ...,  0.0338,  0.0956, -0.0502],\n",
       "                       [-0.0230, -0.0443,  0.0588,  ...,  0.0409,  0.0805,  0.0968],\n",
       "                       [ 0.0438,  0.0094, -0.0670,  ..., -0.0346,  0.0087, -0.0991],\n",
       "                       ...,\n",
       "                       [ 0.1073,  0.0975, -0.0653,  ...,  0.0733,  0.0350, -0.0087],\n",
       "                       [-0.0151,  0.0871,  0.0228,  ...,  0.0948, -0.0478,  0.0382],\n",
       "                       [ 0.0215, -0.0271, -0.0555,  ...,  0.1043,  0.0624,  0.0255]])),\n",
       "              ('net.models.1.mixing.2.intraatomic_context_net.1.bias',\n",
       "               tensor([-3.6938e-03,  3.8788e-03,  2.9605e-03,  6.6278e-04,  4.2466e-03,\n",
       "                        7.0335e-04, -1.0341e-02, -5.0277e-03,  1.0150e-03,  2.7593e-03,\n",
       "                        1.4517e-02, -4.0064e-03,  7.4273e-03,  6.0616e-04, -6.7460e-03,\n",
       "                        4.3683e-03, -6.1762e-03,  1.3498e-03, -2.4304e-03, -3.0644e-03,\n",
       "                        5.6572e-03, -3.5234e-03,  6.2809e-03,  1.1459e-02,  5.4413e-03,\n",
       "                       -4.0903e-03, -8.8023e-03, -5.5075e-03, -1.4700e-03, -3.8425e-03,\n",
       "                        8.2992e-03,  3.7413e-03,  1.2580e-03,  6.5111e-03, -5.7635e-04,\n",
       "                       -2.6279e-03, -1.8370e-04,  5.4003e-03,  3.2560e-03, -3.7970e-04,\n",
       "                       -2.4066e-03, -4.0511e-04,  9.8787e-04, -2.3704e-03, -4.3045e-03,\n",
       "                        9.1724e-04, -5.3808e-03, -5.8413e-03, -3.3926e-03,  9.7674e-03,\n",
       "                        4.0245e-03, -8.9410e-03,  1.7050e-03,  1.5783e-03, -4.6666e-03,\n",
       "                       -4.7417e-03, -2.9074e-03, -1.9641e-03, -9.9594e-03,  7.8600e-03,\n",
       "                        2.4688e-03, -3.3021e-03,  1.6527e-03, -2.1255e-03,  9.8581e-03,\n",
       "                        1.7956e-05,  7.0330e-03,  1.0484e-02, -4.2855e-03, -2.5126e-03,\n",
       "                        7.1801e-04,  5.6647e-03,  2.0223e-03, -7.4504e-03,  1.4022e-03,\n",
       "                       -1.9928e-03, -1.3651e-03, -1.2245e-03,  1.6110e-03, -3.1507e-03,\n",
       "                        7.1504e-03,  3.9686e-04, -5.2312e-03,  1.1463e-03,  2.0387e-03,\n",
       "                        8.5866e-03, -3.5340e-03,  1.4512e-03,  2.6409e-03,  6.0027e-04,\n",
       "                       -4.2870e-03, -2.7137e-04,  4.4760e-03,  3.0104e-03, -2.1405e-06,\n",
       "                       -1.7080e-03,  2.0104e-03,  1.5575e-03, -5.3268e-03, -5.1354e-03,\n",
       "                        1.5910e-03, -1.0440e-03, -3.5731e-03, -5.6878e-03,  1.4675e-03,\n",
       "                        1.1890e-03, -3.3439e-03, -9.9710e-04,  2.2425e-03, -1.3396e-03,\n",
       "                        5.6799e-03,  1.2356e-03,  1.0701e-03, -3.9689e-04, -6.7752e-03,\n",
       "                       -5.6864e-03,  1.1581e-02,  1.2939e-03, -1.0878e-03,  3.2088e-03,\n",
       "                        5.2748e-03, -1.2446e-02, -2.6421e-03,  1.1142e-03, -2.7572e-03,\n",
       "                        5.1317e-03,  8.3876e-03,  1.2700e-03,  5.4554e-03,  7.6429e-04,\n",
       "                       -7.6971e-03, -6.9563e-03,  4.2373e-04,  2.1597e-03,  7.1870e-03,\n",
       "                       -7.3303e-03,  4.0635e-03, -5.3209e-03, -2.8521e-03,  7.7654e-04,\n",
       "                       -8.4929e-03, -1.0006e-02, -4.5606e-03, -1.9003e-05, -1.9155e-03,\n",
       "                        1.5334e-03, -2.5223e-02, -5.9482e-03, -4.7754e-03, -2.8379e-03,\n",
       "                        5.3400e-03,  1.7915e-03, -9.5269e-03,  1.6650e-03, -1.0401e-03,\n",
       "                       -9.7556e-03, -1.1203e-02,  7.3117e-03, -2.4389e-03, -8.4706e-03,\n",
       "                       -4.8519e-03,  1.4762e-02, -1.3680e-02,  1.2322e-02,  7.7805e-03,\n",
       "                        1.0681e-02, -2.0316e-03, -5.2890e-03, -1.3205e-02, -4.8467e-03,\n",
       "                        2.3975e-03,  9.2611e-03, -1.2321e-03,  3.5141e-05,  6.3538e-03,\n",
       "                        3.0048e-03,  1.3717e-03, -5.5966e-03,  1.2895e-03,  5.7054e-04,\n",
       "                       -5.2237e-03,  3.7533e-03,  3.5672e-03, -1.0625e-02, -2.6497e-03,\n",
       "                        1.3038e-03, -6.8929e-03, -3.9489e-03,  1.2965e-02, -5.2228e-03,\n",
       "                       -1.1448e-02, -1.2736e-02, -2.3702e-03, -7.2430e-03, -1.1479e-02,\n",
       "                        3.6298e-03,  2.4207e-03,  3.2837e-03, -4.0092e-03, -5.8114e-03,\n",
       "                        4.9706e-03,  3.5528e-03, -2.2084e-03,  1.5554e-03, -3.8616e-03,\n",
       "                        2.3922e-03, -4.9855e-03, -1.2549e-02,  1.5993e-02, -8.9613e-04,\n",
       "                        1.9539e-03, -1.1283e-02, -6.7434e-03, -1.3424e-02,  5.7909e-03,\n",
       "                       -7.5492e-03,  6.7270e-03, -1.0687e-02, -1.1642e-02, -2.4127e-03,\n",
       "                       -1.1275e-02,  3.3796e-04,  4.7874e-03, -1.5731e-05, -1.0634e-02,\n",
       "                       -2.3028e-03,  3.8894e-03,  7.6717e-03, -9.2379e-03,  4.5991e-03,\n",
       "                        2.3064e-03, -3.0212e-03,  2.4995e-03, -6.2152e-04,  1.0631e-02,\n",
       "                        6.2098e-03,  1.2931e-03, -8.6313e-03,  5.8921e-03, -1.2896e-03,\n",
       "                        2.9014e-04, -2.1953e-03,  1.1926e-03,  4.6695e-03,  1.1699e-02,\n",
       "                       -1.5578e-02, -1.4552e-04, -5.9049e-03, -6.9448e-03,  3.9715e-03,\n",
       "                       -7.6856e-03,  2.1419e-03, -1.5482e-03, -1.4403e-03, -6.3869e-03,\n",
       "                        6.2934e-03, -5.4136e-03, -3.4664e-04, -1.8225e-04,  3.1152e-03,\n",
       "                        1.1979e-02,  3.7044e-03,  2.6991e-02,  3.3202e-03,  1.8156e-02,\n",
       "                       -6.3908e-03,  3.5756e-03, -1.0478e-02,  1.0969e-02, -6.8432e-03,\n",
       "                       -1.2020e-03, -5.7070e-03,  1.1469e-03, -5.1986e-05, -9.5438e-03,\n",
       "                       -2.4924e-04,  5.9988e-03,  4.4569e-03,  1.7855e-03, -4.7455e-03,\n",
       "                        3.4230e-03,  3.0320e-03,  1.3189e-02, -2.5958e-03,  8.0880e-03,\n",
       "                        1.1479e-02,  1.3127e-02,  8.6082e-03, -1.5341e-03,  1.1620e-02,\n",
       "                       -3.8435e-03,  6.1514e-03,  3.0864e-03, -1.3007e-02,  2.9731e-03,\n",
       "                        6.0637e-03, -3.8587e-03, -1.6281e-02, -7.9779e-03, -1.7851e-03,\n",
       "                       -5.3844e-03, -3.9501e-03, -3.9379e-03,  5.7419e-03,  4.5369e-03,\n",
       "                        1.2102e-02, -1.6825e-03,  8.9384e-03,  5.9078e-03,  8.7305e-03,\n",
       "                        1.7127e-02, -9.0555e-03,  9.9767e-03, -3.1047e-03,  8.2006e-03,\n",
       "                        3.4678e-03,  5.4046e-03,  1.0881e-03, -2.8523e-03, -5.8825e-03,\n",
       "                        1.8481e-03, -9.1107e-03, -6.1732e-03,  2.9882e-03, -3.0835e-03,\n",
       "                        1.0447e-02,  8.0985e-03, -3.8577e-03, -3.7217e-03, -6.3129e-03,\n",
       "                        2.0120e-03,  7.2643e-03,  5.8588e-03,  5.4722e-03,  4.3716e-03,\n",
       "                        1.8042e-02,  5.6509e-03,  5.8696e-03, -1.1197e-03, -3.0112e-03,\n",
       "                       -1.0477e-02,  2.0008e-03, -3.0202e-03,  8.6036e-03, -9.2782e-03,\n",
       "                       -9.9362e-03, -3.7128e-03,  1.2588e-04, -6.8504e-03,  2.6307e-03,\n",
       "                       -1.4973e-03, -4.0246e-03,  9.7380e-03,  8.4156e-03,  2.7957e-03,\n",
       "                        6.0283e-03,  3.8650e-03,  4.9623e-04,  2.7033e-03, -4.1260e-04,\n",
       "                        8.1020e-04, -3.1454e-03, -3.4631e-04,  4.0021e-04, -7.7690e-03,\n",
       "                        2.5753e-03,  5.2882e-03,  4.5644e-03,  9.1256e-03,  8.8244e-03,\n",
       "                        1.2461e-02,  5.1443e-03,  2.0824e-03,  2.4653e-03,  9.3534e-03,\n",
       "                       -5.7970e-03, -2.1022e-03, -1.2265e-02, -3.1538e-03, -1.3508e-03,\n",
       "                       -2.4524e-04, -2.7010e-03, -1.0022e-03,  2.1438e-03])),\n",
       "              ('net.models.1.mixing.2.mu_channel_mix.weight',\n",
       "               tensor([[ 0.0188, -0.0229,  0.0250,  ...,  0.1068,  0.1080, -0.0765],\n",
       "                       [-0.0846,  0.0684, -0.0783,  ..., -0.0751,  0.1183, -0.0400],\n",
       "                       [ 0.0198,  0.0055, -0.0175,  ..., -0.0288, -0.0463,  0.0968],\n",
       "                       ...,\n",
       "                       [ 0.0483,  0.1160,  0.0659,  ...,  0.0176,  0.1174,  0.0848],\n",
       "                       [ 0.1135, -0.0685, -0.0647,  ...,  0.0131,  0.0554,  0.0005],\n",
       "                       [ 0.1185,  0.1118, -0.0707,  ..., -0.0126,  0.0183,  0.1043]])),\n",
       "              ('net.models.1.mixing.3.intraatomic_context_net.0.weight',\n",
       "               tensor([[-0.0354,  0.0594,  0.0409,  ..., -0.0379, -0.0031,  0.0456],\n",
       "                       [ 0.0561,  0.1069, -0.0048,  ...,  0.0411,  0.0610, -0.1192],\n",
       "                       [-0.1235, -0.0394,  0.0702,  ..., -0.0814,  0.1140, -0.0112],\n",
       "                       ...,\n",
       "                       [ 0.0011,  0.0592, -0.0006,  ...,  0.1050,  0.0168, -0.0313],\n",
       "                       [-0.0453,  0.0135, -0.1102,  ..., -0.0113,  0.0228, -0.0232],\n",
       "                       [ 0.0328,  0.1100, -0.0844,  ..., -0.0118,  0.0156,  0.0764]])),\n",
       "              ('net.models.1.mixing.3.intraatomic_context_net.0.bias',\n",
       "               tensor([-3.1037e-03, -4.1325e-03,  5.4320e-04, -1.4632e-02, -1.4939e-03,\n",
       "                       -9.6563e-04,  1.5367e-03, -2.3524e-03, -4.3633e-03,  5.8548e-03,\n",
       "                       -1.6916e-03, -9.0361e-04, -4.8163e-03, -1.0979e-02,  4.8389e-03,\n",
       "                       -6.9514e-03,  7.9186e-04, -8.3147e-03, -6.1979e-04,  4.7733e-04,\n",
       "                       -9.4928e-03, -1.2370e-04,  3.1967e-03, -6.7402e-03,  1.7094e-03,\n",
       "                       -1.9422e-03,  4.2699e-04, -5.7899e-03, -5.1356e-03,  1.8373e-03,\n",
       "                       -1.9900e-03,  2.2792e-03, -5.3266e-03, -1.2293e-02, -1.9647e-03,\n",
       "                       -1.7602e-03,  2.3292e-04,  4.3301e-03, -2.0667e-03, -3.9113e-03,\n",
       "                        9.0629e-05, -2.7511e-03, -2.6840e-03, -3.6466e-03, -5.3221e-03,\n",
       "                       -4.6162e-03, -1.2617e-03, -3.4915e-03, -2.8847e-03,  3.1547e-03,\n",
       "                        2.5010e-03, -5.0048e-03,  5.4977e-03, -9.7975e-03,  1.2822e-03,\n",
       "                       -1.1751e-02, -4.2706e-03, -5.2962e-03, -1.6893e-03, -5.9235e-03,\n",
       "                        4.1956e-04, -2.1146e-03, -2.8848e-03,  9.2690e-04, -3.8012e-03,\n",
       "                       -3.0940e-03,  5.9464e-03,  1.4162e-04, -2.1945e-03, -2.3536e-03,\n",
       "                       -2.4093e-03, -2.3933e-03,  3.5390e-03, -5.6864e-03,  6.5137e-04,\n",
       "                        4.1667e-03, -4.5404e-03, -1.3223e-03, -2.2526e-03, -4.9329e-03,\n",
       "                       -5.6136e-04,  3.1184e-03,  2.5103e-03,  2.5633e-03,  6.0644e-03,\n",
       "                        3.8315e-04, -2.0583e-03,  6.3120e-04,  1.4563e-03,  1.2443e-04,\n",
       "                       -3.4796e-03, -2.8739e-03, -2.4535e-03, -2.2162e-04, -1.0135e-02,\n",
       "                       -1.0049e-03, -8.5585e-04, -5.4473e-04, -1.9304e-03, -1.4312e-03,\n",
       "                       -3.7868e-03,  4.3021e-03, -5.3416e-04, -1.7210e-03, -4.1451e-03,\n",
       "                       -3.8691e-03,  2.3481e-03,  1.1586e-03, -2.3498e-06,  1.7659e-03,\n",
       "                       -3.2021e-04, -1.3555e-03,  1.1510e-03, -5.3021e-03, -4.4545e-03,\n",
       "                       -3.1436e-03, -1.0602e-03,  1.0602e-03, -4.9844e-03, -1.2948e-03,\n",
       "                       -3.0717e-03, -4.6403e-04,  6.5050e-04, -2.9781e-03, -3.0567e-03,\n",
       "                       -2.9715e-06, -1.9596e-03, -4.8970e-04])),\n",
       "              ('net.models.1.mixing.3.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 0.0126,  0.0589,  0.0883,  ..., -0.0227,  0.0927, -0.0461],\n",
       "                       [ 0.0408,  0.0232, -0.0810,  ..., -0.1110,  0.0201,  0.0107],\n",
       "                       [-0.0119, -0.0990,  0.0433,  ..., -0.0397, -0.0548,  0.0941],\n",
       "                       ...,\n",
       "                       [ 0.0041,  0.0165, -0.0780,  ..., -0.0964,  0.0743,  0.0028],\n",
       "                       [ 0.0766,  0.0541,  0.0910,  ..., -0.0243, -0.0360,  0.0113],\n",
       "                       [ 0.0314, -0.0151, -0.0181,  ...,  0.0586,  0.1136,  0.0693]])),\n",
       "              ('net.models.1.mixing.3.intraatomic_context_net.1.bias',\n",
       "               tensor([-1.5808e-03,  4.2952e-03,  4.0553e-03,  4.0035e-04,  2.3829e-03,\n",
       "                        6.8807e-04, -8.7878e-03, -5.1871e-03, -1.0127e-03,  2.2289e-03,\n",
       "                        7.6369e-03, -2.1264e-03,  8.2942e-03,  1.2042e-03, -4.2025e-03,\n",
       "                        1.3072e-03, -8.6478e-05,  6.1931e-04, -4.6873e-03, -1.8412e-03,\n",
       "                       -1.0240e-03, -2.3492e-03,  3.6015e-03,  5.5702e-03,  4.2880e-03,\n",
       "                       -3.5005e-03, -3.3477e-03, -4.0281e-03, -8.3168e-05, -2.4820e-03,\n",
       "                       -2.8663e-03,  2.2585e-03,  9.8983e-04,  5.8360e-03,  2.2246e-03,\n",
       "                       -6.1720e-04, -2.6231e-04,  3.3450e-03,  4.4818e-03, -2.6424e-03,\n",
       "                       -1.6875e-03, -2.0206e-03,  7.6551e-04, -1.9153e-03, -3.3304e-03,\n",
       "                        4.1972e-04, -3.9816e-03, -2.6626e-03, -2.3451e-03,  1.0593e-02,\n",
       "                        1.7257e-03, -5.6131e-03, -8.8963e-04,  2.0352e-03, -1.5223e-03,\n",
       "                        4.4023e-04, -1.4326e-03, -9.7517e-04, -4.6244e-03, -8.5830e-04,\n",
       "                        1.7925e-03, -1.9962e-03,  7.3588e-04, -3.9410e-03,  5.5728e-03,\n",
       "                        7.9020e-04,  8.3074e-03,  5.9030e-03, -3.7236e-03, -2.7291e-04,\n",
       "                        9.9527e-04,  3.1677e-03, -4.9610e-04, -2.6246e-03,  3.0216e-04,\n",
       "                       -4.6229e-03, -2.3747e-03,  4.1264e-03,  2.2999e-03, -7.1732e-03,\n",
       "                       -1.8836e-03,  2.8123e-04, -8.7283e-03,  1.8445e-03, -2.2267e-04,\n",
       "                        6.6404e-03, -2.8526e-03,  9.9006e-04,  4.8510e-03, -4.9286e-05,\n",
       "                       -3.2223e-03, -1.2179e-03,  4.5049e-03,  6.2144e-04,  2.0800e-03,\n",
       "                        2.7996e-03,  1.2833e-03,  1.4950e-03, -1.6785e-03, -1.2738e-03,\n",
       "                        1.1274e-03, -2.8525e-05, -3.2858e-03, -2.4307e-03,  8.1176e-04,\n",
       "                       -2.3995e-05, -1.8140e-03, -2.8228e-03,  4.0366e-03, -1.1105e-03,\n",
       "                        3.6863e-03,  8.6427e-04,  1.3149e-03,  8.0616e-04, -4.0240e-03,\n",
       "                       -3.5088e-03,  8.0353e-03,  1.8552e-03, -1.4446e-03,  3.6795e-03,\n",
       "                        3.8297e-03, -4.7504e-03, -2.6926e-03,  1.0503e-04, -1.7839e-03,\n",
       "                        3.9473e-03,  5.0352e-03,  6.6035e-04,  6.5620e-03,  1.5527e-02,\n",
       "                       -2.4623e-03,  5.1808e-03,  2.8442e-03,  1.2456e-03, -7.1024e-03,\n",
       "                        5.3759e-03, -7.8936e-03,  5.5118e-03, -1.3923e-03, -9.8819e-03,\n",
       "                        4.0421e-03, -1.5488e-04,  4.1485e-03,  1.6526e-03,  1.0723e-02,\n",
       "                        1.8246e-02,  7.4359e-03,  1.2644e-02, -1.6265e-02, -3.3310e-03,\n",
       "                       -2.7609e-03, -4.5536e-03, -1.2069e-03,  9.8461e-03, -6.1296e-04,\n",
       "                       -1.3070e-02,  1.1847e-02,  8.1662e-03, -6.7548e-03,  1.0812e-02,\n",
       "                       -2.0261e-03, -8.2295e-03, -3.3251e-03, -2.6772e-03, -7.1411e-03,\n",
       "                       -1.3257e-03, -1.1234e-03,  1.0561e-02,  1.1277e-02, -5.7519e-03,\n",
       "                       -4.5796e-04,  8.3454e-03,  1.2455e-02,  1.2105e-04, -2.5338e-03,\n",
       "                        2.5431e-03,  3.8356e-03,  5.7323e-03, -4.3151e-03,  3.8794e-03,\n",
       "                       -9.9157e-03,  5.0314e-03, -6.8983e-03, -1.2413e-02,  5.5723e-03,\n",
       "                       -6.2372e-03, -8.5208e-03, -5.5250e-04,  8.1527e-03, -1.0497e-02,\n",
       "                        1.3453e-02, -2.4061e-03, -3.4743e-03, -1.9712e-03,  3.4967e-03,\n",
       "                       -1.3264e-02, -3.4571e-03,  2.6309e-03,  6.3525e-03, -1.8350e-04,\n",
       "                        1.4607e-02, -7.6341e-03,  4.9012e-03, -1.5352e-02, -7.1216e-04,\n",
       "                       -1.3540e-03, -6.6440e-03, -3.8154e-03, -4.0019e-03,  1.7713e-03,\n",
       "                        3.2998e-04,  3.9610e-03,  2.8577e-03,  2.6111e-03, -9.3699e-03,\n",
       "                        7.2313e-03,  1.2318e-02, -1.3599e-02, -1.7201e-02, -6.5198e-04,\n",
       "                       -1.1172e-02, -1.1587e-03,  3.2368e-03,  4.7044e-03, -3.0585e-03,\n",
       "                       -3.7243e-03, -2.2112e-03,  3.9089e-03,  1.1435e-02, -1.1318e-02,\n",
       "                        8.3043e-03, -5.1332e-03,  1.5933e-05,  4.7884e-03, -3.5287e-04,\n",
       "                        1.2057e-02,  1.3832e-03,  1.5491e-02, -8.7450e-03, -1.2261e-02,\n",
       "                        1.4319e-02, -6.5094e-03,  8.4252e-03,  6.7556e-03, -6.7477e-03,\n",
       "                        6.8801e-03, -5.1161e-03, -5.0631e-03,  1.3569e-02,  7.1753e-03,\n",
       "                       -7.4639e-03, -2.9033e-03,  2.6622e-03, -3.0327e-03, -2.1386e-03,\n",
       "                       -6.0867e-03, -6.5502e-03, -2.1325e-03,  4.5750e-03, -2.1352e-03,\n",
       "                       -2.4888e-03,  2.0017e-03, -5.9459e-03, -1.3362e-04,  6.9232e-04,\n",
       "                        3.4301e-03,  5.4620e-03,  1.7145e-02, -6.0047e-03, -7.2276e-03,\n",
       "                       -7.0809e-03,  2.4264e-03, -1.7625e-03, -5.7977e-03, -4.6165e-03,\n",
       "                       -8.0815e-03, -6.6034e-03,  4.9596e-03,  8.6387e-03,  6.4492e-03,\n",
       "                       -7.2357e-03, -1.0116e-02,  4.3635e-03,  1.2979e-02,  1.1163e-02,\n",
       "                        7.3858e-03,  1.5163e-03,  1.1220e-03,  1.0501e-03,  5.0879e-03,\n",
       "                       -7.4777e-03, -2.7056e-03,  1.9182e-03, -1.1456e-03,  7.2216e-03,\n",
       "                       -6.8346e-03, -1.2943e-02, -7.5243e-03,  5.4116e-04,  4.4490e-04,\n",
       "                        3.5882e-03,  2.8891e-03,  1.3528e-02,  3.6641e-03,  1.0092e-02,\n",
       "                       -1.0209e-02,  6.9217e-03, -7.9835e-03, -3.7123e-03, -6.4170e-03,\n",
       "                       -1.0016e-02, -1.0644e-02, -3.7437e-03, -4.0212e-03,  9.2199e-03,\n",
       "                       -1.5420e-02, -9.6621e-03, -2.7772e-04,  5.5151e-03, -1.2051e-02,\n",
       "                        1.0789e-02, -5.1414e-03,  3.7714e-03, -1.4866e-02,  4.0735e-03,\n",
       "                        4.2400e-03, -6.2118e-03,  3.9196e-03, -5.6533e-03, -8.7572e-04,\n",
       "                       -5.7677e-03,  3.6029e-03,  8.5142e-04, -3.9041e-03, -7.1467e-03,\n",
       "                       -1.1193e-03, -1.6020e-02, -1.2223e-02, -2.4461e-03,  8.9384e-03,\n",
       "                       -1.5199e-03, -6.6083e-03,  9.0707e-03, -1.2085e-02, -1.1891e-03,\n",
       "                       -4.0017e-03,  4.7496e-03, -2.8818e-03,  3.1232e-03, -4.4949e-03,\n",
       "                        2.5387e-03,  5.7415e-03,  1.9508e-02,  3.6189e-03,  5.4875e-03,\n",
       "                       -1.4203e-03, -1.2105e-02, -1.0185e-02,  6.1784e-04,  2.4212e-03,\n",
       "                        5.0440e-03,  1.2624e-02, -2.4404e-03,  5.0553e-03,  5.0233e-03,\n",
       "                       -2.6702e-03, -4.4404e-04,  6.7810e-03,  7.7131e-04, -7.5202e-03,\n",
       "                       -3.0449e-03,  8.2167e-03,  1.3026e-02, -1.0445e-02, -5.7397e-03,\n",
       "                       -4.5402e-04, -1.5848e-03, -7.2420e-03,  2.8029e-03,  5.0055e-03,\n",
       "                       -8.8593e-03, -6.9385e-03,  1.1271e-02,  1.1559e-03])),\n",
       "              ('net.models.1.mixing.3.mu_channel_mix.weight',\n",
       "               tensor([[-0.0103, -0.0713, -0.0228,  ...,  0.0873,  0.0030,  0.1031],\n",
       "                       [-0.0985,  0.0318,  0.0907,  ...,  0.0220,  0.0764,  0.0619],\n",
       "                       [ 0.0278,  0.0703,  0.0709,  ...,  0.1163, -0.0421, -0.0806],\n",
       "                       ...,\n",
       "                       [-0.0706, -0.0504, -0.0322,  ...,  0.0816, -0.0827,  0.0109],\n",
       "                       [-0.1327,  0.1338, -0.0111,  ..., -0.0613, -0.0641, -0.0118],\n",
       "                       [-0.0859, -0.1290, -0.0829,  ...,  0.0633, -0.0779,  0.0733]])),\n",
       "              ('net.models.1.mixing.4.intraatomic_context_net.0.weight',\n",
       "               tensor([[-0.0923, -0.0332,  0.1023,  ..., -0.0700, -0.1041,  0.0776],\n",
       "                       [-0.0972, -0.0868, -0.0514,  ...,  0.0163,  0.1192, -0.0371],\n",
       "                       [-0.1309, -0.0874, -0.0335,  ..., -0.0852, -0.0804, -0.0591],\n",
       "                       ...,\n",
       "                       [ 0.0842,  0.0244, -0.0669,  ...,  0.0304,  0.0136, -0.0675],\n",
       "                       [-0.0529,  0.0937, -0.1243,  ..., -0.0042,  0.0379, -0.1162],\n",
       "                       [ 0.1016,  0.1027,  0.0450,  ...,  0.0159,  0.0790, -0.0303]])),\n",
       "              ('net.models.1.mixing.4.intraatomic_context_net.0.bias',\n",
       "               tensor([-6.7665e-03, -3.1632e-03, -1.0012e-02,  8.0034e-04, -4.6840e-03,\n",
       "                       -1.0945e-02,  2.0843e-03, -1.8517e-03, -6.2822e-04, -3.2253e-03,\n",
       "                       -5.6924e-04, -1.8340e-03,  5.1521e-03, -1.4117e-03, -3.4680e-03,\n",
       "                        1.5495e-03,  5.6038e-03, -4.8480e-03,  8.5338e-05, -1.4980e-03,\n",
       "                       -3.7578e-04,  1.6668e-03, -2.1732e-04, -1.7673e-03, -4.9645e-03,\n",
       "                        4.7443e-04, -3.4855e-03,  1.5741e-03, -3.8450e-03, -3.9810e-03,\n",
       "                       -2.0929e-03, -3.1660e-03, -4.0057e-03, -1.2355e-04, -6.0217e-03,\n",
       "                       -6.6394e-03, -4.1169e-03,  3.3865e-03, -8.6011e-05, -1.6814e-03,\n",
       "                        7.2348e-03, -9.6160e-04, -9.1894e-04, -6.5083e-03, -1.0295e-02,\n",
       "                       -5.2196e-03,  7.3579e-03, -5.0924e-04, -1.5117e-03, -1.5624e-03,\n",
       "                       -2.1403e-03, -7.7428e-03, -2.7247e-03, -1.3095e-02, -1.1186e-02,\n",
       "                       -2.4558e-03, -6.7150e-03, -2.8976e-03, -5.8528e-03, -8.7437e-03,\n",
       "                        3.0262e-04,  3.3698e-03, -1.3178e-04, -9.3762e-04,  2.0808e-05,\n",
       "                        3.5702e-03, -5.8970e-03, -8.3628e-03,  4.3670e-04, -9.7958e-03,\n",
       "                       -2.3078e-04, -2.6990e-03,  8.2708e-03, -2.6211e-03, -6.5064e-03,\n",
       "                        2.0237e-04, -1.4200e-03, -1.7799e-04, -6.0902e-03, -2.5263e-03,\n",
       "                       -3.5838e-03,  4.1363e-04, -2.8401e-03, -4.9510e-03, -1.4798e-03,\n",
       "                       -6.7944e-03,  2.3100e-03, -1.0145e-02,  1.6492e-03, -3.9068e-03,\n",
       "                        8.7084e-03,  4.8655e-04,  9.2076e-05, -1.0414e-03,  1.5032e-03,\n",
       "                        1.1691e-03, -2.3676e-03, -7.6905e-03, -2.1678e-03,  2.8806e-03,\n",
       "                        5.6624e-04, -2.8395e-03, -1.3244e-03,  1.3645e-02, -7.2092e-04,\n",
       "                       -2.3960e-03, -4.0088e-05, -6.9600e-03, -4.5378e-04,  9.0852e-04,\n",
       "                       -1.6618e-03, -4.0456e-03, -1.3241e-02, -4.5986e-03, -3.0001e-03,\n",
       "                       -6.5401e-05,  1.9773e-03,  3.5921e-03, -2.1891e-03, -3.6530e-03,\n",
       "                       -2.6548e-03,  8.9639e-04,  3.3500e-04, -2.7964e-04, -7.4471e-04,\n",
       "                       -9.4011e-03,  3.6970e-04, -2.7239e-03])),\n",
       "              ('net.models.1.mixing.4.intraatomic_context_net.1.weight',\n",
       "               tensor([[ 3.7123e-02, -1.9660e-02, -9.0909e-03,  ...,  6.2575e-02,\n",
       "                        -4.9228e-03, -8.2581e-02],\n",
       "                       [-5.2003e-02, -6.2298e-03,  9.2832e-02,  ..., -6.3377e-02,\n",
       "                        -1.5268e-02, -5.8307e-03],\n",
       "                       [ 2.4734e-02, -7.5050e-02, -6.2948e-02,  ...,  9.0688e-05,\n",
       "                         4.0225e-02, -4.3102e-02],\n",
       "                       ...,\n",
       "                       [ 1.0098e-01, -4.7100e-02, -2.5199e-02,  ...,  4.2611e-02,\n",
       "                        -8.1691e-02, -1.0453e-01],\n",
       "                       [ 8.3406e-02,  7.9289e-02,  6.1586e-02,  ...,  2.7678e-02,\n",
       "                         7.6372e-02, -2.5411e-02],\n",
       "                       [ 1.5623e-02,  2.0701e-02, -4.1162e-02,  ...,  9.9975e-02,\n",
       "                        -1.0191e-01,  1.7522e-02]])),\n",
       "              ('net.models.1.mixing.4.intraatomic_context_net.1.bias',\n",
       "               tensor([-4.5271e-05,  1.8874e-03,  1.7037e-03,  5.7378e-04,  2.1604e-04,\n",
       "                        4.6551e-04, -7.4976e-03, -9.7826e-04,  6.7286e-04,  1.3817e-03,\n",
       "                        7.8479e-04, -2.8984e-04,  1.3447e-02,  6.8696e-03, -2.2533e-03,\n",
       "                       -6.6221e-04,  1.0154e-03,  6.6590e-04, -3.1002e-03, -1.7055e-03,\n",
       "                        1.8775e-03, -1.6690e-03,  1.7010e-03,  4.3388e-03,  3.1258e-03,\n",
       "                       -1.5803e-03, -7.8379e-05, -8.1601e-04, -6.1254e-03, -3.6461e-04,\n",
       "                        5.4514e-03,  1.1519e-03,  4.1525e-04,  6.3456e-04,  4.6627e-03,\n",
       "                        1.4380e-04, -7.6370e-04,  2.7979e-03,  2.5689e-03, -1.4836e-04,\n",
       "                       -4.1448e-03, -8.6326e-05,  4.6351e-04, -8.7554e-04, -2.3199e-03,\n",
       "                        2.0797e-04, -1.3141e-03, -1.5289e-03, -1.7003e-03,  6.2712e-03,\n",
       "                        8.0665e-04, -4.1199e-03,  2.0057e-03,  7.4179e-04, -3.0121e-04,\n",
       "                        1.4717e-03, -8.2331e-04, -5.7712e-04, -3.5006e-03,  3.5826e-04,\n",
       "                        9.6615e-04, -1.3856e-03, -4.0533e-04, -2.6003e-04,  5.7728e-03,\n",
       "                        3.6039e-04,  3.2488e-03,  5.2512e-04, -1.3210e-03, -3.8913e-04,\n",
       "                        8.7199e-04,  1.3610e-03, -1.0919e-03, -5.4409e-04,  8.5375e-04,\n",
       "                       -7.1641e-03, -4.8180e-03, -3.4089e-04, -9.6310e-05, -1.6896e-03,\n",
       "                        3.6933e-04,  7.5012e-04, -2.7144e-03, -1.0078e-03, -1.7767e-04,\n",
       "                        2.7769e-03, -5.5588e-04, -5.6878e-04,  1.0295e-03, -2.2454e-04,\n",
       "                       -2.1685e-03, -6.5194e-04,  1.2750e-03,  1.3268e-05,  5.2511e-04,\n",
       "                        3.1477e-04, -2.9758e-04,  9.2930e-04, -1.3665e-03, -4.4309e-04,\n",
       "                        6.3237e-04,  8.0187e-04, -1.1723e-03, -1.1962e-03,  4.4027e-04,\n",
       "                       -5.6918e-04, -2.3542e-03,  2.6147e-04,  4.4039e-03,  4.7579e-03,\n",
       "                        4.5331e-04,  6.0810e-04,  5.5270e-05,  4.4155e-04, -9.5081e-04,\n",
       "                       -3.1954e-03,  7.1428e-03, -4.0902e-04, -1.0335e-03,  2.3867e-03,\n",
       "                        8.5276e-04, -1.2213e-03, -2.1434e-04, -5.1139e-04, -8.5110e-04,\n",
       "                        3.2980e-03,  7.5946e-03,  1.0997e-04,  4.2220e-03,  1.1766e-02,\n",
       "                        1.2531e-02,  7.5138e-03,  1.8488e-02, -3.4044e-03,  4.0161e-03,\n",
       "                        1.2418e-02, -7.1015e-03,  9.1513e-03,  9.2064e-03,  5.2113e-03,\n",
       "                        1.9677e-03, -1.4275e-04,  5.9574e-03, -1.4994e-02, -4.0771e-03,\n",
       "                        5.7979e-03,  2.1525e-03, -4.8979e-03,  7.6038e-03,  5.6803e-03,\n",
       "                        1.6154e-03,  5.9769e-03, -4.9298e-04,  1.7713e-02,  1.1459e-02,\n",
       "                       -1.7057e-03,  9.0606e-04, -6.5924e-03, -2.6022e-04, -1.6660e-04,\n",
       "                        1.3716e-03,  3.8766e-03, -2.4007e-03, -7.5112e-03,  5.3121e-03,\n",
       "                       -7.6770e-03, -5.4262e-03, -5.1353e-03, -1.2611e-02, -4.3838e-03,\n",
       "                        7.4686e-03,  7.7284e-03,  4.1319e-03,  6.0619e-03,  5.7414e-03,\n",
       "                        1.4114e-02,  7.6454e-03,  3.5669e-03,  9.0590e-03, -1.6426e-03,\n",
       "                        4.2251e-03,  5.9633e-03, -6.8807e-03, -1.7365e-03,  1.2918e-03,\n",
       "                       -1.6118e-03,  9.5261e-03, -4.7611e-03,  3.0760e-03,  3.6504e-03,\n",
       "                        6.7594e-03,  3.3702e-03,  6.7190e-03, -1.7333e-02, -5.4149e-03,\n",
       "                        7.5027e-03,  1.2237e-02,  2.5018e-03, -8.8060e-03,  1.5240e-02,\n",
       "                       -2.2817e-03,  6.7797e-03,  1.7268e-03,  3.7082e-03,  1.8089e-03,\n",
       "                        1.0702e-03, -2.1568e-03, -3.4522e-03,  3.4640e-03,  9.3040e-03,\n",
       "                        1.1910e-02,  7.7070e-04,  9.9555e-03,  1.5127e-02,  1.4966e-02,\n",
       "                        1.0109e-02, -3.5985e-03, -3.8045e-03,  1.4020e-02, -1.1450e-02,\n",
       "                       -7.5971e-03, -4.8237e-03,  3.7389e-03, -9.7292e-03, -9.7265e-03,\n",
       "                       -2.6851e-03, -1.3647e-03, -8.7392e-03,  2.0290e-03,  2.6689e-03,\n",
       "                        3.8346e-03, -4.1784e-04,  4.7520e-03,  5.0789e-03, -3.9807e-03,\n",
       "                        1.0616e-03,  5.8849e-03,  6.4861e-04, -7.1093e-03, -3.9469e-03,\n",
       "                       -7.7520e-03, -1.5952e-03,  9.0837e-03,  4.7141e-03, -6.6659e-03,\n",
       "                       -2.7755e-03,  3.9825e-03, -7.3519e-03,  1.3610e-02,  1.5015e-02,\n",
       "                        1.3382e-03,  1.2115e-02, -1.1519e-02,  9.0677e-03,  1.9382e-03,\n",
       "                       -1.6792e-03,  4.0702e-03,  2.4214e-04, -6.9481e-04, -2.2665e-03,\n",
       "                        3.4325e-03,  1.5016e-03, -6.3145e-03, -1.1985e-02, -7.7752e-03,\n",
       "                       -1.4979e-02, -8.3131e-03,  7.5428e-05,  3.8938e-03, -1.0827e-02,\n",
       "                        5.4114e-03,  6.1592e-03, -2.2488e-03,  2.4604e-03,  1.1634e-02,\n",
       "                        3.9886e-03, -4.3769e-03,  4.7130e-03, -3.4905e-03, -3.0540e-03,\n",
       "                       -2.8150e-03,  1.1961e-02, -9.9720e-03,  1.0808e-03, -1.0133e-02,\n",
       "                       -1.7378e-03, -1.3695e-03, -4.0190e-03,  6.5089e-03,  3.4372e-03,\n",
       "                       -1.1856e-03,  9.3298e-03,  6.5092e-04,  1.0226e-02, -9.6664e-03,\n",
       "                       -4.8418e-03, -4.5971e-03, -7.3604e-03, -5.9139e-03,  8.2430e-03,\n",
       "                       -4.7331e-03,  9.6212e-03, -2.5738e-03, -6.9560e-04,  1.9421e-03,\n",
       "                       -1.3820e-02,  1.4618e-02,  1.9359e-03,  3.0217e-03,  7.3179e-05,\n",
       "                       -4.7750e-03,  9.4567e-03, -5.4208e-03,  1.2749e-03, -3.3292e-04,\n",
       "                        2.4679e-03,  1.0909e-03,  6.8065e-03, -3.7037e-03,  1.1971e-02,\n",
       "                       -6.6851e-03,  5.7612e-03,  6.0526e-03, -4.3934e-04,  3.3870e-03,\n",
       "                       -1.0051e-02,  5.7703e-03,  7.1523e-04,  6.7359e-03,  9.9760e-03,\n",
       "                        7.3483e-03, -4.4481e-03, -3.4318e-03,  4.2455e-03,  5.3346e-03,\n",
       "                       -1.0434e-03, -1.2042e-02, -6.5208e-03, -5.2984e-03, -6.2546e-03,\n",
       "                       -7.1617e-03,  2.1988e-03,  2.5994e-03, -3.0953e-03, -4.8734e-03,\n",
       "                        4.9300e-04, -5.8244e-03, -4.8166e-03, -1.7317e-03,  1.2957e-03,\n",
       "                       -1.2325e-03,  1.7379e-02, -6.5642e-05, -3.3725e-03, -6.8611e-03,\n",
       "                       -7.5413e-03, -9.2207e-03,  1.9267e-03,  7.3831e-03, -9.3200e-03,\n",
       "                       -1.3025e-02,  1.4729e-02, -3.6393e-04,  4.7246e-04,  9.2701e-04,\n",
       "                       -1.7376e-03, -4.4875e-03, -6.3534e-03,  8.9175e-03,  7.5379e-03,\n",
       "                        3.0511e-03, -2.2413e-03, -8.0080e-03, -4.3021e-03, -6.7227e-03,\n",
       "                        4.6194e-03, -1.8507e-02,  6.1625e-03,  3.9076e-03,  1.0840e-02,\n",
       "                        6.2744e-03, -8.6032e-03, -2.9107e-03, -1.7195e-03])),\n",
       "              ('net.models.1.mixing.4.mu_channel_mix.weight',\n",
       "               tensor([[ 8.2579e-02, -4.6666e-02,  8.4610e-02,  ..., -4.3060e-02,\n",
       "                         8.5835e-02, -3.8150e-02],\n",
       "                       [-7.0246e-02, -1.1406e-01, -3.9924e-02,  ..., -7.3752e-02,\n",
       "                         3.5985e-02,  7.6859e-02],\n",
       "                       [ 7.2408e-03,  4.4993e-02,  7.7669e-02,  ..., -1.1969e-02,\n",
       "                        -8.1094e-03,  1.0407e-01],\n",
       "                       ...,\n",
       "                       [-6.4154e-02,  8.0105e-02, -8.2880e-02,  ..., -5.3774e-02,\n",
       "                        -2.5581e-02, -7.5461e-02],\n",
       "                       [ 7.6108e-02, -1.1908e-01, -2.6620e-02,  ...,  9.0115e-02,\n",
       "                        -7.9976e-04, -8.9415e-02],\n",
       "                       [-2.7778e-02, -8.9407e-02, -1.2391e-02,  ...,  3.7503e-02,\n",
       "                         3.2889e-05,  5.3378e-02]])),\n",
       "              ('net.models.1.mixing.5.intraatomic_context_net.0.weight',\n",
       "               tensor([[ 0.0157,  0.0781, -0.0249,  ...,  0.0078, -0.1137,  0.0577],\n",
       "                       [-0.0966,  0.0633, -0.0612,  ..., -0.0663, -0.1036, -0.1291],\n",
       "                       [-0.0955,  0.1001, -0.0167,  ..., -0.0591, -0.0386,  0.1132],\n",
       "                       ...,\n",
       "                       [-0.0960,  0.0273,  0.1000,  ...,  0.0793,  0.1132,  0.0068],\n",
       "                       [ 0.0414, -0.0546, -0.0512,  ..., -0.0745,  0.1008,  0.0117],\n",
       "                       [-0.1074, -0.1166, -0.0579,  ..., -0.0355,  0.0557, -0.1150]])),\n",
       "              ('net.models.1.mixing.5.intraatomic_context_net.0.bias',\n",
       "               tensor([-6.5501e-03, -6.6751e-03, -1.3490e-03, -4.6276e-04,  9.1068e-04,\n",
       "                       -2.3715e-03, -5.7376e-03, -6.5874e-03, -2.9712e-03, -1.4553e-03,\n",
       "                       -1.6178e-03, -3.6529e-04, -1.5993e-03, -3.8400e-03, -3.1157e-03,\n",
       "                       -5.6293e-03, -4.6744e-03,  2.7243e-03, -7.1443e-03,  3.7740e-03,\n",
       "                        4.0984e-04, -8.5109e-03,  1.2920e-03,  2.5061e-03, -2.5656e-03,\n",
       "                       -1.6852e-03,  4.1905e-03, -1.9656e-03, -2.9809e-03, -8.3082e-04,\n",
       "                       -1.8047e-03, -4.9600e-04, -3.5467e-03,  3.9498e-03, -4.6777e-03,\n",
       "                       -5.2416e-03,  2.4428e-04, -9.1996e-04, -8.0715e-03, -3.2875e-03,\n",
       "                       -3.3327e-03, -3.2069e-03, -8.4942e-03,  3.5249e-04, -3.8683e-03,\n",
       "                       -2.8108e-03, -1.6454e-03, -4.8608e-03, -7.1520e-03, -8.7207e-03,\n",
       "                       -2.5593e-03, -7.4749e-04, -1.7080e-03,  5.9446e-03, -4.4279e-03,\n",
       "                        1.6061e-03, -4.7673e-03, -8.5067e-03, -6.9110e-03, -8.5831e-05,\n",
       "                       -4.9282e-03, -5.9501e-03,  1.3877e-03, -1.6455e-03,  1.0271e-02,\n",
       "                       -6.1036e-03, -3.2148e-03, -5.8890e-05, -1.2055e-04, -1.2146e-02,\n",
       "                       -2.8750e-03, -4.6813e-04, -7.2678e-03,  3.7793e-03, -4.1903e-04,\n",
       "                       -2.1276e-03, -6.0506e-03, -1.9036e-03,  3.2872e-04, -1.4919e-02,\n",
       "                        2.5780e-03,  2.5289e-03,  8.9533e-04, -4.1537e-03, -1.0707e-02,\n",
       "                       -6.8320e-04, -1.5005e-03, -3.3902e-04, -9.2542e-03, -1.0245e-03,\n",
       "                       -7.7933e-04,  9.7266e-04, -8.0482e-03, -3.2150e-03, -5.8934e-03,\n",
       "                       -4.3277e-03, -1.9339e-03, -7.3122e-03, -7.1511e-03, -8.1087e-03,\n",
       "                        8.7606e-03,  1.8636e-04, -4.5198e-03,  6.1521e-04, -6.7403e-04,\n",
       "                        5.7604e-03, -4.5920e-03,  2.3727e-03, -5.6390e-03, -2.4062e-03,\n",
       "                       -5.7126e-04, -9.6397e-03, -3.1252e-03, -1.3528e-03, -2.6556e-03,\n",
       "                        7.1362e-04,  1.4388e-03, -2.0318e-03,  5.2668e-03, -4.6964e-03,\n",
       "                        4.8072e-03, -1.5927e-03, -3.6794e-03,  2.8634e-03, -1.3372e-03,\n",
       "                        2.7095e-03, -7.6389e-03, -1.4317e-03])),\n",
       "              ('net.models.1.mixing.5.intraatomic_context_net.1.weight',\n",
       "               tensor([[-0.0664, -0.0371,  0.0192,  ...,  0.0690, -0.0106, -0.0123],\n",
       "                       [-0.0899,  0.0075,  0.0125,  ..., -0.1078, -0.0983, -0.0796],\n",
       "                       [-0.0129,  0.0086, -0.0362,  ..., -0.0906,  0.0882, -0.0538],\n",
       "                       ...,\n",
       "                       [-0.1119,  0.0768,  0.1074,  ..., -0.0444, -0.0250,  0.0382],\n",
       "                       [-0.0471, -0.0983, -0.0564,  ...,  0.0775,  0.0539,  0.0316],\n",
       "                       [-0.0999,  0.0316,  0.0456,  ..., -0.0903, -0.0819, -0.0860]])),\n",
       "              ('net.models.1.mixing.5.intraatomic_context_net.1.bias',\n",
       "               tensor([-5.9356e-04,  2.9100e-04,  2.9359e-04, -1.5565e-04, -7.4198e-05,\n",
       "                        1.2791e-04, -8.6393e-04, -1.8497e-05, -1.5777e-04,  2.4462e-04,\n",
       "                        2.3179e-03, -2.5571e-04,  5.6521e-04,  5.4694e-04, -2.2501e-04,\n",
       "                        1.7067e-04,  3.2484e-04,  2.0621e-04,  1.7668e-04, -2.7036e-04,\n",
       "                        5.8192e-04, -4.6633e-04,  1.5401e-04,  1.1326e-03,  1.5744e-03,\n",
       "                       -4.8362e-04,  1.6489e-04, -2.9985e-04, -3.9611e-04,  1.3201e-04,\n",
       "                        1.7970e-03,  1.7341e-04,  1.2266e-04,  2.1833e-04,  1.0481e-03,\n",
       "                        1.0204e-03, -3.4997e-04,  8.2055e-04,  5.2390e-04, -1.7977e-04,\n",
       "                        2.3700e-03,  6.2318e-05, -4.2580e-05, -2.9681e-04, -2.0880e-04,\n",
       "                        9.3210e-05, -3.1990e-04, -2.4945e-04, -4.5309e-04,  6.6567e-04,\n",
       "                        4.6079e-05, -1.0057e-03, -2.8364e-04,  1.5331e-04, -4.4337e-03,\n",
       "                       -2.5154e-03, -3.5529e-04, -1.9815e-04, -5.2508e-04,  8.9817e-04,\n",
       "                        2.5070e-04, -4.3288e-04, -5.6471e-04, -9.3575e-05,  5.0386e-04,\n",
       "                       -2.4906e-04,  6.9856e-04,  3.1621e-03, -7.1687e-04,  1.0355e-04,\n",
       "                       -8.0503e-05,  3.0889e-04, -4.1062e-05, -1.0712e-04,  2.3870e-04,\n",
       "                       -3.1642e-03, -1.7048e-03,  9.4532e-05,  3.3763e-04, -7.2131e-04,\n",
       "                       -7.3603e-04,  1.4488e-04, -1.6018e-03, -2.5634e-03,  6.8488e-04,\n",
       "                        4.6309e-04, -1.3036e-04, -6.0761e-05, -1.5861e-04,  3.8509e-04,\n",
       "                       -2.5456e-04, -5.7193e-04,  2.8663e-04,  1.6709e-04, -1.3711e-04,\n",
       "                        1.0826e-04,  3.2986e-04,  2.3214e-04, -3.1288e-04, -5.0073e-04,\n",
       "                       -1.0752e-05, -1.2394e-04, -4.8210e-05, -1.3993e-04,  1.6011e-04,\n",
       "                       -3.4671e-04, -3.7489e-04,  8.3672e-05,  9.9871e-04,  1.4511e-04,\n",
       "                        1.1899e-04,  1.8539e-04, -3.1000e-04,  7.7221e-05, -4.6366e-04,\n",
       "                        1.1484e-04, -7.6397e-05,  6.3075e-05,  8.3722e-04,  3.3994e-04,\n",
       "                        1.9644e-03, -2.7986e-04, -3.0695e-04,  2.9373e-03, -6.1909e-05,\n",
       "                        2.1634e-02,  1.4595e-03,  3.1052e-04,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "                        0.0000e+00, -2.3481e-03,  1.1071e-02,  4.8211e-03, -5.8678e-03,\n",
       "                       -1.3009e-02,  5.3328e-03, -5.7181e-03, -5.0797e-03, -2.2944e-06,\n",
       "                        3.9746e-03,  7.2730e-04,  1.2747e-02, -7.9104e-03, -8.3980e-03,\n",
       "                       -6.6273e-04, -3.9117e-03, -2.7350e-03, -1.5453e-02,  6.9057e-03,\n",
       "                       -8.1280e-03,  2.9226e-03, -1.0574e-02, -8.9206e-03,  6.4694e-03,\n",
       "                        5.5913e-03, -5.6961e-03,  1.3546e-02,  2.7870e-03,  6.0705e-03,\n",
       "                        2.7230e-03, -2.3300e-03,  2.6434e-03,  9.6955e-03, -1.5038e-03,\n",
       "                       -6.8327e-03, -6.7028e-04,  6.2420e-03, -4.0802e-03,  1.2496e-03,\n",
       "                       -6.4853e-03,  4.9473e-03,  4.3400e-03, -1.4149e-03, -1.3885e-02,\n",
       "                       -6.4146e-03, -6.5542e-04,  6.8091e-03, -4.6360e-03, -1.6198e-02,\n",
       "                        7.6090e-03,  7.7540e-03,  1.7465e-04, -7.4801e-03, -6.4125e-03,\n",
       "                        7.2352e-03,  7.2762e-03, -9.4191e-04,  1.8604e-03, -6.4450e-03,\n",
       "                        5.4724e-03,  2.6194e-03,  3.4910e-03, -5.0015e-03,  1.5045e-02,\n",
       "                       -3.0186e-03, -6.6628e-03,  2.0683e-03,  1.5526e-02,  1.2164e-02,\n",
       "                       -1.9686e-02, -4.2137e-03, -1.8657e-05, -8.6364e-03, -8.4029e-03,\n",
       "                       -1.7755e-03,  4.5059e-03,  1.7357e-03,  7.3295e-03, -6.6110e-03,\n",
       "                        1.4668e-02,  6.0120e-03,  1.3240e-03, -1.1772e-02,  3.1674e-03,\n",
       "                        1.3448e-03,  8.5260e-03, -6.4314e-03,  8.4566e-03, -1.2132e-02,\n",
       "                       -3.8310e-04,  3.1699e-04,  7.5403e-03,  6.7286e-03,  2.3767e-03,\n",
       "                       -1.0267e-03, -1.4018e-02,  8.8434e-03,  3.3502e-03,  4.7562e-03,\n",
       "                       -2.4830e-03, -8.6769e-03, -2.5303e-03, -1.5736e-03,  1.2271e-02,\n",
       "                        9.7235e-03, -2.4792e-04, -2.6941e-03, -6.7688e-03, -2.4679e-03,\n",
       "                        2.1041e-03,  2.7345e-04, -2.2314e-03, -4.3862e-03, -5.5238e-03,\n",
       "                       -2.2888e-03, -2.2715e-03, -1.2057e-03,  7.6301e-04, -1.5049e-02,\n",
       "                       -4.2090e-03,  5.5139e-03,  1.4684e-03, -8.5162e-04,  2.5084e-03,\n",
       "                       -8.7176e-03,  5.8274e-03,  1.4061e-02,  1.5969e-04])),\n",
       "              ('net.models.1.mixing.5.mu_channel_mix.weight',\n",
       "               tensor([[-0.1017,  0.0250, -0.1145,  ..., -0.0983, -0.0425, -0.0170],\n",
       "                       [-0.0869,  0.0835, -0.0073,  ..., -0.0467, -0.0327,  0.0324],\n",
       "                       [ 0.0536, -0.1144,  0.0432,  ...,  0.0416, -0.0836, -0.0568],\n",
       "                       ...,\n",
       "                       [-0.0061,  0.0097,  0.0286,  ..., -0.0283,  0.0524,  0.0498],\n",
       "                       [ 0.1259,  0.0144, -0.0565,  ...,  0.0236, -0.0092, -0.1142],\n",
       "                       [ 0.0283,  0.0117, -0.0664,  ...,  0.0836,  0.0495,  0.1007]])),\n",
       "              ('net.linear.weight',\n",
       "               tensor([[-0.0252,  0.0165,  0.0430, -0.0205,  0.0408,  0.0143,  0.0017, -0.0519,\n",
       "                         0.0356, -0.0223,  0.0430,  0.0082,  0.0034,  0.0067, -0.0166,  0.0466,\n",
       "                        -0.0285,  0.0213,  0.0477,  0.0030,  0.0278,  0.0484,  0.0176, -0.0113,\n",
       "                         0.0049,  0.0251, -0.0131, -0.0387, -0.0355,  0.0268, -0.0008, -0.0213,\n",
       "                         0.0423,  0.0271,  0.0144, -0.0388, -0.0504, -0.0163, -0.0540, -0.0007,\n",
       "                        -0.0407,  0.0345, -0.0475, -0.0494, -0.0141, -0.0317, -0.0009, -0.0292,\n",
       "                         0.0010, -0.0452,  0.0380, -0.0007, -0.0349,  0.0292,  0.0319,  0.0300,\n",
       "                        -0.0053,  0.0059, -0.0157, -0.0497,  0.0038, -0.0363,  0.0081,  0.0130,\n",
       "                         0.0305,  0.0304,  0.0400, -0.0126, -0.0195, -0.0482,  0.0083,  0.0541,\n",
       "                         0.0005, -0.0249, -0.0324,  0.0372, -0.0015, -0.0350,  0.0459,  0.0167,\n",
       "                         0.0479, -0.0287,  0.0179, -0.0301,  0.0303,  0.0335, -0.0462,  0.0357,\n",
       "                         0.0221, -0.0426,  0.0126, -0.0316,  0.0490, -0.0276, -0.0126, -0.0384,\n",
       "                         0.0042,  0.0017, -0.0248, -0.0173,  0.0432, -0.0116, -0.0489, -0.0445,\n",
       "                         0.0413,  0.0098, -0.0463,  0.0366, -0.0454, -0.0233, -0.0310, -0.0090,\n",
       "                         0.0134, -0.0244,  0.0123,  0.0098,  0.0033,  0.0316, -0.0456,  0.0166,\n",
       "                        -0.0021, -0.0402, -0.0183,  0.0126, -0.0031, -0.0341, -0.0234, -0.0159,\n",
       "                         0.0201,  0.0156,  0.0268,  0.0186,  0.0216, -0.0418,  0.0115,  0.0133,\n",
       "                        -0.0135, -0.0358, -0.0057, -0.0348,  0.0082,  0.0048, -0.0418,  0.0215,\n",
       "                         0.0100, -0.0327, -0.0188,  0.0428,  0.0028,  0.0324,  0.0324, -0.0076,\n",
       "                        -0.0082, -0.0177, -0.0223,  0.0221,  0.0114, -0.0451,  0.0020,  0.0527,\n",
       "                        -0.0271, -0.0229,  0.0035, -0.0003,  0.0246,  0.0069,  0.0146,  0.0231,\n",
       "                        -0.0043, -0.0379,  0.0435, -0.0292,  0.0251, -0.0199, -0.0255, -0.0345,\n",
       "                        -0.0176,  0.0105,  0.0314, -0.0069, -0.0096,  0.0468,  0.0024, -0.0048,\n",
       "                         0.0488,  0.0214,  0.0252,  0.0030, -0.0478,  0.0343, -0.0011, -0.0234,\n",
       "                         0.0159,  0.0391, -0.0173,  0.0014,  0.0180, -0.0322,  0.0193, -0.0446,\n",
       "                        -0.0128, -0.0383, -0.0267, -0.0039, -0.0018,  0.0251,  0.0229, -0.0058,\n",
       "                        -0.0035,  0.0387,  0.0030, -0.0005,  0.0101, -0.0208, -0.0269, -0.0243,\n",
       "                         0.0248, -0.0261, -0.0099,  0.0237, -0.0152,  0.0252,  0.0351, -0.0073,\n",
       "                         0.0268, -0.0362,  0.0494,  0.0240,  0.0448, -0.0153, -0.0399, -0.0350,\n",
       "                        -0.0389, -0.0164, -0.0234, -0.0142, -0.0071,  0.0087,  0.0367, -0.0478,\n",
       "                         0.0447,  0.0190,  0.0312, -0.0114, -0.0093,  0.0169,  0.0009,  0.0103,\n",
       "                        -0.0012, -0.0188,  0.0516, -0.0021, -0.0488, -0.0008, -0.0091, -0.0328]])),\n",
       "              ('net.linear.bias', tensor([-0.0321]))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 17},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 17,\n",
       "     'completed': 17,\n",
       "     'started': 17,\n",
       "     'processed': 17},\n",
       "    'current': {'ready': 17, 'completed': 17, 'started': 17, 'processed': 17},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 17, 'completed': 17},\n",
       "    'current': {'ready': 17, 'completed': 17}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 17,\n",
       "       'completed': 17},\n",
       "      'current': {'ready': 17, 'completed': 17}},\n",
       "     'zero_grad': {'total': {'ready': 17, 'completed': 17, 'started': 17},\n",
       "      'current': {'ready': 17, 'completed': 17, 'started': 17}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 3,\n",
       "     'completed': 3,\n",
       "     'started': 3,\n",
       "     'processed': 3},\n",
       "    'current': {'ready': 3, 'completed': 3, 'started': 3, 'processed': 3},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 1,\n",
       "     'completed': 0,\n",
       "     'started': 1,\n",
       "     'processed': 1},\n",
       "    'current': {'ready': 1, 'completed': 0, 'started': 1, 'processed': 1}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'max_atomic_num': 79,\n",
       "  'unique_variables': 2,\n",
       "  'activation': 'relu',\n",
       "  'batch_size': 256,\n",
       "  'dataset': 'BDE',\n",
       "  'dropout': 0.5,\n",
       "  'hidden_dim': 128,\n",
       "  'learning_rate': 0.001,\n",
       "  'max_num_conformers': 20,\n",
       "  'max_num_molecules': None,\n",
       "  'num_epochs': 2000,\n",
       "  'patience': 200,\n",
       "  'seed': 123,\n",
       "  'target': 'BindingEnergy',\n",
       "  'train_ratio': 0.7,\n",
       "  'valid_ratio': 0.1,\n",
       "  'weight_decay': 0.0001},\n",
       " 'datamodule_hyper_parameters': {'__module__': 'config',\n",
       "  '__annotations__': {'dataset': str,\n",
       "   'target': str,\n",
       "   'max_num_molecules': int,\n",
       "   'max_num_conformers': int,\n",
       "   'train_ratio': float,\n",
       "   'valid_ratio': float,\n",
       "   'batch_size': int,\n",
       "   'hidden_dim': int,\n",
       "   'num_epochs': int,\n",
       "   'patience': int,\n",
       "   'activation': str,\n",
       "   'seed': int,\n",
       "   'device': str,\n",
       "   'dropout': float,\n",
       "   'scheduler': str,\n",
       "   'reduce_lr_on_plateau': config.ReduceLROnPlateau,\n",
       "   'cosine_annealing_lr': config.CosineAnnealingLR,\n",
       "   'linear_warmup_cosine_annealing_lr': config.LinearWarmupCosineAnnealingLR,\n",
       "   'one_cycle_lr': config.OneCycleLR,\n",
       "   'learning_rate': float,\n",
       "   'weight_decay': float,\n",
       "   'modelfprf': configs.model_fp_rf.ModelFPRF,\n",
       "   'model1d': configs.model_1d.Model1D,\n",
       "   'model2d': configs.model_2d.Model2D,\n",
       "   'model3d': configs.model_3d.Model3D,\n",
       "   'model4d': configs.model_4d.Model4D},\n",
       "  'dataset': 'BDE',\n",
       "  'target': 'BindingEnergy',\n",
       "  'max_num_molecules': None,\n",
       "  'max_num_conformers': 20,\n",
       "  'train_ratio': 0.7,\n",
       "  'valid_ratio': 0.1,\n",
       "  'batch_size': 256,\n",
       "  'hidden_dim': 128,\n",
       "  'num_epochs': 2000,\n",
       "  'patience': 200,\n",
       "  'activation': 'relu',\n",
       "  'seed': 123,\n",
       "  'device': 'cuda:0',\n",
       "  'dropout': 0.5,\n",
       "  'scheduler': None,\n",
       "  'reduce_lr_on_plateau': ReduceLROnPlateau(mode='min', factor=0.8, patience=20),\n",
       "  'cosine_annealing_lr': CosineAnnealingLR(eta_min=1e-06),\n",
       "  'linear_warmup_cosine_annealing_lr': LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000),\n",
       "  'one_cycle_lr': OneCycleLR(max_lr=0.001, steps_per_epoch=100),\n",
       "  'learning_rate': 0.001,\n",
       "  'weight_decay': 0.0001,\n",
       "  'modelfprf': ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True),\n",
       "  'model1d': Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4),\n",
       "  'model2d': Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)),\n",
       "  'model3d': Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)),\n",
       "  'model4d': Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2)),\n",
       "  '__dict__': <attribute '__dict__' of 'Config' objects>,\n",
       "  '__weakref__': <attribute '__weakref__' of 'Config' objects>,\n",
       "  '__doc__': \"Config(dataset: str = 'Kraken', target: str = 'qpoletens_xx', max_num_molecules: int = None, max_num_conformers: int = 20, train_ratio: float = 0.7, valid_ratio: float = 0.1, batch_size: int = 256, hidden_dim: int = 128, num_epochs: int = 2000, patience: int = 200, activation: str = 'relu', seed: int = 123, device: str = 'cuda:5', dropout: float = 0.5, scheduler: str = None, reduce_lr_on_plateau: config.ReduceLROnPlateau = ReduceLROnPlateau(mode='min', factor=0.8, patience=20), cosine_annealing_lr: config.CosineAnnealingLR = CosineAnnealingLR(eta_min=1e-06), linear_warmup_cosine_annealing_lr: config.LinearWarmupCosineAnnealingLR = LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000), one_cycle_lr: config.OneCycleLR = OneCycleLR(max_lr=0.001, steps_per_epoch=100), learning_rate: float = 0.001, weight_decay: float = 0.0001, modelfprf: configs.model_fp_rf.ModelFPRF = ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True), model1d: configs.model_1d.Model1D = Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4), model2d: configs.model_2d.Model2D = Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)), model3d: configs.model_3d.Model3D = Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)), model4d: configs.model_4d.Model4D = Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2)))\",\n",
       "  '__dataclass_params__': _DataclassParams(init=True,repr=True,eq=True,order=False,unsafe_hash=False,frozen=False),\n",
       "  '__dataclass_fields__': {'dataset': Field(name='dataset',type=<class 'str'>,default='Kraken',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'target': Field(name='target',type=<class 'str'>,default='qpoletens_xx',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'max_num_molecules': Field(name='max_num_molecules',type=<class 'int'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'max_num_conformers': Field(name='max_num_conformers',type=<class 'int'>,default=20,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'train_ratio': Field(name='train_ratio',type=<class 'float'>,default=0.7,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'valid_ratio': Field(name='valid_ratio',type=<class 'float'>,default=0.1,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'batch_size': Field(name='batch_size',type=<class 'int'>,default=256,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'hidden_dim': Field(name='hidden_dim',type=<class 'int'>,default=128,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'num_epochs': Field(name='num_epochs',type=<class 'int'>,default=2000,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'patience': Field(name='patience',type=<class 'int'>,default=200,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'activation': Field(name='activation',type=<class 'str'>,default='relu',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'seed': Field(name='seed',type=<class 'int'>,default=123,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'device': Field(name='device',type=<class 'str'>,default='cuda:5',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'dropout': Field(name='dropout',type=<class 'float'>,default=0.5,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'scheduler': Field(name='scheduler',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'reduce_lr_on_plateau': Field(name='reduce_lr_on_plateau',type=<class 'config.ReduceLROnPlateau'>,default=ReduceLROnPlateau(mode='min', factor=0.8, patience=20),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'cosine_annealing_lr': Field(name='cosine_annealing_lr',type=<class 'config.CosineAnnealingLR'>,default=CosineAnnealingLR(eta_min=1e-06),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'linear_warmup_cosine_annealing_lr': Field(name='linear_warmup_cosine_annealing_lr',type=<class 'config.LinearWarmupCosineAnnealingLR'>,default=LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'one_cycle_lr': Field(name='one_cycle_lr',type=<class 'config.OneCycleLR'>,default=OneCycleLR(max_lr=0.001, steps_per_epoch=100),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'learning_rate': Field(name='learning_rate',type=<class 'float'>,default=0.001,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'weight_decay': Field(name='weight_decay',type=<class 'float'>,default=0.0001,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'modelfprf': Field(name='modelfprf',type=<class 'configs.model_fp_rf.ModelFPRF'>,default=ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'model1d': Field(name='model1d',type=<class 'configs.model_1d.Model1D'>,default=Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'model2d': Field(name='model2d',type=<class 'configs.model_2d.Model2D'>,default=Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'model3d': Field(name='model3d',type=<class 'configs.model_3d.Model3D'>,default=Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "   'model4d': Field(name='model4d',type=<class 'configs.model_4d.Model4D'>,default=Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2)),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD)},\n",
       "  '__init__': <function config.Config.__init__(self, dataset: str = 'Kraken', target: str = 'qpoletens_xx', max_num_molecules: int = None, max_num_conformers: int = 20, train_ratio: float = 0.7, valid_ratio: float = 0.1, batch_size: int = 256, hidden_dim: int = 128, num_epochs: int = 2000, patience: int = 200, activation: str = 'relu', seed: int = 123, device: str = 'cuda:5', dropout: float = 0.5, scheduler: str = None, reduce_lr_on_plateau: config.ReduceLROnPlateau = ReduceLROnPlateau(mode='min', factor=0.8, patience=20), cosine_annealing_lr: config.CosineAnnealingLR = CosineAnnealingLR(eta_min=1e-06), linear_warmup_cosine_annealing_lr: config.LinearWarmupCosineAnnealingLR = LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000), one_cycle_lr: config.OneCycleLR = OneCycleLR(max_lr=0.001, steps_per_epoch=100), learning_rate: float = 0.001, weight_decay: float = 0.0001, modelfprf: configs.model_fp_rf.ModelFPRF = ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True), model1d: configs.model_1d.Model1D = Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4), model2d: configs.model_2d.Model2D = Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)), model3d: configs.model_3d.Model3D = Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)), model4d: configs.model_4d.Model4D = Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2))) -> None>,\n",
       "  '__repr__': <function config.Config.__repr__(self)>,\n",
       "  '__eq__': <function config.Config.__eq__(self, other)>,\n",
       "  '__hash__': None,\n",
       "  '__match_args__': ('dataset',\n",
       "   'target',\n",
       "   'max_num_molecules',\n",
       "   'max_num_conformers',\n",
       "   'train_ratio',\n",
       "   'valid_ratio',\n",
       "   'batch_size',\n",
       "   'hidden_dim',\n",
       "   'num_epochs',\n",
       "   'patience',\n",
       "   'activation',\n",
       "   'seed',\n",
       "   'device',\n",
       "   'dropout',\n",
       "   'scheduler',\n",
       "   'reduce_lr_on_plateau',\n",
       "   'cosine_annealing_lr',\n",
       "   'linear_warmup_cosine_annealing_lr',\n",
       "   'one_cycle_lr',\n",
       "   'learning_rate',\n",
       "   'weight_decay',\n",
       "   'modelfprf',\n",
       "   'model1d',\n",
       "   'model2d',\n",
       "   'model3d',\n",
       "   'model4d')}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54e9f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object at key 'datamodule_hyper_parameters' of type '<class 'dict'>' cannot be pickled.\n",
      "Exception: cannot pickle 'getset_descriptor' object\n",
      "\n",
      "Non-picklable objects:\n",
      "- Key: 'datamodule_hyper_parameters', Type: '<class 'dict'>'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "\n",
    "def identify_non_picklable_objects(checkpoint):\n",
    "    non_picklable_objects = []\n",
    "    for key, value in checkpoint.items():\n",
    "        try:\n",
    "            # Attempt to pickle the object\n",
    "            torch.save(value, io.BytesIO())\n",
    "        except Exception as e:\n",
    "            # If an exception occurs, it means the object is not picklable\n",
    "            non_picklable_objects.append((key, type(value)))\n",
    "            print(f\"Object at key '{key}' of type '{type(value)}' cannot be pickled.\")\n",
    "            print(f\"Exception: {e}\")\n",
    "    return non_picklable_objects\n",
    "\n",
    "# Identify non-picklable objects\n",
    "non_picklable_objects = identify_non_picklable_objects(checkpoint)\n",
    "\n",
    "# Print out non-picklable objects\n",
    "print(\"\\nNon-picklable objects:\")\n",
    "for key, obj_type in non_picklable_objects:\n",
    "    print(f\"- Key: '{key}', Type: '{obj_type}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef5e1720-4340-46a7-8bce-257ae35c71dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Key: 'epoch', Type: '<class 'int'>'\n",
      "- Key: 'global_step', Type: '<class 'int'>'\n",
      "- Key: 'pytorch-lightning_version', Type: '<class 'str'>'\n",
      "- Key: 'state_dict', Type: '<class 'collections.OrderedDict'>'\n",
      "- Key: 'loops', Type: '<class 'dict'>'\n",
      "- Key: 'hparams_name', Type: '<class 'str'>'\n",
      "- Key: 'hyper_parameters', Type: '<class 'dict'>'\n",
      "- Key: 'datamodule_hyper_parameters', Type: '<class 'dict'>'\n"
     ]
    }
   ],
   "source": [
    "for key, obj_type in checkpoint.items():\n",
    "    print(f\"- Key: '{key}', Type: '{type(obj_type)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eaf119da-f36f-4d99-872f-4f1d5ad2c706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__module__': 'config',\n",
       " '__annotations__': {'dataset': str,\n",
       "  'target': str,\n",
       "  'max_num_molecules': int,\n",
       "  'max_num_conformers': int,\n",
       "  'train_ratio': float,\n",
       "  'valid_ratio': float,\n",
       "  'batch_size': int,\n",
       "  'hidden_dim': int,\n",
       "  'num_epochs': int,\n",
       "  'patience': int,\n",
       "  'activation': str,\n",
       "  'seed': int,\n",
       "  'device': str,\n",
       "  'dropout': float,\n",
       "  'scheduler': str,\n",
       "  'reduce_lr_on_plateau': config.ReduceLROnPlateau,\n",
       "  'cosine_annealing_lr': config.CosineAnnealingLR,\n",
       "  'linear_warmup_cosine_annealing_lr': config.LinearWarmupCosineAnnealingLR,\n",
       "  'one_cycle_lr': config.OneCycleLR,\n",
       "  'learning_rate': float,\n",
       "  'weight_decay': float,\n",
       "  'modelfprf': configs.model_fp_rf.ModelFPRF,\n",
       "  'model1d': configs.model_1d.Model1D,\n",
       "  'model2d': configs.model_2d.Model2D,\n",
       "  'model3d': configs.model_3d.Model3D,\n",
       "  'model4d': configs.model_4d.Model4D},\n",
       " 'dataset': 'BDE',\n",
       " 'target': 'BindingEnergy',\n",
       " 'max_num_molecules': None,\n",
       " 'max_num_conformers': 20,\n",
       " 'train_ratio': 0.7,\n",
       " 'valid_ratio': 0.1,\n",
       " 'batch_size': 256,\n",
       " 'hidden_dim': 128,\n",
       " 'num_epochs': 2000,\n",
       " 'patience': 200,\n",
       " 'activation': 'relu',\n",
       " 'seed': 123,\n",
       " 'device': 'cuda:0',\n",
       " 'dropout': 0.5,\n",
       " 'scheduler': None,\n",
       " 'reduce_lr_on_plateau': ReduceLROnPlateau(mode='min', factor=0.8, patience=20),\n",
       " 'cosine_annealing_lr': CosineAnnealingLR(eta_min=1e-06),\n",
       " 'linear_warmup_cosine_annealing_lr': LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000),\n",
       " 'one_cycle_lr': OneCycleLR(max_lr=0.001, steps_per_epoch=100),\n",
       " 'learning_rate': 0.001,\n",
       " 'weight_decay': 0.0001,\n",
       " 'modelfprf': ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True),\n",
       " 'model1d': Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4),\n",
       " 'model2d': Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)),\n",
       " 'model3d': Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)),\n",
       " 'model4d': Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2)),\n",
       " '__dict__': <attribute '__dict__' of 'Config' objects>,\n",
       " '__weakref__': <attribute '__weakref__' of 'Config' objects>,\n",
       " '__doc__': \"Config(dataset: str = 'Kraken', target: str = 'qpoletens_xx', max_num_molecules: int = None, max_num_conformers: int = 20, train_ratio: float = 0.7, valid_ratio: float = 0.1, batch_size: int = 256, hidden_dim: int = 128, num_epochs: int = 2000, patience: int = 200, activation: str = 'relu', seed: int = 123, device: str = 'cuda:5', dropout: float = 0.5, scheduler: str = None, reduce_lr_on_plateau: config.ReduceLROnPlateau = ReduceLROnPlateau(mode='min', factor=0.8, patience=20), cosine_annealing_lr: config.CosineAnnealingLR = CosineAnnealingLR(eta_min=1e-06), linear_warmup_cosine_annealing_lr: config.LinearWarmupCosineAnnealingLR = LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000), one_cycle_lr: config.OneCycleLR = OneCycleLR(max_lr=0.001, steps_per_epoch=100), learning_rate: float = 0.001, weight_decay: float = 0.0001, modelfprf: configs.model_fp_rf.ModelFPRF = ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True), model1d: configs.model_1d.Model1D = Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4), model2d: configs.model_2d.Model2D = Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)), model3d: configs.model_3d.Model3D = Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)), model4d: configs.model_4d.Model4D = Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2)))\",\n",
       " '__dataclass_params__': _DataclassParams(init=True,repr=True,eq=True,order=False,unsafe_hash=False,frozen=False),\n",
       " '__dataclass_fields__': {'dataset': Field(name='dataset',type=<class 'str'>,default='Kraken',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'target': Field(name='target',type=<class 'str'>,default='qpoletens_xx',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'max_num_molecules': Field(name='max_num_molecules',type=<class 'int'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'max_num_conformers': Field(name='max_num_conformers',type=<class 'int'>,default=20,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'train_ratio': Field(name='train_ratio',type=<class 'float'>,default=0.7,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'valid_ratio': Field(name='valid_ratio',type=<class 'float'>,default=0.1,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'batch_size': Field(name='batch_size',type=<class 'int'>,default=256,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'hidden_dim': Field(name='hidden_dim',type=<class 'int'>,default=128,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'num_epochs': Field(name='num_epochs',type=<class 'int'>,default=2000,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'patience': Field(name='patience',type=<class 'int'>,default=200,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'activation': Field(name='activation',type=<class 'str'>,default='relu',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'seed': Field(name='seed',type=<class 'int'>,default=123,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'device': Field(name='device',type=<class 'str'>,default='cuda:5',default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'dropout': Field(name='dropout',type=<class 'float'>,default=0.5,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'scheduler': Field(name='scheduler',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'reduce_lr_on_plateau': Field(name='reduce_lr_on_plateau',type=<class 'config.ReduceLROnPlateau'>,default=ReduceLROnPlateau(mode='min', factor=0.8, patience=20),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'cosine_annealing_lr': Field(name='cosine_annealing_lr',type=<class 'config.CosineAnnealingLR'>,default=CosineAnnealingLR(eta_min=1e-06),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'linear_warmup_cosine_annealing_lr': Field(name='linear_warmup_cosine_annealing_lr',type=<class 'config.LinearWarmupCosineAnnealingLR'>,default=LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'one_cycle_lr': Field(name='one_cycle_lr',type=<class 'config.OneCycleLR'>,default=OneCycleLR(max_lr=0.001, steps_per_epoch=100),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'learning_rate': Field(name='learning_rate',type=<class 'float'>,default=0.001,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'weight_decay': Field(name='weight_decay',type=<class 'float'>,default=0.0001,default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'modelfprf': Field(name='modelfprf',type=<class 'configs.model_fp_rf.ModelFPRF'>,default=ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'model1d': Field(name='model1d',type=<class 'configs.model_1d.Model1D'>,default=Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'model2d': Field(name='model2d',type=<class 'configs.model_2d.Model2D'>,default=Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'model3d': Field(name='model3d',type=<class 'configs.model_3d.Model3D'>,default=Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       "  'model4d': Field(name='model4d',type=<class 'configs.model_4d.Model4D'>,default=Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2)),default_factory=<dataclasses._MISSING_TYPE object at 0x7f61e02dd180>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD)},\n",
       " '__init__': <function config.Config.__init__(self, dataset: str = 'Kraken', target: str = 'qpoletens_xx', max_num_molecules: int = None, max_num_conformers: int = 20, train_ratio: float = 0.7, valid_ratio: float = 0.1, batch_size: int = 256, hidden_dim: int = 128, num_epochs: int = 2000, patience: int = 200, activation: str = 'relu', seed: int = 123, device: str = 'cuda:5', dropout: float = 0.5, scheduler: str = None, reduce_lr_on_plateau: config.ReduceLROnPlateau = ReduceLROnPlateau(mode='min', factor=0.8, patience=20), cosine_annealing_lr: config.CosineAnnealingLR = CosineAnnealingLR(eta_min=1e-06), linear_warmup_cosine_annealing_lr: config.LinearWarmupCosineAnnealingLR = LinearWarmupCosineAnnealingLR(warmup_steps=200, max_epochs=2000), one_cycle_lr: config.OneCycleLR = OneCycleLR(max_lr=0.001, steps_per_epoch=100), learning_rate: float = 0.001, weight_decay: float = 0.0001, modelfprf: configs.model_fp_rf.ModelFPRF = ModelFPRF(n_jobs=8, n_estimators=500, min_samples_leaf=2, min_samples_split=10, min_impurity_decrease=0, warm_start=True), model1d: configs.model_1d.Model1D = Model1D(model='LSTM', input_type='SMILES', embedding_dim=128, num_layers=4, num_heads=4), model2d: configs.model_2d.Model2D = Model2D(model='GIN', gin=GIN(num_layers=6, virtual_node=False), gps=GPS(num_layers=6, walk_length=20, num_heads=4), chemprop=ChemProp(num_layers=6)), model3d: configs.model_3d.Model3D = Model3D(model='PaiNN', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32)), model4d: configs.model_4d.Model4D = Model4D(graph_encoder='SchNet', set_encoder='Attention', schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), transformer=TransformerPooling(num_heads=8, num_layers=2))) -> None>,\n",
       " '__repr__': <function config.Config.__repr__(self)>,\n",
       " '__eq__': <function config.Config.__eq__(self, other)>,\n",
       " '__hash__': None,\n",
       " '__match_args__': ('dataset',\n",
       "  'target',\n",
       "  'max_num_molecules',\n",
       "  'max_num_conformers',\n",
       "  'train_ratio',\n",
       "  'valid_ratio',\n",
       "  'batch_size',\n",
       "  'hidden_dim',\n",
       "  'num_epochs',\n",
       "  'patience',\n",
       "  'activation',\n",
       "  'seed',\n",
       "  'device',\n",
       "  'dropout',\n",
       "  'scheduler',\n",
       "  'reduce_lr_on_plateau',\n",
       "  'cosine_annealing_lr',\n",
       "  'linear_warmup_cosine_annealing_lr',\n",
       "  'one_cycle_lr',\n",
       "  'learning_rate',\n",
       "  'weight_decay',\n",
       "  'modelfprf',\n",
       "  'model1d',\n",
       "  'model2d',\n",
       "  'model3d',\n",
       "  'model4d')}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['datamodule_hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bf021-55a1-41be-9f0b-b15d5c86b7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config.num_epochs):\n",
    "    loss = train(train_loader)\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(loss)\n",
    "    valid_error = eval(valid_loader)\n",
    "\n",
    "    early_stopping(valid_error, model)\n",
    "    if early_stopping.counter == 0:\n",
    "        test_error = eval(test_loader)\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping...')\n",
    "        break\n",
    "\n",
    "    writer.add_scalar(f'Loss_{config.model1d.model}/{config.model1d.input_type}'\n",
    "                      f'/{config.dataset}/{config.target}/train', loss, epoch)\n",
    "    writer.add_scalar(f'Loss_{config.model1d.model}/{config.model1d.input_type}'\n",
    "                      f'/{config.dataset}/{config.target}/valid', valid_error, epoch)\n",
    "    writer.add_scalar(f'Loss_{config.model1d.model}/{config.model1d.input_type}'\n",
    "                      f'/{config.dataset}/{config.target}/test', test_error, epoch)\n",
    "    print(f'Progress: {epoch}/{config.num_epochs}/{loss:.5f}/{valid_error:.5f}/{test_error:.5f}')\n",
    "    res_dict[dataname][algo][d]['loss'].append(loss)\n",
    "    res_dict[dataname][algo][d]['valid_error'].append(valid_error)\n",
    "    res_dict[dataname][algo][d]['test_error'].append(test_error)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "test_error = eval(test_loader)\n",
    "test_r2 = eval_r2(test_loader)\n",
    "print(f'Best validation error: {-early_stopping.best_score:.7f}')\n",
    "print(f'Test error: {test_error:.7f}')\n",
    "print(f'Test r2: {test_r2:.7f}')\n",
    "\n",
    "res_dict[dataname][algo][d]['Test error'] = test_error\n",
    "res_dict[dataname][algo][d]['Test r2'] = test_r2\n",
    "res_dict[dataname][algo][d]['checkpoint']=checkpoint_path\n",
    "\n",
    "\n",
    "#os.remove(checkpoint_path)\n",
    "writer.close()\n",
    "\n",
    "import pickle\n",
    "with open(\"res_dict_1d.pkl\", \"wb\") as f:\n",
    "pickle.dump(res_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
