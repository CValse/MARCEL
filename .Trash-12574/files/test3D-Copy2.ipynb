{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92808ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 13 08:46:33 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1D.0 Off |                    0 |\n",
      "|  0%   18C    P8              15W / 300W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d846afd-a3fd-49fa-ab4f-bb6ef3dc37f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a17adde-c69c-4aa1-827a-8f6508b2fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Requirement already satisfied: torch-geometric in /home/ubuntu/.local/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.4.2)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1050ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Requirement already satisfied: torch-scatter in /home/ubuntu/.local/lib/python3.10/site-packages (2.1.2+pt23cu121)\n",
      "Requirement already satisfied: torch-sparse in /home/ubuntu/.local/lib/python3.10/site-packages (0.6.18+pt23cu121)\n",
      "Requirement already satisfied: torch-cluster in /home/ubuntu/.local/lib/python3.10/site-packages (1.6.3+pt23cu121)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cee94b-989c-4354-a213-5f6d29e4f2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ase in /home/ubuntu/.local/lib/python3.10/site-packages (3.22.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (3.8.4)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (4.51.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c377884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pytorch-lightning\n",
    "#!pip install transformers\n",
    "#!pip install lightning-bolts\n",
    "#!pip install lightning-utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45edc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import asdict\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "# from pl_bolts.optimizers import LinearWarmupCosineAnnealingLR\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "from config import Config\n",
    "from data.ee import EE\n",
    "from data.bde import BDE\n",
    "from data.drugs import Drugs\n",
    "from data.kraken import Kraken\n",
    "from happy_config import ConfigLoader\n",
    "from loaders.samplers import EnsembleSampler, EnsembleMultiBatchSampler\n",
    "from loaders.multibatch import MultiBatchLoader\n",
    "from utils.early_stopping import EarlyStopping, generate_checkpoint_filename\n",
    "\n",
    "from models.model_3d import Model3D\n",
    "from models.models_3d.chiro import ChIRo\n",
    "from models.models_3d.painn import PaiNN\n",
    "from models.models_3d.schnet import SchNet\n",
    "from models.models_3d.gemnet import GemNetT\n",
    "from models.models_3d.dimenet import DimeNet, DimeNetPlusPlus\n",
    "from models.models_3d.clofnet import ClofNet\n",
    "from models.models_3d.leftnet import LEFTNet\n",
    "from models.models_3d.chytorch_discrete import ChytorchDiscrete\n",
    "#from models.models_3d.chytorch_conformer import ChytorchConformer\n",
    "\n",
    "import pickle\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b09137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CyclicLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8091e7ee-675d-485d-9b73-e4f9a05565a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_3d import GroupedScaledMAELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e757818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "import os\n",
    "import numpy as np\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "torch.cuda.empty_cache()\n",
    "#print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If you are using a GPU, you should also set the seed for CUDA operations\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(seed)\n",
    "################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee749ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_torch(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the R-squared score.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (torch.Tensor): The true target values.\n",
    "        y_pred (torch.Tensor): The predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        float: The R-squared score.\n",
    "    \"\"\"\n",
    "    # Calculate the mean of the true target values\n",
    "    y_mean = torch.mean(y_true)\n",
    "    # Calculate the total sum of squares (TSS)\n",
    "    tss = torch.sum((y_true - y_mean) ** 2)\n",
    "    # Calculate the residual sum of squares (RSS)\n",
    "    rss = torch.sum((y_true - y_pred) ** 2)\n",
    "    # Calculate R-squared score\n",
    "    r2 = 1 - rss / tss\n",
    "\n",
    "    return r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ff1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, hparams, dataset=None, multitask = False):\n",
    "        super().__init__()\n",
    "        self.hparams.update(hparams.__dict__) if hasattr(hparams, \"__dict__\") else self.hparams.update(hparams)\n",
    "        self._saved_dataloaders = dict()\n",
    "        self.dataset = dataset\n",
    "        self.multitask = multitask\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.variable_name = None\n",
    "            unique_variables = 1\n",
    "\n",
    "            if self.hparams.dataset == 'Drugs':\n",
    "                dataset = Drugs('/mnt/data/MARCEL/datasets/Drugs', max_num_conformers=self.hparams.max_num_conformers).shuffle()\n",
    "            elif self.hparams.dataset == 'Kraken':\n",
    "                dataset = Kraken('/mnt/data/MARCEL/datasets/Kraken', max_num_conformers=self.hparams.max_num_conformers).shuffle()\n",
    "            elif self.hparams.dataset == 'BDE':\n",
    "                dataset = BDE('/mnt/data/MARCEL/datasets/BDE').shuffle()\n",
    "                self.variable_name = 'is_ligand'\n",
    "                unique_variables = 2\n",
    "            elif self.hparams.dataset == 'EE':\n",
    "                dataset = EE('/mnt/data/MARCEL/datasets/EE', max_num_conformers=self.hparams.max_num_conformers).shuffle()\n",
    "                self.variable_name = 'config_id'\n",
    "                unique_variables = 2\n",
    "\n",
    "            if self.multitask:\n",
    "                self.hparams.target = 'all'\n",
    "                pass\n",
    "            else:\n",
    "                #autoscaling\n",
    "                target_id = dataset.descriptors.index(self.hparams.target)\n",
    "                dataset.y = dataset.y[:, target_id]\n",
    "                #mean = dataset.y.mean(dim=0, keepdim=True)\n",
    "                #std = dataset.y.std(dim=0, keepdim=True)\n",
    "                #dataset.y = ((dataset.y - mean) / std).to('cuda')\n",
    "                #mean = mean.to('cuda')\n",
    "                #std = std.to('cuda')\n",
    "            \n",
    "                #data.dataset.data.y = data.dataset.y\n",
    "            \n",
    "            self.dataset = dataset\n",
    "            self.max_atomic_num = self.dataset.data.x[:, 0].max().item() + 1\n",
    "            self.unique_variables = unique_variables\n",
    "            print('--done---')\n",
    "\n",
    "    def split_compute(self):\n",
    "\n",
    "        split = self.dataset.get_idx_split(train_ratio=self.hparams.train_ratio, \n",
    "                                      valid_ratio=self.hparams.valid_ratio, \n",
    "                                      seed=self.hparams.seed)\n",
    "        self.train_dataset = self.dataset[split['train']]\n",
    "        self.valid_dataset = self.dataset[split['valid']]\n",
    "        self.test_dataset = self.dataset[split['test']]\n",
    "\n",
    "        print(f'{len(self.train_dataset)} training data, {len(self.test_dataset)} test data and {len(self.valid_dataset)} validation data')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._get_dataloader(self.train_dataset, \"train\")\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._get_dataloader(self.valid_dataset, \"val\")\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._get_dataloader(self.test_dataset, \"test\")\n",
    "    \n",
    "    def _get_dataloader(self, dataset, stage, store_dataloader=True):\n",
    "        store_dataloader = store_dataloader\n",
    "        \n",
    "        if stage in self._saved_dataloaders and store_dataloader:\n",
    "            return self._saved_dataloaders[stage]\n",
    "\n",
    "        if self.hparams.model3d_augmentation:\n",
    "            strategy = 'random'\n",
    "        else:\n",
    "            strategy = 'first'\n",
    "            \n",
    "        if stage == \"train\":\n",
    "            shuffle=True                              \n",
    "        else:\n",
    "            shuffle=False\n",
    "            if stage == \"train\"=='test':\n",
    "                strategy = 'first'\n",
    "\n",
    "        if self.variable_name is None:\n",
    "            dl = DataLoader(dataset, batch_sampler=EnsembleSampler(dataset, \n",
    "                                                                   batch_size=self.hparams.batch_size, \n",
    "                                                                   strategy=strategy, \n",
    "                                                                   shuffle=shuffle),\n",
    "                           num_workers=20)\n",
    "        else:\n",
    "            dl = MultiBatchLoader(dataset, batch_sampler=EnsembleMultiBatchSampler(dataset, \n",
    "                                                                                   batch_size=self.hparams.batch_size, \n",
    "                                                                                   strategy=strategy, \n",
    "                                                                                   shuffle=shuffle, \n",
    "                                                                                   variable_name=self.variable_name),\n",
    "                                 num_workers=20)\n",
    "        if store_dataloader:\n",
    "            self._saved_dataloaders[stage] = dl\n",
    "        return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5796c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_pnorm(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Computes the norm of the parameters of a model.\n",
    "    :param model: A PyTorch model.\n",
    "    :return: The norm of the parameters of the model.\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum([p.norm().item() ** 2 for p in model.parameters() if p.requires_grad]))\n",
    "\n",
    "\n",
    "def compute_gnorm(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Computes the norm of the gradients of a model.\n",
    "    :param model: A PyTorch model.\n",
    "    :return: The norm of the gradients of the model.\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum([p.grad.norm().item() ** 2 for p in model.parameters() if p.grad is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLM(LightningModule):\n",
    "    def __init__(self, max_atomic_num=None, whole_dataset = None, unique_variables=1, multitask = False, **kwargs):\n",
    "        super().__init__()\n",
    "        #self.kwargs.update(kwargs.__dict__) if hasattr(kwargs, \"__dict__\") else self.kwargs.update(kwargs)\n",
    "        print(kwargs.get('model3d'))\n",
    "        if kwargs.get('model3d').model == 'SchNet':\n",
    "            model_factory = lambda: SchNet(max_atomic_num=max_atomic_num, \n",
    "                                           **asdict(kwargs.get('model3d').schnet))\n",
    "        elif kwargs.get('model3d').model == 'DimeNet':\n",
    "            model_factory = lambda: DimeNet(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').dimenet))\n",
    "        elif kwargs.get('model3d').model == 'DimeNet++':\n",
    "            model_factory = lambda: DimeNetPlusPlus(max_atomic_num=max_atomic_num, \n",
    "                                                    **asdict(kwargs.get('model3d').dimenetplusplus))\n",
    "        elif kwargs.get('model3d').model == 'GemNet':\n",
    "            model_factory = lambda: GemNetT(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').gemnet))\n",
    "        elif kwargs.get('model3d').model == 'ChIRo':\n",
    "            model_factory = lambda: ChIRo(**asdict(kwargs.get('model3d').chiro))\n",
    "            \n",
    "        elif kwargs.get('model3d').model == 'PaiNN':\n",
    "            model_factory = lambda: PaiNN(max_atomic_num=max_atomic_num, \n",
    "                                          **asdict(kwargs.get('model3d').painn))\n",
    "        elif kwargs.get('model3d').model == 'ClofNet':\n",
    "            model_factory = lambda: ClofNet(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').clofnet))\n",
    "        elif kwargs.get('model3d').model == 'LEFTNet':\n",
    "            model_factory = lambda: LEFTNet(max_atomic_num=max_atomic_num, \n",
    "                                            **asdict(kwargs.get('model3d').leftnet))\n",
    "        elif kwargs.get('model3d').model == 'ChytorchDiscrete':\n",
    "            model_factory = lambda: ChytorchDiscrete(max_neighbors=max_atomic_num, \n",
    "                                                     **asdict(kwargs.get('model3d').chytorch_discrete))\n",
    "        elif kwargs.get('model3d').model == 'ChytorchConformer':\n",
    "            model_factory = lambda: ChytorchConformer(**asdict(kwargs.get('model3d').chytorch_conformer))\n",
    "            \n",
    "        elif kwargs.get('model3d').model == 'ChytorchRotary':\n",
    "            model_factory = lambda: ChytorchRotary(max_neighbors=max_atomic_num, \n",
    "                                                   **asdict(kwargs.get('model3d').chytorch_rotary))\n",
    "        self.device_= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.multitask = multitask\n",
    "        self.net = Model3D(model_factory, \n",
    "                           hidden_dim=kwargs.get('hidden_dim'), \n",
    "                           out_dim=1,\n",
    "                           unique_variables=unique_variables, \n",
    "                           device='cuda',\n",
    "                           multitask=self.multitask).to('cuda')\n",
    "        \n",
    "        self.whole_dataset = whole_dataset\n",
    "\n",
    "        if self.multitask:\n",
    "            self.loss_fn = GroupedScaledMAELoss(torch.ones(self.whole_dataset.y.shape[1], \n",
    "                                                           dtype=torch.long))\n",
    "        else:\n",
    "            self.loss_fn = nn.MSELoss() #LOGITS #GroupedScaledMAELoss(torch.ones(4, dtype=torch.long))\n",
    "        \n",
    "        self.lr = kwargs.get('learning_rate')\n",
    "        self.wd = kwargs.get('learning_rate')\n",
    "        \n",
    "        self._reset_losses_dict()\n",
    "        self._reset_inference_results()\n",
    "        self.save_hyperparameters(ignore=[\"cosine_annealing_lr\",\"linear_warmup_cosine_annealing_lr\",\n",
    "                                          \"model1d\",\"model2d\",\"model3d\",\"model4d\",\"modelfprf\",\"one_cycle_lr\",\n",
    "                                          \"reduce_lr_on_plateau\",\"whole_dataset\",\"device\",\"scheduler\"])\n",
    "\n",
    "    def forward(self, batch):\n",
    "        out = self.net(batch)\n",
    "        return out\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        o = AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        s = CyclicLR(o, self.lr, 2e-4, 1000, mode='triangular', cycle_momentum=False)\n",
    "        # instantiate the WeakMethod in the lr scheduler object into the custom scale function attribute\n",
    "        #s._scale_fn_custom = s._scale_fn_ref()\n",
    "        # remove the reference so there are no more WeakMethod references in the object\n",
    "        #s._scale_fn_ref = None\n",
    "        return [o], [{'scheduler': s, 'interval': 'step', 'name': 'lr_scheduler'}]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pnorm = compute_pnorm(self.net)\n",
    "        gnorm = compute_gnorm(self.net)\n",
    "        self.log(f'(training) pnorm', pnorm)\n",
    "        self.log(f'(training) gnorm', gnorm)\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "        \n",
    "    def step(self, batch, stage):\n",
    "        start = time()\n",
    "        if type(batch) is not list:\n",
    "            batch = [batch]\n",
    "        molecule_idx = batch[0].molecule_idx.to('cuda')\n",
    "        dataset = self.whole_dataset.y.to('cuda')\n",
    "        targets = dataset[molecule_idx].squeeze()\n",
    "\n",
    "        with torch.set_grad_enabled(stage == \"train\"):\n",
    "            if self.multitask:\n",
    "                batch_multi = batch.copy()\n",
    "                if self.whole_dataset.y.shape[1]==1:\n",
    "                    print('only one property-switch to singletask')\n",
    "                else:\n",
    "                    for cnt, bat_i in enumerate(batch_multi):\n",
    "                        for i in range(self.whole_dataset.y.shape[1]-1):\n",
    "                            bat_tmp = batch_multi[cnt].batch#.detach().clone()\n",
    "                            batch_multi[cnt] = batch_multi[cnt].concat(batch[cnt])\n",
    "                            batch_multi[cnt].batch = torch.hstack([bat_tmp, batch[cnt].batch + (bat_tmp.max()+1)])\n",
    "                \n",
    "                targets_flat = targets.flatten()\n",
    "                prompts = torch.tensor([i for i in range(data.dataset.y.shape[1])]*targets.shape[0],\n",
    "                                      dtype=torch.int32,\n",
    "                                      device=targets.device)\n",
    "                for cnt, bat_i in enumerate(batch_multi):\n",
    "                    batch_multi[cnt].tokens = prompts\n",
    "                pred = self(batch_multi)\n",
    "                loss = self.loss_fn(pred.squeeze(), targets_flat, prompts)\n",
    "                if stage == \"test\":\n",
    "                    self.inference_results['token'].append(prompts.squeeze())\n",
    "                    self.inference_results['y_pred'].append(pred.squeeze())\n",
    "                    self.inference_results['y_true'].append(targets_flat.squeeze())\n",
    "                    return None\n",
    "                r2=r2_score_torch(targets_flat.cpu(),pred.squeeze().cpu().detach())\n",
    "            else:\n",
    "                pred = self(batch)\n",
    "                loss = self.loss_fn(pred.squeeze(), targets)\n",
    "            \n",
    "                if stage == \"test\":\n",
    "                    self.inference_results['y_pred'].append(pred.squeeze())\n",
    "                    self.inference_results['y_true'].append(targets.squeeze())\n",
    "                    return None\n",
    "\n",
    "                r2=r2_score_torch(targets.cpu(),pred.squeeze().cpu().detach())\n",
    "\n",
    "            self.logging_info[f'{stage}_loss'].append(loss.item())\n",
    "            self.logging_info[f'{stage}_r2'].append(r2)\n",
    "            self.logging_info[f'{stage}_time'].append(time()-start)\n",
    "            \n",
    "            if stage == 'train':\n",
    "                self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], on_step=True, on_epoch=False, prog_bar=True, logger=True, sync_dist=True)\n",
    "                self.log(f'{stage}_step_loss', loss.item(), on_step=True, on_epoch=False, prog_bar=True, logger=True, sync_dist=True)\n",
    "            #model.save_checkpoint('checkpoint.pth')\n",
    "            return loss\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self.trainer.sanity_checking:                    \n",
    "            result_dict = {\n",
    "                \"epoch\": float(self.current_epoch),\n",
    "                \"train_epoch_loss\": torch.tensor(self.logging_info[\"train_loss\"]).mean().item(),\n",
    "                \"train_epoch_r2\": torch.tensor(self.logging_info[\"train_r2\"]).mean().item(),\n",
    "                \"val_epoch_loss\": torch.tensor(self.logging_info[\"val_loss\"]).mean().item(),\n",
    "                \"val_epoch_r2\": torch.tensor(self.logging_info[\"val_r2\"]).mean().item(),\n",
    "                \"train_epoch_time\": sum(self.logging_info[\"train_time\"]),\n",
    "                \"val_epoch_time\": sum(self.logging_info[\"val_time\"]),\n",
    "                }\n",
    "            self.log_dict(result_dict, logger=True, sync_dist=True)\n",
    "            \n",
    "        self._reset_losses_dict()\n",
    "    \n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        for key in self.inference_results.keys():\n",
    "            self.inference_results[key] = torch.cat(self.inference_results[key], dim=0)\n",
    "    \n",
    "    def _reset_losses_dict(self):\n",
    "        self.logging_info = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_r2\": [], \n",
    "            \"train_mse\": [], \n",
    "            \"val_loss\": [],\n",
    "            \"val_r2\": [],\n",
    "            \"train_sample_size\": [], \n",
    "            \"val_sample_size\": [],\n",
    "            \"train_time\": [],\n",
    "            \"val_time\": [],\n",
    "        }\n",
    "        \n",
    "    def _reset_inference_results(self):\n",
    "        self.inference_results = {'token': [],\n",
    "                                  'y_pred': [],\n",
    "                                  'y_true': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c7d3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'Kraken'  #['BDE','Drugs','Kraken'],\n",
    "target = 'sterimol_B5' #[['BindingEnergy'],['ip', 'ea', 'chi'],['sterimol_B5', 'sterimol_L', 'sterimol_burB5', 'sterimol_burL']]\n",
    "modeltype = 'ChIRo'  #['SchNet','GemNet','PaiNN','ClofNet','LEFTNet','DimeNet++','ChytorchDiscrete', 'ChIRo']  #oom: 'GemNet'\n",
    "\n",
    "writer = SummaryWriter(log_dir='/mnt/code/logs/')\n",
    "#loader = ConfigLoader(model=Config, config='params/params_1d.json')\n",
    "#config = loader()\n",
    "\n",
    "config = Config\n",
    "config.dataset = dataname\n",
    "config.target = target\n",
    "config.device = 'cuda:0'\n",
    "\n",
    "\n",
    "#config.hidden_dim =128\n",
    "#config.dropout = 0.5\n",
    "\n",
    "#config.train_ratio = 0.7\n",
    "#config.valid_ratio = 0.1\n",
    "config.batch_size = 64 #256\n",
    "#config.patience = 200\n",
    "\n",
    "#config.learning_rate = 0.00001\n",
    "#config.weight_decay = 1e-4\n",
    "#config.scheduler = None\n",
    "#config.reduce_lr_on_plateau = ReduceLROnPlateau()\n",
    "\n",
    "#config.num_epochs = 2000\n",
    "#config.cosine_annealing_lr = CosineAnnealingLR()\n",
    "#config.linear_warmup_cosine_annealing_lr = LinearWarmupCosineAnnealingLR()\n",
    "\n",
    "\n",
    "#not used in 1d\n",
    "\n",
    "#config.one_cycle_lr = OneCycleLR()\n",
    "#config.seed = 123\n",
    "#activation = 'relu'\n",
    "\n",
    "######3DMODEL\n",
    "config.model3d.model=modeltype\n",
    "config.model3d.augmentation = True\n",
    "\n",
    "#config.model3d.schnet = SchNet()\n",
    "#config.model3d.dimenet = DimeNet()\n",
    "#config.model3d.dimenetplusplus = DimeNetPlusPlus()\n",
    "#config.model3d.gemnet = GemNet()\n",
    "#config.model3d.painn = PaiNN()\n",
    "#config.model3d.clofnet = ClofNet()\n",
    "#config.model3d.leftnet= LEFTNet()\n",
    "#config.model3d.chytorch_discrete = ChytorchDiscrete()\n",
    "#config.model3d.chytorch_conformer = ChytorchConformer()\n",
    "#config.model3d.chytorch_rotary = ChytorchRotary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce3a7da-8b67-4b4c-98dc-c92f28bcc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_to_dict(config_class):\n",
    "    config_dict = {}\n",
    "    for attr_name in dir(config_class):\n",
    "        if not attr_name.startswith(\"__\") and not callable(getattr(config_class, attr_name)):\n",
    "            #if attr_name=='model1d':\n",
    "             #   attr_val = getattr(config_class, attr_name)\n",
    "             #   for subattr, subvalue in zip(['model', 'input_type', 'embedding_dim', 'num_layers', 'num_heads'],\n",
    "             #                                [attr_val.model, attr_val.input_type, attr_val.embedding_dim, \n",
    "             #                                 attr_val.num_layers, attr_val.num_heads]):\n",
    "             #       config_dict[f'{attr_name}_{subattr}'] = subvalue\n",
    "            #elif attr_name in ['model2d','model3d','model4d','modelfprf',\n",
    "            #                   'linear_warmup_cosine_annealing_lr','cosine_annealing_lr',\n",
    "            #                   'reduce_lr_on_plateau','one_cycle_lr']:\n",
    "            #    pass\n",
    "            #else:\n",
    "            config_dict[attr_name] = getattr(config_class, attr_name)\n",
    "    return config_dict\n",
    "config_dict = config_to_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d61b8117-6368-49f0-bab2-1b12bea10ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subkeys = [\"dataset\",\n",
    "           \"max_num_conformers\",\n",
    "           \"target\",\n",
    "           \"train_ratio\",\n",
    "           \"valid_ratio\",\n",
    "           \"seed\",\n",
    "           \"model3d\", #.augmentation\"\n",
    "           \"batch_size\"]\n",
    "config_dict_datamodule = {}\n",
    "for k,v in config_dict.items():\n",
    "    if k in subkeys:\n",
    "        if k==\"model3d\":\n",
    "            config_dict_datamodule[f'{k}_augmentation']=config_dict[k].augmentation\n",
    "        else:\n",
    "            config_dict_datamodule[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d24cfce3-1969-43a4-809d-36d81a4c8508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'dataset': 'Kraken',\n",
       " 'max_num_conformers': 20,\n",
       " 'model3d_augmentation': True,\n",
       " 'seed': 123,\n",
       " 'target': 'sterimol_B5',\n",
       " 'train_ratio': 0.7,\n",
       " 'valid_ratio': 0.1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict_datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cb75383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--done---\n",
      "10939 training data, 3344 test data and 1466 validation data\n"
     ]
    }
   ],
   "source": [
    "data = DataModule(config_dict_datamodule, multitask = False)\n",
    "data.prepare_data()\n",
    "data.split_compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a448976-50f0-4af0-9e20-4498cb7cd5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[798044, 9], edge_index=[2, 1647430], edge_attr=[1647430, 3], pos=[798044, 3], name=[15749], id=[15749], smiles=[15749], y=[15749, 4], molecule_idx=[15749])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2913d700-eb42-4623-b1e8-d1a09da44cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15749"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297ec960-ffa3-4150-9277-6991cce1a293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kraken: 1552 molecules, 15749 conformers"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "262f115e-1202-451d-b6e1-9e943fbaf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e370101b-64ad-422c-b509-94e0804260fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "databatch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "184bd84c-8fb5-44f0-b466-d8a84b61a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(databatch) is not list:\n",
    "    batch = [databatch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c8fd69-9433-47a5-8a84-c870c99d6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_idx = batch[0].molecule_idx.to('cuda')\n",
    "dataset = data.dataset.y.to('cuda')\n",
    "targets = dataset[molecule_idx].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86e6e36f-a5e3-45fb-85e4-c1a7f0a3eb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "138e149e-3069-4473-8ec1-3fba4f77ed82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset.y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b07feefc-7d32-4ef9-80d1-fcf58d798448",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_multi = batch.copy()\n",
    "if data.dataset.y.shape[1]==1:\n",
    "    print('only one property-switch to singletask')\n",
    "else:\n",
    "    for cnt, bat_i in enumerate(batch_multi):\n",
    "        for i in range(data.dataset.y.shape[1]-1):\n",
    "            bat_tmp = batch_multi[cnt].batch#.detach().clone()\n",
    "            batch_multi[cnt] = batch_multi[cnt].concat(batch[cnt])\n",
    "            batch_multi[cnt].batch = torch.hstack([bat_tmp, batch[cnt].batch + (bat_tmp.max()+1)])\n",
    "\n",
    "targets_flat = targets.flatten()\n",
    "prompts = torch.tensor([i for i in range(data.dataset.y.shape[1])]*targets.shape[0],\n",
    "                      dtype=torch.int32,\n",
    "                      device=targets.device)\n",
    "for cnt, bat_i in enumerate(batch_multi):\n",
    "    batch_multi[cnt].tokens = prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc7d98bd-9628-449b-bdc2-4b88c5694649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2,  ..., 1, 2, 3], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_multi[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "604ee11c-6511-4e69-9564-0a60802adb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z, hgs, pos, bat, tokens = batch_multi[0].x[:, 0]+1, batch_multi[0].x[:, 4], batch_multi[0].pos, batch_multi[0].batch, batch_multi[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5d217f9-d6d7-4ae8-a7eb-a5f274cc722f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([45812]),\n",
       " torch.Size([45812]),\n",
       " torch.Size([45812, 3]),\n",
       " torch.Size([45812]),\n",
       " torch.Size([1024]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape, hgs.shape, pos.shape, bat.shape, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db8e1ee1-19c2-41dd-abd8-dd8c3f699ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.zeros_like(z) if bat is None else bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f744cd2c-c57d-44a9-98e3-a416d1755a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = max(batch.bincount())\n",
    "num_batches = max(batch)+1\n",
    "batched_z = torch.zeros(num_batches, N, dtype=torch.int32, device=z.device)\n",
    "batched_hgs =torch.zeros(num_batches, N, dtype=torch.int32, device=z.device)\n",
    "batched_dist = torch.zeros(num_batches, N+1, N+1, dtype=torch.int32, device=z.device)\n",
    "\n",
    "short_cutoff =.9\n",
    "long_cutoff = 5.\n",
    "precision = .05\n",
    "_bins = np.arange(short_cutoff - 3 * precision, long_cutoff, precision)\n",
    "_bins[:3] = [-1, 0, .01]  # trick for self-loop coding\n",
    "max_distance = len(_bins) - 2  # param for MoleculeEncoder\n",
    "\n",
    "# Populate the batched_tensor\n",
    "for i in range(num_batches):\n",
    "    indices = (batch == i).nonzero(as_tuple=True)[0]\n",
    "    batched_z[i, :len(indices)] = z[indices] + 2\n",
    "    batched_hgs[i, :len(indices)] = hgs[indices] + 2\n",
    "    pos_i = pos[indices,:]\n",
    "    diff = pos_i[None, :, :] - pos_i[:, None, :]  # NxNx3\n",
    "    dist = (diff ** 2).sum(dim=-1).sqrt()  # BxNxN\n",
    "\n",
    "    dist = np.digitize(dist.cpu(), _bins)\n",
    "    dist = torch.tensor(dist, dtype=torch.int32, device = z.device)\n",
    "    \n",
    "    tmp = torch.ones((len(indices)+1, len(indices)+1), dtype=torch.int32)\n",
    "    tmp[1:, 1:] = dist\n",
    "    \n",
    "    batched_dist[i, :len(indices)+1, :len(indices)+1] = tmp\n",
    "    diagonal = torch.diag(batched_dist[i, :, :])\n",
    "    zero_diagonal_indices = torch.where(diagonal == 0)[0]\n",
    "    batched_dist[i, zero_diagonal_indices, zero_diagonal_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38309626-ab8b-43bb-b2a1-6e4b59a42f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 1 cls\n",
    "atoms = torch.ones(batched_z.shape[0], batched_z.shape[1] + 1, dtype=torch.int32, device=z.device)\n",
    "neighbors = torch.zeros(batched_hgs.shape[0], batched_hgs.shape[1] + 1, dtype=torch.int32, device=z.device)\n",
    "#sum3 from default MAECEL\n",
    "atoms[:,1:] = batched_z.int()\n",
    "neighbors[:,1:] = batched_hgs.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c665314-3320-4f9b-8ace-a47211bfad43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  8,  9,  ...,  0,  0,  0],\n",
       "        [ 1,  8,  9,  ...,  0,  0,  0],\n",
       "        [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "        [ 1,  8, 10,  ...,  0,  0,  0],\n",
       "        [ 1,  8,  8,  ...,  0,  0,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f78dc2d9-98e5-49e4-8801-4768ea49a0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 2,  ..., 0, 0, 0],\n",
       "        [0, 2, 2,  ..., 0, 0, 0],\n",
       "        [0, 2, 2,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 2, 2,  ..., 0, 0, 0],\n",
       "        [0, 2, 2,  ..., 0, 0, 0],\n",
       "        [0, 2, 2,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e010721-86a7-4ee5-8914-6109204d14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokens is None:\n",
    "    pass\n",
    "else:\n",
    "    atoms[:,0]=tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27bf0173-7710-4f62-8522-4c6505bebb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 131])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "292bb6dd-4461-4caa-863f-89cdc51c66ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  8,  9,  ...,  0,  0,  0],\n",
       "        [ 1,  8,  9,  ...,  0,  0,  0],\n",
       "        [ 2,  8,  8,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "        [ 2,  8, 10,  ...,  0,  0,  0],\n",
       "        [ 3,  8,  8,  ...,  0,  0,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cfcd21-646e-42b9-abb1-a9a920b0f08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7b37b-d9b9-4a76-a507-17d7fdfe3343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24d052c-c317-4703-991f-e577c8b5dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#databatch = [databatch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cf296d0-dbdb-424e-aac4-f4853ec23c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z, hgs, pos, bat = databatch[0].x[:, 0]+1, databatch[0].x[:, 4], databatch[0].pos, databatch[0].batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5435ff99-f4f4-482b-a442-cfbb608bf555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z.shape, hgs.shape, pos.shape, bat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3edb7560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model3D(model='ChIRo', augmentation=True, schnet=SchNet(hidden_dim=128, num_filters=5, num_interactions=6, num_gaussians=50, cutoff=10, readout='mean', dipole=False), dimenet=DimeNet(hidden_channels=128, out_channels=128, num_blocks=6, num_bilinear=8, num_spherical=7, num_radial=6), dimenetplusplus=DimeNetPlusPlus(hidden_channels=128, out_channels=128, num_blocks=4, int_emb_size=64, basis_emb_size=8, out_emb_channels=256, num_spherical=7, num_radial=6), gemnet=GemNet(num_spherical=7, num_radial=6, num_blocks=4, emb_size_atom=128, emb_size_edge=128, emb_size_trip=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_bil_trip=64, num_before_skip=1, num_after_skip=1, num_concat=1, num_atoms=1, num_atom=2, bond_feat_dim=0), painn=PaiNN(hidden_dim=128, num_interactions=6, num_rbf=64, cutoff=12.0, readout='add', shared_interactions=False, shared_filters=False), clofnet=ClofNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), leftnet=LEFTNet(cutoff=6.5, num_layers=6, hidden_channels=128, num_radial=32), chytorch_discrete=ChytorchDiscrete(max_distance=83, d_model=128, nhead=16, num_layers=8, dim_feedforward=512, shared_weights=False, dropout=0.1, norm_first=True, post_norm=True, zero_bias=True), chytorch_conformer=ChytorchConformer(nkernel=128, shared_layers=True, d_model=128, nhead=16, num_layers=8, dim_feedforward=512, dropout=0.1, norm_first=True, post_norm=True), chytorch_rotary=ChytorchRotary(d_model=128, nhead=16, num_layers=8, dim_feedforward=512, shared_weights=False, dropout=0.1, norm_first=False, post_norm=False))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model3D' object has no attribute 'chiro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModelLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_atomic_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_atomic_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwhole_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43munique_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmultitask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 41\u001b[0m, in \u001b[0;36mModelLM.__init__\u001b[0;34m(self, max_atomic_num, whole_dataset, unique_variables, multitask, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultitask \u001b[38;5;241m=\u001b[39m multitask\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[43mModel3D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                   \u001b[49m\u001b[43munique_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmultitask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultitask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhole_dataset \u001b[38;5;241m=\u001b[39m whole_dataset\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultitask:\n",
      "File \u001b[0;32m/mnt/code/benchmarks/models/model_3d.py:15\u001b[0m, in \u001b[0;36mModel3D.__init__\u001b[0;34m(self, model_factory, hidden_dim, out_dim, device, unique_variables, multitask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_factory, hidden_dim, out_dim, device, unique_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, multitask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m---> 15\u001b[0m         [model_factory() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(unique_variables)])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#self.linear = torch.nn.Linear(hidden_dim * unique_variables, out_dim)#to symbolic\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m Symbolic(hidden_dim \u001b[38;5;241m*\u001b[39m unique_variables, \u001b[38;5;241m1\u001b[39m, bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m#(hidden_dim * unique_variables, out_dim)#to symbolic\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/code/benchmarks/models/model_3d.py:15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_factory, hidden_dim, out_dim, device, unique_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, multitask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m---> 15\u001b[0m         [\u001b[43mmodel_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(unique_variables)])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#self.linear = torch.nn.Linear(hidden_dim * unique_variables, out_dim)#to symbolic\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m Symbolic(hidden_dim \u001b[38;5;241m*\u001b[39m unique_variables, \u001b[38;5;241m1\u001b[39m, bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m#(hidden_dim * unique_variables, out_dim)#to symbolic\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m, in \u001b[0;36mModelLM.__init__.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     model_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: GemNetT(max_atomic_num\u001b[38;5;241m=\u001b[39mmax_atomic_num, \n\u001b[1;32m     17\u001b[0m                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39masdict(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgemnet))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChIRo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     model_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: ChIRo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39masdict(\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel3d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchiro\u001b[49m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaiNN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     22\u001b[0m     model_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: PaiNN(max_atomic_num\u001b[38;5;241m=\u001b[39mmax_atomic_num, \n\u001b[1;32m     23\u001b[0m                                   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39masdict(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mpainn))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model3D' object has no attribute 'chiro'"
     ]
    }
   ],
   "source": [
    "model = ModelLM(max_atomic_num=data.max_atomic_num, \n",
    "                whole_dataset = data.dataset, \n",
    "                unique_variables=data.unique_variables, \n",
    "                multitask = False, **config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e82ee2b-5cfe-4480-95d4-d6e3a5cd3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model._log_hyperparams = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69530b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PARAMS = 1610720\n"
     ]
    }
   ],
   "source": [
    "print(f'#PARAMS = {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffad2ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLM(\n",
       "  (net): Model3D(\n",
       "    (models): ModuleList(\n",
       "      (0): ChytorchDiscrete(\n",
       "        (embedding): EmbeddingBag(\n",
       "          (atoms_encoder): Embedding(121, 128, padding_idx=0)\n",
       "          (neighbors_encoder): Embedding(56, 128, padding_idx=0)\n",
       "        )\n",
       "        (distance_encoder): Embedding(86, 16, padding_idx=1, neg_inf_idx=0)\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-7): 8 x EncoderLayer(\n",
       "            (self_attn): GraphormerAttention(\n",
       "              (qkv_proj): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (o_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (activation): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Symbolic(\n",
       "      (head): Linear(in_features=128, out_features=1, bias=False)\n",
       "      (scaler): Linear(in_features=128, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): GroupedScaledMAELoss()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a20c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = f\"tmp_{dataname}_{target}_{modeltype}_multitask_v0\"\n",
    "\n",
    "dir_load_model = None\n",
    "log_dir_folder = '/mnt/code/logs/'\n",
    "log_dir_folder = os.path.join(log_dir_folder, dir_name)\n",
    "if os.path.exists(log_dir_folder):\n",
    "    if os.path.exists(os.path.join(log_dir_folder, \"last.ckpt\")):\n",
    "        dir_load_model = os.path.join(log_dir_folder, \"last.ckpt\")\n",
    "    csv_path = os.path.join(log_dir_folder, \"metrics.csv\")\n",
    "    while os.path.exists(csv_path):\n",
    "        csv_path = csv_path + '.bak'\n",
    "    if os.path.exists(os.path.join(log_dir_folder, \"metrics.csv\")):\n",
    "        os.rename(os.path.join(log_dir_folder, \"metrics.csv\"), csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50c750fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_monitor = \"val_epoch_loss\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=log_dir_folder,\n",
    "    monitor=metric_to_monitor,\n",
    "    mode = 'min',\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    every_n_epochs=5,\n",
    "    save_weights_only=True,\n",
    "    verbose=True,\n",
    "    filename=\"best-model-{epoch}-{val_epoch_loss:.4f}\",\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = early_stop_callback = EarlyStopping(\n",
    "        monitor=metric_to_monitor,  # The metric you want to monitor\n",
    "        patience=config.patience,  # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=True,\n",
    "        mode='min'  # Minimizing the validation loss\n",
    "    )\n",
    "\n",
    "tb_logger = TensorBoardLogger(log_dir_folder, name=\"tensorbord\")#, version=\"\", default_hp_metric=False)\n",
    "csv_logger = CSVLogger(log_dir_folder, name=\"\", version=\"\")\n",
    "\n",
    "model_params = dict(\n",
    "    devices=1, #args['ngpus'],\n",
    "    accelerator='gpu', #args['accelerator'],\n",
    "    default_root_dir=log_dir_folder, #args['log_dir'],\n",
    "    logger=[tb_logger, csv_logger],\n",
    "    enable_progress_bar=True)\n",
    "\n",
    "\n",
    "model_params.update(dict(\n",
    "    max_epochs=config.num_epochs,#1000,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    #enable_checkpointing=False,\n",
    "    gradient_clip_val=10,#args['clip_norm'],\n",
    "    #precision=\"16-mixed\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "843bb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "787f4d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory /mnt/code/logs/tmp_Kraken_all_ChytorchDiscrete_multitask_v0/ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/code/logs/tmp_Kraken_all_ChytorchDiscrete_multitask_v0 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                 | Params\n",
      "-------------------------------------------------\n",
      "0 | net     | Model3D              | 1.6 M \n",
      "1 | loss_fn | GroupedScaledMAELoss | 0     \n",
      "-------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.443     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66d4cf488f543ddb8410ccec3a96583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved. New best score: 0.403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 85: 'val_epoch_loss' reached 0.38251 (best 0.38251), saving model to '/mnt/code/logs/tmp_Kraken_all_ChytorchDiscrete_multitask_v0/best-model-epoch=4-val_epoch_loss=0.3825.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 170: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 255: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 340: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 425: 'val_epoch_loss' reached 0.38075 (best 0.38075), saving model to '/mnt/code/logs/tmp_Kraken_all_ChytorchDiscrete_multitask_v0/best-model-epoch=24-val_epoch_loss=0.3808.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 510: 'val_epoch_loss' reached 0.37862 (best 0.37862), saving model to '/mnt/code/logs/tmp_Kraken_all_ChytorchDiscrete_multitask_v0/best-model-epoch=29-val_epoch_loss=0.3786.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 595: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573d197c817246a9aff2c60a69850b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05eb04616a9d4d5ea631b4742fde0ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d78822e79346fbb9154a4ebad5cd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b60f5fd110045599099dc51215a3d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae892cad9844cc1a5c9d892a5842886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 680: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9aeed7480144c1bbaaf4f14c3be079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af0796bd4354c539afac94284e92f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478e10084dc048daaaee90a669f9ddf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f07003ea14417eae0718014b7d040d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25e1a4916c2474799c948c0a8b3fdf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 765: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f572ea4e1cc4b56ad2180b7605de38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b12f0d2f24f6b9918e544c4e0b7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b76d8b86a14c918e69b76748f388b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4eb9ee4d74453987b5182d9c0e1117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20872884a3234ff3b12f194e99f70270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 850: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7108f3598b7d4ddbac05bc6dea15bc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b611da9cfb8b4af7a61ba49201d1158e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c3cda6859a44af879248b8ec456438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_epoch_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e468b421a244fbb6ecdd5a90da1522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe7fdf69b0b4d05a46c1e27cc38b0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 935: 'val_epoch_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81abd755dd04e6e99698750ff158283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd109be73422477f8d42e233f3026afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fd643c19090>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _releaseLock at 0x7fd643c19090>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**model_params)\n",
    "trainer.fit(model, datamodule=data, ckpt_path=dir_load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "531274fc-c611-4e67-afb5-7ac09c7aec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sterimol_B5', 'sterimol_L', 'sterimol_burB5', 'sterimol_burL']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset.descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e66010-c81f-4506-9371-18e972ab3956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98760096-e74b-4ba8-b072-9d43d749c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_candidates = checkpoint_callback._monitor_candidates(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba5b9cc4-d3a3-4299-b96c-289dfc605f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = checkpoint_callback.format_checkpoint_name(monitor_candidates, checkpoint_callback.CHECKPOINT_NAME_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "370d4ca6-b286-4f08-b8d6-4aa4f2389ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = trainer._checkpoint_connector.dump_checkpoint(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54e9f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object at key 'datamodule_hyper_parameters' of type '<class 'dict'>' cannot be pickled.\n",
      "Exception: cannot pickle 'getset_descriptor' object\n",
      "\n",
      "Non-picklable objects:\n",
      "- Key: 'datamodule_hyper_parameters', Type: '<class 'dict'>'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "\n",
    "def identify_non_picklable_objects(checkpoint):\n",
    "    non_picklable_objects = []\n",
    "    for key, value in checkpoint.items():\n",
    "        try:\n",
    "            # Attempt to pickle the object\n",
    "            torch.save(value, io.BytesIO())\n",
    "        except Exception as e:\n",
    "            # If an exception occurs, it means the object is not picklable\n",
    "            non_picklable_objects.append((key, type(value)))\n",
    "            print(f\"Object at key '{key}' of type '{type(value)}' cannot be pickled.\")\n",
    "            print(f\"Exception: {e}\")\n",
    "    return non_picklable_objects\n",
    "\n",
    "# Identify non-picklable objects\n",
    "non_picklable_objects = identify_non_picklable_objects(checkpoint)\n",
    "\n",
    "# Print out non-picklable objects\n",
    "print(\"\\nNon-picklable objects:\")\n",
    "for key, obj_type in non_picklable_objects:\n",
    "    print(f\"- Key: '{key}', Type: '{obj_type}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef5e1720-4340-46a7-8bce-257ae35c71dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Key: 'epoch', Type: '<class 'int'>'\n",
      "- Key: 'global_step', Type: '<class 'int'>'\n",
      "- Key: 'pytorch-lightning_version', Type: '<class 'str'>'\n",
      "- Key: 'state_dict', Type: '<class 'collections.OrderedDict'>'\n",
      "- Key: 'loops', Type: '<class 'dict'>'\n",
      "- Key: 'hparams_name', Type: '<class 'str'>'\n",
      "- Key: 'hyper_parameters', Type: '<class 'dict'>'\n",
      "- Key: 'datamodule_hyper_parameters', Type: '<class 'dict'>'\n"
     ]
    }
   ],
   "source": [
    "for key, obj_type in checkpoint.items():\n",
    "    print(f\"- Key: '{key}', Type: '{type(obj_type)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
